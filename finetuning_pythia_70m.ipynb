{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "9h0fp5Ufprxo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhnanjay/SEC/blob/main/finetuning_pythia_70m.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lamini --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip uninstall accelerate -y --quiet # Uninstall accelerate first\n",
        "!pip install accelerate --quiet # Explicitly install the required version\n",
        "!pip install transformers[torch] --quiet"
      ],
      "metadata": {
        "id": "jKn874rLp3O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Utilities"
      ],
      "metadata": {
        "id": "9h0fp5Ufprxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "import config\n",
        "import os\n",
        "import yaml\n",
        "import logging\n",
        "import time\n",
        "\n",
        "import transformers\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "global_config = None\n",
        "\n",
        "#############################\n",
        "########## Permissions ##########\n",
        "#############################\n",
        "model_name_to_id = {\n",
        "  \"bigger_model_name\" : \"06ad41e68cd839fb475a0c1a4ee7a3ad398228df01c9396a97788295d5a0f8bb\"\n",
        "}\n",
        "\n",
        "#############################\n",
        "########## LOGGING ##########\n",
        "#############################\n",
        "def initialize_config_and_logging(existing_config=None):\n",
        "    global global_config\n",
        "    global_config = build_config(existing_config)\n",
        "    setup_logging(global_config)\n",
        "    logger.debug(\"Config: \" + str(yaml.dump(global_config.as_dict())))\n",
        "    return global_config\n",
        "\n",
        "def get_config():\n",
        "    global global_config\n",
        "    assert global_config is not None\n",
        "    return global_config\n",
        "\n",
        "def build_config(existing_config=None):\n",
        "    configs = [\n",
        "        # Using config library\n",
        "        config.config_from_env(prefix=\"LLAMA\", separator=\"_\", lowercase_keys=True),\n",
        "    ]\n",
        "\n",
        "    if existing_config:\n",
        "        if isinstance(existing_config, dict):\n",
        "            configs.append(config.config_from_dict(existing_config))\n",
        "        else:\n",
        "            configs.append(existing_config)\n",
        "\n",
        "    config_paths = get_config_paths()\n",
        "\n",
        "    for path in reversed(config_paths):\n",
        "        print(\"Loading builtin config from \" + path)\n",
        "        configs.append(config.config_from_yaml(path, read_from_file=True))\n",
        "\n",
        "    return config.ConfigurationSet(*configs)\n",
        "\n",
        "def get_config_paths():\n",
        "    paths = []\n",
        "\n",
        "def get_config_paths():\n",
        "    paths = []\n",
        "\n",
        "    config_name = \"llama_config\"\n",
        "    config_base = \"configs\"\n",
        "\n",
        "    base_config_path = os.path.join(config_base, config_name + \".yaml\")\n",
        "    if os.path.exists(base_config_path):\n",
        "        paths.append(base_config_path)\n",
        "\n",
        "    local_config_path = os.path.join(config_base, config_name + \"_local.yaml\")\n",
        "    if os.path.exists(local_config_path):\n",
        "        paths.append(local_config_path)\n",
        "\n",
        "    home = os.path.expanduser(\"~\")\n",
        "    home_config_path = os.path.join(home, \".\" + config_name + \".yaml\")\n",
        "    if os.path.exists(home_config_path):\n",
        "        paths.append(home_config_path)\n",
        "\n",
        "    return paths\n",
        "\n",
        "def setup_logging(arguments):\n",
        "    logging_format = \"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"\n",
        "\n",
        "    if arguments[\"verbose\"]:\n",
        "        logging.basicConfig(level=logging.DEBUG, format=logging_format)\n",
        "    elif arguments[\"verbose_info\"]:\n",
        "        logging.basicConfig(level=logging.INFO, format=logging_format)\n",
        "    else:\n",
        "        logging.basicConfig(level=logging.WARNING, format=logging_format)\n",
        "\n",
        "    root_logger = logging.getLogger()\n",
        "\n",
        "    if arguments[\"verbose\"]:\n",
        "        root_logger.setLevel(logging.DEBUG)\n",
        "    elif arguments[\"verbose_info\"]:\n",
        "        root_logger.setLevel(logging.INFO)\n",
        "    else:\n",
        "        root_logger.setLevel(logging.WARNING)\n",
        "\n",
        "    logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "    logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
        "    logging.getLogger(\"smart_open\").setLevel(logging.WARNING)\n",
        "    logging.getLogger(\"botocore\").setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "##########################\n",
        "########## DATA ##########\n",
        "##########################\n",
        "# Wrapper for data load, split, tokenize for training\n",
        "def tokenize_and_split_data(training_config, tokenizer):\n",
        "  initialized_config = initialize_config_and_logging(training_config)\n",
        "  dataset_path = initialized_config[\"datasets\"][\"path\"]\n",
        "  use_hf = initialized_config[\"datasets\"][\"use_hf\"]\n",
        "  print(\"tokenize\", use_hf, dataset_path)\n",
        "  if use_hf:\n",
        "    dataset = datasets.load_dataset(dataset_path)\n",
        "  else:\n",
        "    dataset = load_dataset(dataset_path, tokenizer)\n",
        "  train_dataset = dataset[\"train\"]\n",
        "  test_dataset = dataset[\"test\"]\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "# Tokenize and split data\n",
        "def load_dataset(dataset_path, tokenizer):\n",
        "    random.seed(42)\n",
        "    finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    max_length = training_config[\"model\"][\"max_length\"]\n",
        "    tokenized_dataset = finetuning_dataset_loaded.map(\n",
        "        get_tokenize_function(tokenizer, max_length), # returns tokenize_function\n",
        "        batched=True,\n",
        "        batch_size=1,\n",
        "        drop_last_batch=True\n",
        "    )\n",
        "    tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
        "    split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
        "    return split_dataset\n",
        "\n",
        "# Get function for tokenization, based on config parameters\n",
        "def get_tokenize_function(tokenizer, _max_length):\n",
        "\n",
        "  def tokenize_function(examples):\n",
        "    max_length = _max_length\n",
        "\n",
        "    # Set pad token\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    if \"question\" in examples and \"answer\" in examples:\n",
        "      text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "    elif \"input\" in examples and \"output\" in examples:\n",
        "      text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "    else:\n",
        "      text = examples[\"text\"][0]\n",
        "\n",
        "    # Run tokenizer on all the text (the input and the output)\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "\n",
        "        # Return tensors in a numpy array (other options are pytorch or tf objects)\n",
        "        return_tensors=\"np\",\n",
        "\n",
        "        # Padding type is to pad to the longest sequence in the batch (other option is to a certain max length, or no padding)\n",
        "        padding=True,\n",
        "    )\n",
        "\n",
        "    # Calculate max length\n",
        "    max_length = min(\n",
        "        tokenized_inputs[\"input_ids\"].shape[1],\n",
        "        max_length\n",
        "    )\n",
        "\n",
        "    if tokenized_inputs[\"input_ids\"].shape[1] > max_length:\n",
        "        logger.warn(\n",
        "            f\"Truncating input from {tokenized_inputs['input_ids'].shape[1]} to {max_length}\"\n",
        "        )\n",
        "\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"]\n",
        "\n",
        "    return tokenized_inputs\n",
        "  return tokenize_function\n",
        "\n",
        "\n",
        "###########################\n",
        "########## MODEL ##########\n",
        "###########################\n",
        "\n",
        "# Load model onto the right device (GPU if available), and load tokenizer\n",
        "def load_model(training_config, load_base_model=False):\n",
        "    model_load_path = \"\"\n",
        "    model_load_path = training_config[\"model\"][\"pretrained_name\"]\n",
        "    logger.debug(f\"Loading default model: {model_load_path}\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_load_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_load_path)\n",
        "\n",
        "    logger.debug(\"Copying model to device\")\n",
        "\n",
        "    device_count = torch.cuda.device_count()\n",
        "    if device_count > 0:\n",
        "        logger.debug(\"Select GPU device\")\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        logger.debug(\"Select CPU device\")\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    logger.debug(\"Copying finished...\")\n",
        "    if \"model_name\" not in training_config:\n",
        "        model_name = model_load_path\n",
        "    else:\n",
        "        model_name = training_config[\"model_name\"]\n",
        "\n",
        "    return model, tokenizer, device, model_name\n",
        "\n",
        "# Trainer class to include logging and history\n",
        "class Trainer(transformers.Trainer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        model_flops,\n",
        "        total_steps,\n",
        "        args=None,\n",
        "        data_collator=None,\n",
        "        train_dataset=None,\n",
        "        eval_dataset=None,\n",
        "        tokenizer=None,\n",
        "        model_init=None,\n",
        "        compute_metrics=None,\n",
        "        callbacks=None,\n",
        "        optimizers=(None, None),\n",
        "    ):\n",
        "        super(Trainer, self).__init__(\n",
        "            model,\n",
        "            args,\n",
        "            data_collator,\n",
        "            train_dataset,\n",
        "            eval_dataset,\n",
        "            tokenizer,\n",
        "            model_init,\n",
        "            compute_metrics,\n",
        "            callbacks,\n",
        "            optimizers,\n",
        "        )\n",
        "\n",
        "        self.total_steps = total_steps\n",
        "        self.model_flops = model_flops\n",
        "        self.start_step = 0\n",
        "\n",
        "    def training_step(self, model, inputs):\n",
        "        if inputs[\"input_ids\"].numel() == 0:\n",
        "\n",
        "          print(\"Inputs: \", inputs)\n",
        "          print(\"Inputs - input_ids\", inputs[\"input_ids\"])\n",
        "          print(\"numel\", inputs[\"input_ids\"].numel())\n",
        "\n",
        "          return torch.tensor(0)\n",
        "        else:\n",
        "          model.train()\n",
        "          inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "          with self.compute_loss_context_manager():\n",
        "              loss = self.compute_loss(model, inputs)\n",
        "\n",
        "          if self.args.n_gpu > 1:\n",
        "              loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "\n",
        "          # if self.do_grad_scaling:\n",
        "          #     self.scaler.scale(loss).backward()\n",
        "          # else:\n",
        "          self.accelerator.backward(loss)\n",
        "\n",
        "          return loss.detach() / self.args.gradient_accumulation_steps\n",
        "\n",
        "    def log(self, logs):\n",
        "        \"\"\"\n",
        "        Log `logs` on the various objects watching training.\n",
        "        Subclass and override this method to inject custom behavior.\n",
        "        Args:\n",
        "            logs (`Dict[str, float]`):\n",
        "                The values to log.\n",
        "        \"\"\"\n",
        "        if self.state.epoch is not None:\n",
        "            logs[\"epoch\"] = round(self.state.epoch, 2)\n",
        "\n",
        "        self.update_log_timing(logs)\n",
        "\n",
        "        output = {**logs, **{\"step\": self.state.global_step}}\n",
        "        self.update_history(output)\n",
        "\n",
        "        logger.debug(\"Step (\" + str(self.state.global_step) + \") Logs: \" + str(logs))\n",
        "        self.control = self.callback_handler.on_log(\n",
        "            self.args, self.state, self.control, logs\n",
        "        )\n",
        "\n",
        "    def update_log_timing(self, logs):\n",
        "        if len(self.state.log_history) == 0:\n",
        "            self.start_time = time.time()\n",
        "            logs[\"iter_time\"] = 0.0\n",
        "            logs[\"flops\"] = 0.0\n",
        "            logs[\"remaining_time\"] = 0.0\n",
        "            self.start_step = self.state.global_step\n",
        "        elif self.state.global_step > self.start_step:\n",
        "            logs[\"iter_time\"] = (time.time() - self.start_time) / (\n",
        "                self.state.global_step - self.start_step\n",
        "            )\n",
        "            logs[\"flops\"] = self.model_flops / logs[\"iter_time\"]\n",
        "            logs[\"remaining_time\"] = (self.total_steps - self.state.global_step) * logs[\n",
        "                \"iter_time\"\n",
        "            ]\n",
        "\n",
        "    def update_history(self, output):\n",
        "        if \"eval_loss\" in output:\n",
        "            return\n",
        "        if len(self.state.log_history) > 0:\n",
        "            smoothing_window = 100\n",
        "            p = 1.0 / smoothing_window\n",
        "            if \"loss\" in output:\n",
        "                output[\"loss\"] = output[\"loss\"] * p + self.state.log_history[-1][\n",
        "                    \"loss\"\n",
        "                ] * (1.0 - p)\n",
        "        self.state.log_history.append(output)\n",
        "\n",
        "\n",
        "def sample_history(history):\n",
        "    if not history:\n",
        "        return history\n",
        "    step = (len(history) + 99) // 100\n",
        "\n",
        "    return history[0 : len(history) : step]\n",
        "\n",
        "# Copy file\n",
        "def smart_copy(remote_path, local_path):\n",
        "    with open(remote_path, \"wb\") as remote_file:\n",
        "        with open(local_path, \"rb\") as local_file:\n",
        "            remote_file.write(local_file.read())"
      ],
      "metadata": {
        "id": "qcvTQhY1puET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Imports"
      ],
      "metadata": {
        "id": "PqgHqDMlouk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import lamini"
      ],
      "metadata": {
        "id": "EfQZqErKo6v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "import config\n",
        "import os\n",
        "import yaml\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import jsonlines\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoModelForCausalLM\n",
        "from llama import BasicModelRunner\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "global_config = None"
      ],
      "metadata": {
        "id": "znZD7sUKpEGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Specify dataset"
      ],
      "metadata": {
        "id": "kg1f1Qb3qC2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"virattt/llama-3-8b-financialQA\"\n",
        "# dataset_path = \"lamini/lamini_docs\"\n",
        "use_hf = True"
      ],
      "metadata": {
        "id": "AuDQY1-VpFk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Set up model, training config, and tokenizer"
      ],
      "metadata": {
        "id": "7UTTdH0EqNh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"EleutherAI/pythia-70m\""
      ],
      "metadata": {
        "id": "Ywu58C9OqGFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_config = {\n",
        "    \"model\": {\n",
        "        \"pretrained_name\": model_name,\n",
        "        \"max_length\" : 2048\n",
        "    },\n",
        "    \"datasets\": {\n",
        "        \"use_hf\": use_hf,\n",
        "        \"path\": dataset_path\n",
        "    },\n",
        "    \"verbose\": True\n",
        "}"
      ],
      "metadata": {
        "id": "7-OTqgvgvJuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Tokenize the dataset\n",
        "random.seed(42)\n",
        "finetuning_dataset_loaded = datasets.load_dataset(dataset_path, split=\"train\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "max_length = training_config[\"model\"][\"max_length\"]\n",
        "tokenized_dataset = finetuning_dataset_loaded.map(\n",
        "    get_tokenize_function(tokenizer, max_length), # returns tokenize_function\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    drop_last_batch=True\n",
        ")\n",
        "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
        "\n",
        "# Split the dataset into train / test\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
        "\n",
        "train_dataset = split_dataset['train']\n",
        "test_dataset = split_dataset['test']\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAPp6OEJwGLJ",
        "outputId": "2eca1578-44d2-4e1e-d1e9-6112d511e286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "DEBUG:fsspec.local:open file: /root/.cache/huggingface/datasets/virattt___llama-3-8b-financial_qa/default/0.0.0/8105ab3194296d5260c01871a811c7124896ba66/dataset_info.json\n",
            "DEBUG:fsspec.local:open file: /root/.cache/huggingface/datasets/virattt___llama-3-8b-financial_qa/default/0.0.0/8105ab3194296d5260c01871a811c7124896ba66/dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'answer', 'context', 'ticker', 'filing', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 900\n",
            "})\n",
            "Dataset({\n",
            "    features: ['question', 'answer', 'context', 'ticker', 'filing', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Load base model"
      ],
      "metadata": {
        "id": "hcvs5ulVvLKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "eSpmIYe_v6yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_count = torch.cuda.device_count()\n",
        "if device_count > 0:\n",
        "    logger.debug(\"Select GPU device\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    logger.debug(\"Select CPU device\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsslUIlzwKiG",
        "outputId": "9b20b3cb-1d00-4384-fbc7-d12c257cc5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:__main__:Select GPU device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu980yA2wL_a",
        "outputId": "db8e5352-21e0-4d44-9c1b-a18ed8ae4f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 512)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Define inference function"
      ],
      "metadata": {
        "id": "luvfw43wwRB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",\n",
        "          truncation=True,\n",
        "          max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ],
      "metadata": {
        "id": "F8SNu4UKwNaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Try base model"
      ],
      "metadata": {
        "id": "HYDWL0pAwUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_text)\n",
        "print(f\"Correct answer from Lamini docs: {test_dataset[0]['answer']}\")\n",
        "print(\"Model's answer: \")\n",
        "print(inference(test_text, base_model, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6glEFTBMwPxR",
        "outputId": "0bb0c38f-9c62-46e8-ec73-e6b34953cf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question input (test): How are non-GAAP financial measures justified for aiding investors according to the document?\n",
            "Correct answer from Lamini docs: Non-GAAP financial measures are justified as they provide additional insight into operational performance and help clarify trends affecting the business, aiding investors.\n",
            "Model's answer: \n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "The document is a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is not a document that is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Set up hyperparameters for training"
      ],
      "metadata": {
        "id": "qjUWi4MhwonB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Play around with this value\n",
        "max_steps = 1000"
      ],
      "metadata": {
        "id": "kwwELrBDwWOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Get current timestamp with date, hour, minute, and seconds\n",
        "timestamp = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Set up training arguments\n",
        "trained_model_name = f\"financialQA_{max_steps}_steps_{timestamp}\"\n",
        "output_dir = trained_model_name"
      ],
      "metadata": {
        "id": "De28EFzhwt1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "\n",
        "  # Learning rate\n",
        "  learning_rate=1.0e-5,\n",
        "\n",
        "  # Number of training epochs\n",
        "  num_train_epochs=2,\n",
        "\n",
        "  # Max steps to train for (each step is a batch of data)\n",
        "  # Overrides num_train_epochs, if not -1\n",
        "  max_steps=max_steps,\n",
        "\n",
        "  # Batch size for training\n",
        "  per_device_train_batch_size=1,\n",
        "\n",
        "  # Directory to save model checkpoints\n",
        "  output_dir=output_dir,\n",
        "\n",
        "  # Other arguments\n",
        "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
        "  disable_tqdm=False, # Disable progress bars\n",
        "  eval_steps=120, # Number of update steps between two evaluations\n",
        "  save_steps=120, # After # steps model is saved\n",
        "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
        "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
        "  evaluation_strategy=\"steps\",\n",
        "  logging_strategy=\"steps\",\n",
        "  logging_steps=1,\n",
        "  optim=\"adafactor\",\n",
        "  gradient_accumulation_steps = 4,\n",
        "  gradient_checkpointing=False,\n",
        "\n",
        "  # Parameters for early stopping\n",
        "  load_best_model_at_end=True,\n",
        "  save_total_limit=1,\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae9aG-5zw_Zc",
        "outputId": "ab5a22cc-7292-428f-bf2b-913f0d0c781f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_flops = (\n",
        "  base_model.floating_point_ops(\n",
        "    {\n",
        "       \"input_ids\": torch.zeros(\n",
        "           (1, training_config[\"model\"][\"max_length\"])\n",
        "      )\n",
        "    }\n",
        "  )\n",
        "  * training_args.gradient_accumulation_steps\n",
        ")\n",
        "\n",
        "print(base_model)\n",
        "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
        "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlKzHX3NxAH3",
        "outputId": "59cea61b-8ddb-42d8-f1e2-c517600c7c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTNeoXForCausalLM(\n",
            "  (gpt_neox): GPTNeoXModel(\n",
            "    (embed_in): Embedding(50304, 512)\n",
            "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x GPTNeoXLayer(\n",
            "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (attention): GPTNeoXAttention(\n",
            "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
            "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
            "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (mlp): GPTNeoXMLP(\n",
            "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (act): GELUActivation()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
            ")\n",
            "Memory footprint 0.3084454 GB\n",
            "Flops 2195.667812352 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    model_flops=model_flops,\n",
        "    total_steps=max_steps,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4TTU4kyamd",
        "outputId": "8ef16e81-5b8a-428e-e168-298cbc2542a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Begin finetuning"
      ],
      "metadata": {
        "id": "SNW4yTR00KEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_output = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_H9DZZpIyI6e",
        "outputId": "92150887-867a-4ae8-d49c-f7c2a765d726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 02:04, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.685840</td>\n",
              "      <td>3.008493</td>\n",
              "      <td>104.781966</td>\n",
              "      <td>18440078492689.253906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.824582</td>\n",
              "      <td>2.918530</td>\n",
              "      <td>92.143760</td>\n",
              "      <td>18109826906666.527344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.541118</td>\n",
              "      <td>2.883304</td>\n",
              "      <td>78.210332</td>\n",
              "      <td>17967285978829.292969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>2.349249</td>\n",
              "      <td>2.898516</td>\n",
              "      <td>63.853095</td>\n",
              "      <td>17880844548122.492188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.155623</td>\n",
              "      <td>2.892917</td>\n",
              "      <td>49.187715</td>\n",
              "      <td>17855416239454.808594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>2.057369</td>\n",
              "      <td>2.917614</td>\n",
              "      <td>34.671841</td>\n",
              "      <td>17731593222444.089844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>1.950076</td>\n",
              "      <td>2.920505</td>\n",
              "      <td>19.833210</td>\n",
              "      <td>17713060384197.523438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>1.855202</td>\n",
              "      <td>2.930685</td>\n",
              "      <td>4.963152</td>\n",
              "      <td>17695751761688.769531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:__main__:Step (1) Logs: {'loss': 2.2709, 'grad_norm': 46.51436233520508, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
            "DEBUG:__main__:Step (2) Logs: {'loss': 2.5014, 'grad_norm': 49.03346252441406, 'learning_rate': 9.989989989989992e-06, 'epoch': 0.01, 'iter_time': 0.11273312568664551, 'flops': 19476687078251.582, 'remaining_time': 112.50765943527222}\n",
            "DEBUG:__main__:Step (3) Logs: {'loss': 1.9007, 'grad_norm': 62.61591339111328, 'learning_rate': 9.979979979979981e-06, 'epoch': 0.01, 'iter_time': 0.11202871799468994, 'flops': 19599151464502.812, 'remaining_time': 111.69263184070587}\n",
            "DEBUG:__main__:Step (4) Logs: {'loss': 2.494, 'grad_norm': 53.349647521972656, 'learning_rate': 9.96996996996997e-06, 'epoch': 0.02, 'iter_time': 0.11738801002502441, 'flops': 18704361815861.215, 'remaining_time': 116.91845798492432}\n",
            "DEBUG:__main__:Step (5) Logs: {'loss': 2.1122, 'grad_norm': 75.27790832519531, 'learning_rate': 9.95995995995996e-06, 'epoch': 0.02, 'iter_time': 0.12330043315887451, 'flops': 17807462278115.83, 'remaining_time': 122.68393099308014}\n",
            "DEBUG:__main__:Step (6) Logs: {'loss': 2.4217, 'grad_norm': 59.99551773071289, 'learning_rate': 9.949949949949951e-06, 'epoch': 0.03, 'iter_time': 0.12477178573608398, 'flops': 17597470448938.31, 'remaining_time': 124.02315502166748}\n",
            "DEBUG:__main__:Step (7) Logs: {'loss': 2.0288, 'grad_norm': 77.70494079589844, 'learning_rate': 9.93993993993994e-06, 'epoch': 0.03, 'iter_time': 0.12270661195119222, 'flops': 17893638960754.2, 'remaining_time': 121.84766566753387}\n",
            "DEBUG:__main__:Step (8) Logs: {'loss': 2.9729, 'grad_norm': 51.521549224853516, 'learning_rate': 9.929929929929931e-06, 'epoch': 0.04, 'iter_time': 0.12100369589669364, 'flops': 18145460732261.777, 'remaining_time': 120.0356663295201}\n",
            "DEBUG:__main__:Step (9) Logs: {'loss': 2.8693, 'grad_norm': 59.67495346069336, 'learning_rate': 9.91991991991992e-06, 'epoch': 0.04, 'iter_time': 0.1195186972618103, 'flops': 18370914866502.48, 'remaining_time': 118.44302898645401}\n",
            "DEBUG:__main__:Step (10) Logs: {'loss': 2.3432, 'grad_norm': 51.92192840576172, 'learning_rate': 9.90990990990991e-06, 'epoch': 0.04, 'iter_time': 0.11837132771809895, 'flops': 18548983564507.934, 'remaining_time': 117.18761444091797}\n",
            "DEBUG:__main__:Step (11) Logs: {'loss': 3.0991, 'grad_norm': 59.39780044555664, 'learning_rate': 9.899899899899901e-06, 'epoch': 0.05, 'iter_time': 0.11752805709838868, 'flops': 18682073596382.992, 'remaining_time': 116.2352484703064}\n",
            "DEBUG:__main__:Step (12) Logs: {'loss': 2.0604, 'grad_norm': 43.53318786621094, 'learning_rate': 9.88988988988989e-06, 'epoch': 0.05, 'iter_time': 0.11691520430824974, 'flops': 18780002355921.727, 'remaining_time': 115.51222185655074}\n",
            "DEBUG:__main__:Step (13) Logs: {'loss': 2.0135, 'grad_norm': 40.57891082763672, 'learning_rate': 9.879879879879881e-06, 'epoch': 0.06, 'iter_time': 0.1167879303296407, 'flops': 18800468560018.15, 'remaining_time': 115.26968723535538}\n",
            "DEBUG:__main__:Step (14) Logs: {'loss': 2.3601, 'grad_norm': 62.7369499206543, 'learning_rate': 9.86986986986987e-06, 'epoch': 0.06, 'iter_time': 0.11667288266695462, 'flops': 18819007143412.95, 'remaining_time': 115.03946230961726}\n",
            "DEBUG:__main__:Step (15) Logs: {'loss': 2.9179, 'grad_norm': 62.07474136352539, 'learning_rate': 9.85985985985986e-06, 'epoch': 0.07, 'iter_time': 0.11634014333997454, 'flops': 18872830558027.75, 'remaining_time': 114.59504118987492}\n",
            "DEBUG:__main__:Step (16) Logs: {'loss': 2.1092, 'grad_norm': 55.78179931640625, 'learning_rate': 9.849849849849851e-06, 'epoch': 0.07, 'iter_time': 0.11601276397705078, 'flops': 18926088277547.97, 'remaining_time': 114.15655975341797}\n",
            "DEBUG:__main__:Step (17) Logs: {'loss': 2.7456, 'grad_norm': 70.68408966064453, 'learning_rate': 9.83983983983984e-06, 'epoch': 0.08, 'iter_time': 0.11565826833248138, 'flops': 18984097237563.17, 'remaining_time': 113.6920777708292}\n",
            "DEBUG:__main__:Step (18) Logs: {'loss': 2.5627, 'grad_norm': 62.98134994506836, 'learning_rate': 9.829829829829831e-06, 'epoch': 0.08, 'iter_time': 0.11532452527214498, 'flops': 19039036208218.69, 'remaining_time': 113.24868381724637}\n",
            "DEBUG:__main__:Step (19) Logs: {'loss': 1.6986, 'grad_norm': 51.654747009277344, 'learning_rate': 9.81981981981982e-06, 'epoch': 0.08, 'iter_time': 0.11500891049702962, 'flops': 19091284343648.387, 'remaining_time': 112.82374119758606}\n",
            "DEBUG:__main__:Step (20) Logs: {'loss': 3.0743, 'grad_norm': 60.86171340942383, 'learning_rate': 9.80980980980981e-06, 'epoch': 0.09, 'iter_time': 0.11474842774240594, 'flops': 19134622195268.46, 'remaining_time': 112.45345918755783}\n",
            "DEBUG:__main__:Step (21) Logs: {'loss': 2.6956, 'grad_norm': 69.1961441040039, 'learning_rate': 9.799799799799801e-06, 'epoch': 0.09, 'iter_time': 0.11458809375762939, 'flops': 19161395746718.32, 'remaining_time': 112.18174378871917}\n",
            "DEBUG:__main__:Step (22) Logs: {'loss': 2.9559, 'grad_norm': 58.147403717041016, 'learning_rate': 9.78978978978979e-06, 'epoch': 0.1, 'iter_time': 0.11440403120858329, 'flops': 19192224165150.465, 'remaining_time': 111.88714252199446}\n",
            "DEBUG:__main__:Step (23) Logs: {'loss': 2.8131, 'grad_norm': 79.48436737060547, 'learning_rate': 9.779779779779781e-06, 'epoch': 0.1, 'iter_time': 0.1144355210390958, 'flops': 19186942938826.41, 'remaining_time': 111.8035040551966}\n",
            "DEBUG:__main__:Step (24) Logs: {'loss': 2.4763, 'grad_norm': 48.84286117553711, 'learning_rate': 9.76976976976977e-06, 'epoch': 0.11, 'iter_time': 0.11427143345708432, 'flops': 19214494348463.766, 'remaining_time': 111.5289190541143}\n",
            "DEBUG:__main__:Step (25) Logs: {'loss': 2.4042, 'grad_norm': 67.2675552368164, 'learning_rate': 9.75975975975976e-06, 'epoch': 0.11, 'iter_time': 0.11407311757405598, 'flops': 19247898707831.65, 'remaining_time': 111.22128963470459}\n",
            "DEBUG:__main__:Step (26) Logs: {'loss': 2.4046, 'grad_norm': 100.64042663574219, 'learning_rate': 9.749749749749751e-06, 'epoch': 0.12, 'iter_time': 0.1138994312286377, 'flops': 19277250014923.2, 'remaining_time': 110.93804601669312}\n",
            "DEBUG:__main__:Step (27) Logs: {'loss': 2.053, 'grad_norm': 56.697181701660156, 'learning_rate': 9.73973973973974e-06, 'epoch': 0.12, 'iter_time': 0.11386577899639423, 'flops': 19282947270940.2, 'remaining_time': 110.79140296349159}\n",
            "DEBUG:__main__:Step (28) Logs: {'loss': 2.6385, 'grad_norm': 66.80276489257812, 'learning_rate': 9.729729729729732e-06, 'epoch': 0.12, 'iter_time': 0.11373751251785844, 'flops': 19304693444981.473, 'remaining_time': 110.5528621673584}\n",
            "DEBUG:__main__:Step (29) Logs: {'loss': 3.1155, 'grad_norm': 82.41960906982422, 'learning_rate': 9.719719719719721e-06, 'epoch': 0.13, 'iter_time': 0.1135959369795663, 'flops': 19328753041114.12, 'remaining_time': 110.30165480715887}\n",
            "DEBUG:__main__:Step (30) Logs: {'loss': 2.2049, 'grad_norm': 42.02432632446289, 'learning_rate': 9.70970970970971e-06, 'epoch': 0.13, 'iter_time': 0.11347103118896484, 'flops': 19350029600907.78, 'remaining_time': 110.0669002532959}\n",
            "DEBUG:__main__:Step (31) Logs: {'loss': 3.2911, 'grad_norm': 61.24635314941406, 'learning_rate': 9.699699699699701e-06, 'epoch': 0.14, 'iter_time': 0.11340294679005941, 'flops': 19361646892798.965, 'remaining_time': 109.88745543956757}\n",
            "DEBUG:__main__:Step (32) Logs: {'loss': 3.063, 'grad_norm': 63.0736083984375, 'learning_rate': 9.68968968968969e-06, 'epoch': 0.14, 'iter_time': 0.11345710292939216, 'flops': 19352405055842.395, 'remaining_time': 109.82647563565162}\n",
            "DEBUG:__main__:Step (33) Logs: {'loss': 3.2332, 'grad_norm': 91.00827026367188, 'learning_rate': 9.67967967967968e-06, 'epoch': 0.15, 'iter_time': 0.11337904632091522, 'flops': 19365728356342.344, 'remaining_time': 109.63753779232502}\n",
            "DEBUG:__main__:Step (34) Logs: {'loss': 3.1379, 'grad_norm': 68.99664306640625, 'learning_rate': 9.669669669669671e-06, 'epoch': 0.15, 'iter_time': 0.11325414975484212, 'flops': 19387084862717.14, 'remaining_time': 109.40350866317749}\n",
            "DEBUG:__main__:Step (35) Logs: {'loss': 2.9345, 'grad_norm': 75.81309509277344, 'learning_rate': 9.65965965965966e-06, 'epoch': 0.16, 'iter_time': 0.11313092708587646, 'flops': 19408201354924.742, 'remaining_time': 109.17134463787079}\n",
            "DEBUG:__main__:Step (36) Logs: {'loss': 2.8768, 'grad_norm': 71.91923522949219, 'learning_rate': 9.649649649649651e-06, 'epoch': 0.16, 'iter_time': 0.11308345794677735, 'flops': 19416348352076.3, 'remaining_time': 109.01245346069337}\n",
            "DEBUG:__main__:Step (37) Logs: {'loss': 3.3609, 'grad_norm': 65.92037963867188, 'learning_rate': 9.63963963963964e-06, 'epoch': 0.16, 'iter_time': 0.11300430695215861, 'flops': 19429948039781.844, 'remaining_time': 108.82314759492874}\n",
            "DEBUG:__main__:Step (38) Logs: {'loss': 2.6074, 'grad_norm': 59.17711639404297, 'learning_rate': 9.62962962962963e-06, 'epoch': 0.17, 'iter_time': 0.11291821582897289, 'flops': 19444761823704.168, 'remaining_time': 108.62732362747192}\n",
            "DEBUG:__main__:Step (39) Logs: {'loss': 2.7471, 'grad_norm': 97.73084259033203, 'learning_rate': 9.61961961961962e-06, 'epoch': 0.17, 'iter_time': 0.11284743484697844, 'flops': 19456958107460.164, 'remaining_time': 108.44638488794628}\n",
            "DEBUG:__main__:Step (40) Logs: {'loss': 2.5441, 'grad_norm': 69.2578125, 'learning_rate': 9.60960960960961e-06, 'epoch': 0.18, 'iter_time': 0.11277129711248936, 'flops': 19470094506067.637, 'remaining_time': 108.26044522798978}\n",
            "DEBUG:__main__:Step (41) Logs: {'loss': 2.5647, 'grad_norm': 57.253047943115234, 'learning_rate': 9.5995995995996e-06, 'epoch': 0.18, 'iter_time': 0.11268313527107239, 'flops': 19485327658571.67, 'remaining_time': 108.06312672495842}\n",
            "DEBUG:__main__:Step (42) Logs: {'loss': 2.0041, 'grad_norm': 66.82723236083984, 'learning_rate': 9.58958958958959e-06, 'epoch': 0.19, 'iter_time': 0.11274652946286084, 'flops': 19474371608708.91, 'remaining_time': 108.01117522542069}\n",
            "DEBUG:__main__:Step (43) Logs: {'loss': 2.6238, 'grad_norm': 62.12065124511719, 'learning_rate': 9.57957957957958e-06, 'epoch': 0.19, 'iter_time': 0.11276531787145705, 'flops': 19471126883665.383, 'remaining_time': 107.9164092029844}\n",
            "DEBUG:__main__:Step (44) Logs: {'loss': 2.5547, 'grad_norm': 72.56844329833984, 'learning_rate': 9.56956956956957e-06, 'epoch': 0.2, 'iter_time': 0.11269358701484147, 'flops': 19483520495827.645, 'remaining_time': 107.73506918618845}\n",
            "DEBUG:__main__:Step (45) Logs: {'loss': 3.5426, 'grad_norm': 48.540733337402344, 'learning_rate': 9.55955955955956e-06, 'epoch': 0.2, 'iter_time': 0.11261517893184315, 'flops': 19497085856257.973, 'remaining_time': 107.54749587991022}\n",
            "DEBUG:__main__:Step (46) Logs: {'loss': 2.995, 'grad_norm': 69.01502227783203, 'learning_rate': 9.54954954954955e-06, 'epoch': 0.2, 'iter_time': 0.1125579039255778, 'flops': 19507006933993.32, 'remaining_time': 107.38024034500121}\n",
            "DEBUG:__main__:Step (47) Logs: {'loss': 2.1738, 'grad_norm': 55.1431770324707, 'learning_rate': 9.53953953953954e-06, 'epoch': 0.21, 'iter_time': 0.11249445313992708, 'flops': 19518009564621.84, 'remaining_time': 107.20721384235051}\n",
            "DEBUG:__main__:Step (48) Logs: {'loss': 2.8368, 'grad_norm': 52.89126968383789, 'learning_rate': 9.52952952952953e-06, 'epoch': 0.21, 'iter_time': 0.11243432126146682, 'flops': 19528448143925.363, 'remaining_time': 107.03747384091642}\n",
            "DEBUG:__main__:Step (49) Logs: {'loss': 3.6844, 'grad_norm': 71.01533508300781, 'learning_rate': 9.51951951951952e-06, 'epoch': 0.22, 'iter_time': 0.11239609122276306, 'flops': 19535090486379.133, 'remaining_time': 106.88868275284767}\n",
            "DEBUG:__main__:Step (50) Logs: {'loss': 2.2862, 'grad_norm': 58.95432662963867, 'learning_rate': 9.50950950950951e-06, 'epoch': 0.22, 'iter_time': 0.11238055813069246, 'flops': 19537790600742.15, 'remaining_time': 106.76153022415784}\n",
            "DEBUG:__main__:Step (51) Logs: {'loss': 3.0784, 'grad_norm': 61.919063568115234, 'learning_rate': 9.4994994994995e-06, 'epoch': 0.23, 'iter_time': 0.11237076759338378, 'flops': 19539492871465.242, 'remaining_time': 106.63985844612121}\n",
            "DEBUG:__main__:Step (52) Logs: {'loss': 2.2213, 'grad_norm': 45.04733657836914, 'learning_rate': 9.489489489489491e-06, 'epoch': 0.23, 'iter_time': 0.11236304395339068, 'flops': 19540835982182.76, 'remaining_time': 106.52016566781437}\n",
            "DEBUG:__main__:Step (53) Logs: {'loss': 3.0379, 'grad_norm': 65.7917709350586, 'learning_rate': 9.47947947947948e-06, 'epoch': 0.24, 'iter_time': 0.11233275670271653, 'flops': 19546104598525.38, 'remaining_time': 106.37912059747255}\n",
            "DEBUG:__main__:Step (54) Logs: {'loss': 2.4173, 'grad_norm': 43.07502746582031, 'learning_rate': 9.46946946946947e-06, 'epoch': 0.24, 'iter_time': 0.11233610027241257, 'flops': 19545522828614.79, 'remaining_time': 106.2699508577023}\n",
            "DEBUG:__main__:Step (55) Logs: {'loss': 2.952, 'grad_norm': 76.43647003173828, 'learning_rate': 9.45945945945946e-06, 'epoch': 0.24, 'iter_time': 0.11229033823366519, 'flops': 19553488277709.438, 'remaining_time': 106.1143696308136}\n",
            "DEBUG:__main__:Step (56) Logs: {'loss': 2.6565, 'grad_norm': 56.96407699584961, 'learning_rate': 9.44944944944945e-06, 'epoch': 0.25, 'iter_time': 0.11224714625965465, 'flops': 19561012333203.484, 'remaining_time': 105.96130606911399}\n",
            "DEBUG:__main__:Step (57) Logs: {'loss': 2.3922, 'grad_norm': 54.34986114501953, 'learning_rate': 9.439439439439441e-06, 'epoch': 0.25, 'iter_time': 0.11220123512404305, 'flops': 19569016418799.664, 'remaining_time': 105.8057647219726}\n",
            "DEBUG:__main__:Step (58) Logs: {'loss': 2.7193, 'grad_norm': 53.80487823486328, 'learning_rate': 9.42942942942943e-06, 'epoch': 0.26, 'iter_time': 0.11222385523612038, 'flops': 19565072040452.43, 'remaining_time': 105.7148716324254}\n",
            "DEBUG:__main__:Step (59) Logs: {'loss': 2.9327, 'grad_norm': 49.69010925292969, 'learning_rate': 9.41941941941942e-06, 'epoch': 0.26, 'iter_time': 0.11224051590623527, 'flops': 19562167855556.2, 'remaining_time': 105.61832546776739}\n",
            "DEBUG:__main__:Step (60) Logs: {'loss': 2.4948, 'grad_norm': 60.03776168823242, 'learning_rate': 9.40940940940941e-06, 'epoch': 0.27, 'iter_time': 0.11233786001043805, 'flops': 19545216654011.266, 'remaining_time': 105.59758840981176}\n",
            "DEBUG:__main__:Step (61) Logs: {'loss': 2.4842, 'grad_norm': 77.5825424194336, 'learning_rate': 9.3993993993994e-06, 'epoch': 0.27, 'iter_time': 0.11235509316126506, 'flops': 19542218786651.023, 'remaining_time': 105.50143247842789}\n",
            "DEBUG:__main__:Step (62) Logs: {'loss': 3.0747, 'grad_norm': 56.1519889831543, 'learning_rate': 9.389389389389391e-06, 'epoch': 0.28, 'iter_time': 0.11232335841069456, 'flops': 19547740055312.89, 'remaining_time': 105.3593101892315}\n",
            "DEBUG:__main__:Step (63) Logs: {'loss': 2.5871, 'grad_norm': 88.92361450195312, 'learning_rate': 9.37937937937938e-06, 'epoch': 0.28, 'iter_time': 0.11229453932854437, 'flops': 19552756754520.82, 'remaining_time': 105.21998335084608}\n",
            "DEBUG:__main__:Step (64) Logs: {'loss': 3.469, 'grad_norm': 64.52928924560547, 'learning_rate': 9.36936936936937e-06, 'epoch': 0.28, 'iter_time': 0.1122693523528084, 'flops': 19557143301691.77, 'remaining_time': 105.08411380222866}\n",
            "DEBUG:__main__:Step (65) Logs: {'loss': 3.2502, 'grad_norm': 224.61241149902344, 'learning_rate': 9.35935935935936e-06, 'epoch': 0.29, 'iter_time': 0.11227637901902199, 'flops': 19555919344174.855, 'remaining_time': 104.97841438278556}\n",
            "DEBUG:__main__:Step (66) Logs: {'loss': 3.038, 'grad_norm': 53.88533401489258, 'learning_rate': 9.34934934934935e-06, 'epoch': 0.29, 'iter_time': 0.11225726421062764, 'flops': 19559249263658.176, 'remaining_time': 104.84828477272622}\n",
            "DEBUG:__main__:Step (67) Logs: {'loss': 3.0143, 'grad_norm': 76.62115478515625, 'learning_rate': 9.339339339339341e-06, 'epoch': 0.3, 'iter_time': 0.11223122567841501, 'flops': 19563787164219.523, 'remaining_time': 104.7117335579612}\n",
            "DEBUG:__main__:Step (68) Logs: {'loss': 3.2584, 'grad_norm': 57.40022659301758, 'learning_rate': 9.32932932932933e-06, 'epoch': 0.3, 'iter_time': 0.11220136329309265, 'flops': 19568994064862.402, 'remaining_time': 104.57167058916235}\n",
            "DEBUG:__main__:Step (69) Logs: {'loss': 2.5947, 'grad_norm': 64.1877212524414, 'learning_rate': 9.31931931931932e-06, 'epoch': 0.31, 'iter_time': 0.11225309442071353, 'flops': 19559975817885.727, 'remaining_time': 104.5076309056843}\n",
            "DEBUG:__main__:Step (70) Logs: {'loss': 2.8982, 'grad_norm': 82.23963165283203, 'learning_rate': 9.30930930930931e-06, 'epoch': 0.31, 'iter_time': 0.11229799795841826, 'flops': 19552154555462.445, 'remaining_time': 104.43713810132898}\n",
            "DEBUG:__main__:Step (71) Logs: {'loss': 3.539, 'grad_norm': 60.08601379394531, 'learning_rate': 9.2992992992993e-06, 'epoch': 0.32, 'iter_time': 0.11228515420641218, 'flops': 19554391031210.906, 'remaining_time': 104.31290825775692}\n",
            "DEBUG:__main__:Step (72) Logs: {'loss': 2.8368, 'grad_norm': 49.93793487548828, 'learning_rate': 9.289289289289291e-06, 'epoch': 0.32, 'iter_time': 0.11226146993502764, 'flops': 19558516502792.66, 'remaining_time': 104.17864409970565}\n",
            "DEBUG:__main__:Step (73) Logs: {'loss': 2.4409, 'grad_norm': 49.95869445800781, 'learning_rate': 9.27927927927928e-06, 'epoch': 0.32, 'iter_time': 0.1122603648238712, 'flops': 19558709040335.402, 'remaining_time': 104.06535819172859}\n",
            "DEBUG:__main__:Step (74) Logs: {'loss': 2.4203, 'grad_norm': 59.96371841430664, 'learning_rate': 9.26926926926927e-06, 'epoch': 0.33, 'iter_time': 0.11223968414411153, 'flops': 19562312822734.293, 'remaining_time': 103.93394751744728}\n",
            "DEBUG:__main__:Step (75) Logs: {'loss': 3.1547, 'grad_norm': 55.03461456298828, 'learning_rate': 9.25925925925926e-06, 'epoch': 0.33, 'iter_time': 0.11222412457337251, 'flops': 19565025084392.305, 'remaining_time': 103.80731523036957}\n",
            "DEBUG:__main__:Step (76) Logs: {'loss': 3.0844, 'grad_norm': 53.62152099609375, 'learning_rate': 9.24924924924925e-06, 'epoch': 0.34, 'iter_time': 0.11221383412679037, 'flops': 19566819273558.69, 'remaining_time': 103.6855827331543}\n",
            "DEBUG:__main__:Step (77) Logs: {'loss': 2.289, 'grad_norm': 176.7492218017578, 'learning_rate': 9.239239239239241e-06, 'epoch': 0.34, 'iter_time': 0.1122016561658759, 'flops': 19568942985172.91, 'remaining_time': 103.56212864110346}\n",
            "DEBUG:__main__:Step (78) Logs: {'loss': 2.7077, 'grad_norm': 54.30794906616211, 'learning_rate': 9.229229229229229e-06, 'epoch': 0.35, 'iter_time': 0.1122051090389103, 'flops': 19568340792669.164, 'remaining_time': 103.4531105338753}\n",
            "DEBUG:__main__:Step (79) Logs: {'loss': 2.9906, 'grad_norm': 63.91807174682617, 'learning_rate': 9.21921921921922e-06, 'epoch': 0.35, 'iter_time': 0.11221892100114089, 'flops': 19565932311269.305, 'remaining_time': 103.35362624205077}\n",
            "DEBUG:__main__:Step (80) Logs: {'loss': 3.2929, 'grad_norm': 66.68231964111328, 'learning_rate': 9.20920920920921e-06, 'epoch': 0.36, 'iter_time': 0.11219180082973046, 'flops': 19570661992352.61, 'remaining_time': 103.21645676335203}\n",
            "DEBUG:__main__:Step (81) Logs: {'loss': 3.5098, 'grad_norm': 63.786720275878906, 'learning_rate': 9.1991991991992e-06, 'epoch': 0.36, 'iter_time': 0.1121775358915329, 'flops': 19573150674971.527, 'remaining_time': 103.09115548431873}\n",
            "DEBUG:__main__:Step (82) Logs: {'loss': 2.7119, 'grad_norm': 61.572723388671875, 'learning_rate': 9.189189189189191e-06, 'epoch': 0.36, 'iter_time': 0.11215551105546362, 'flops': 19576994404369.387, 'remaining_time': 102.9587591489156}\n",
            "DEBUG:__main__:Step (83) Logs: {'loss': 3.3271, 'grad_norm': 67.47264099121094, 'learning_rate': 9.179179179179179e-06, 'epoch': 0.37, 'iter_time': 0.11212263165450678, 'flops': 19582735260065.09, 'remaining_time': 102.81645322718272}\n",
            "DEBUG:__main__:Step (84) Logs: {'loss': 4.1881, 'grad_norm': 70.597412109375, 'learning_rate': 9.16916916916917e-06, 'epoch': 0.37, 'iter_time': 0.11208720666816435, 'flops': 19588924352913.027, 'remaining_time': 102.67188130803855}\n",
            "DEBUG:__main__:Step (85) Logs: {'loss': 2.3465, 'grad_norm': 64.86213684082031, 'learning_rate': 9.15915915915916e-06, 'epoch': 0.38, 'iter_time': 0.11207255295344762, 'flops': 19591485644696.88, 'remaining_time': 102.54638595240458}\n",
            "DEBUG:__main__:Step (86) Logs: {'loss': 2.928, 'grad_norm': 62.55767059326172, 'learning_rate': 9.14914914914915e-06, 'epoch': 0.38, 'iter_time': 0.11207505394430721, 'flops': 19591048454396.285, 'remaining_time': 102.43659930509679}\n",
            "DEBUG:__main__:Step (87) Logs: {'loss': 2.3039, 'grad_norm': 52.35717010498047, 'learning_rate': 9.13913913913914e-06, 'epoch': 0.39, 'iter_time': 0.1120566490084626, 'flops': 19594266219634.87, 'remaining_time': 102.30772054472635}\n",
            "DEBUG:__main__:Step (88) Logs: {'loss': 2.9613, 'grad_norm': 58.76900100708008, 'learning_rate': 9.129129129129129e-06, 'epoch': 0.39, 'iter_time': 0.1121741684003808, 'flops': 19573738264901.156, 'remaining_time': 102.30284158114729}\n",
            "DEBUG:__main__:Step (89) Logs: {'loss': 3.5411, 'grad_norm': 62.02098083496094, 'learning_rate': 9.11911911911912e-06, 'epoch': 0.4, 'iter_time': 0.11214419928464023, 'flops': 19578969098339.52, 'remaining_time': 102.16336554830725}\n",
            "DEBUG:__main__:Step (90) Logs: {'loss': 2.9881, 'grad_norm': 63.58928298950195, 'learning_rate': 9.10910910910911e-06, 'epoch': 0.4, 'iter_time': 0.11211259445447601, 'flops': 19584488460335.863, 'remaining_time': 102.02246095357317}\n",
            "DEBUG:__main__:Step (91) Logs: {'loss': 3.014, 'grad_norm': 74.43291473388672, 'learning_rate': 9.0990990990991e-06, 'epoch': 0.4, 'iter_time': 0.11209064059787327, 'flops': 19588324240459.902, 'remaining_time': 101.8903923034668}\n",
            "DEBUG:__main__:Step (92) Logs: {'loss': 2.3853, 'grad_norm': 49.33219909667969, 'learning_rate': 9.08908908908909e-06, 'epoch': 0.41, 'iter_time': 0.11206496154868996, 'flops': 19592812793658.316, 'remaining_time': 101.75498508621048}\n",
            "DEBUG:__main__:Step (93) Logs: {'loss': 2.8848, 'grad_norm': 67.25214385986328, 'learning_rate': 9.079079079079079e-06, 'epoch': 0.41, 'iter_time': 0.11203786342040352, 'flops': 19597551625142.3, 'remaining_time': 101.61834212230599}\n",
            "DEBUG:__main__:Step (94) Logs: {'loss': 2.7215, 'grad_norm': 103.20217895507812, 'learning_rate': 9.06906906906907e-06, 'epoch': 0.42, 'iter_time': 0.11203424392207977, 'flops': 19598184764642.99, 'remaining_time': 101.50302499340427}\n",
            "DEBUG:__main__:Step (95) Logs: {'loss': 2.7422, 'grad_norm': 70.6083984375, 'learning_rate': 9.05905905905906e-06, 'epoch': 0.42, 'iter_time': 0.11201814387707, 'flops': 19601001555261.9, 'remaining_time': 101.37642020874836}\n",
            "DEBUG:__main__:Step (96) Logs: {'loss': 2.8787, 'grad_norm': 80.3925552368164, 'learning_rate': 9.04904904904905e-06, 'epoch': 0.43, 'iter_time': 0.11201217300013493, 'flops': 19602046398558.44, 'remaining_time': 101.25900439212198}\n",
            "DEBUG:__main__:Step (97) Logs: {'loss': 2.8429, 'grad_norm': 62.126304626464844, 'learning_rate': 9.03903903903904e-06, 'epoch': 0.43, 'iter_time': 0.11212094873189926, 'flops': 19583029194679.977, 'remaining_time': 101.24521670490503}\n",
            "DEBUG:__main__:Step (98) Logs: {'loss': 3.7168, 'grad_norm': 65.2328109741211, 'learning_rate': 9.029029029029029e-06, 'epoch': 0.44, 'iter_time': 0.11211725117005024, 'flops': 19583675031613.035, 'remaining_time': 101.12976055538532}\n",
            "DEBUG:__main__:Step (99) Logs: {'loss': 3.9059, 'grad_norm': 62.09392547607422, 'learning_rate': 9.01901901901902e-06, 'epoch': 0.44, 'iter_time': 0.11209566982424989, 'flops': 19587445400830.344, 'remaining_time': 100.99819851164915}\n",
            "DEBUG:__main__:Step (100) Logs: {'loss': 3.1835, 'grad_norm': 74.36734771728516, 'learning_rate': 9.00900900900901e-06, 'epoch': 0.44, 'iter_time': 0.11207376104412657, 'flops': 19591274459750.703, 'remaining_time': 100.86638493971391}\n",
            "DEBUG:__main__:Step (101) Logs: {'loss': 3.3524, 'grad_norm': 78.59699249267578, 'learning_rate': 8.998998998999e-06, 'epoch': 0.45, 'iter_time': 0.1120561957359314, 'flops': 19594345479354.406, 'remaining_time': 100.73851996660233}\n",
            "DEBUG:__main__:Step (102) Logs: {'loss': 3.4012, 'grad_norm': 62.16214370727539, 'learning_rate': 8.98898898898899e-06, 'epoch': 0.45, 'iter_time': 0.11206597856955954, 'flops': 19592634985015.953, 'remaining_time': 100.63524875546446}\n",
            "DEBUG:__main__:Step (103) Logs: {'loss': 3.547, 'grad_norm': 110.48890686035156, 'learning_rate': 8.97897897897898e-06, 'epoch': 0.46, 'iter_time': 0.11210659438488531, 'flops': 19585536643935.633, 'remaining_time': 100.55961516324213}\n",
            "DEBUG:__main__:Step (104) Logs: {'loss': 3.2093, 'grad_norm': 53.27020263671875, 'learning_rate': 8.96896896896897e-06, 'epoch': 0.46, 'iter_time': 0.11213701442607397, 'flops': 19580223564802.4, 'remaining_time': 100.47476492576229}\n",
            "DEBUG:__main__:Step (105) Logs: {'loss': 2.7405, 'grad_norm': 71.16411590576172, 'learning_rate': 8.95895895895896e-06, 'epoch': 0.47, 'iter_time': 0.11214612538997944, 'flops': 19578632830307.207, 'remaining_time': 100.3707822240316}\n",
            "DEBUG:__main__:Step (106) Logs: {'loss': 3.4471, 'grad_norm': 87.21089935302734, 'learning_rate': 8.94894894894895e-06, 'epoch': 0.47, 'iter_time': 0.11214415913536435, 'flops': 19578976107901.48, 'remaining_time': 100.25687826701574}\n",
            "DEBUG:__main__:Step (107) Logs: {'loss': 2.1503, 'grad_norm': 45.61181640625, 'learning_rate': 8.93893893893894e-06, 'epoch': 0.48, 'iter_time': 0.11212036069834007, 'flops': 19583131901077.684, 'remaining_time': 100.12348210361768}\n",
            "DEBUG:__main__:Step (108) Logs: {'loss': 2.9667, 'grad_norm': 57.21857833862305, 'learning_rate': 8.92892892892893e-06, 'epoch': 0.48, 'iter_time': 0.11211365405644212, 'flops': 19584303364571.637, 'remaining_time': 100.00537941834638}\n",
            "DEBUG:__main__:Step (109) Logs: {'loss': 3.2387, 'grad_norm': 164.7614288330078, 'learning_rate': 8.91891891891892e-06, 'epoch': 0.48, 'iter_time': 0.11211542729978208, 'flops': 19583993614733.055, 'remaining_time': 99.89484572410583}\n",
            "DEBUG:__main__:Step (110) Logs: {'loss': 2.1846, 'grad_norm': 40.76104736328125, 'learning_rate': 8.90890890890891e-06, 'epoch': 0.49, 'iter_time': 0.11212532017209115, 'flops': 19582265709315.84, 'remaining_time': 99.79153495316112}\n",
            "DEBUG:__main__:Step (111) Logs: {'loss': 3.5749, 'grad_norm': 72.25825500488281, 'learning_rate': 8.8988988988989e-06, 'epoch': 0.49, 'iter_time': 0.11210109103809704, 'flops': 19586498151082.332, 'remaining_time': 99.65786993286827}\n",
            "DEBUG:__main__:Step (112) Logs: {'loss': 2.169, 'grad_norm': 71.0714111328125, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.5, 'iter_time': 0.11208590301307472, 'flops': 19589152188887.457, 'remaining_time': 99.53228187561035}\n",
            "DEBUG:__main__:Step (113) Logs: {'loss': 2.4664, 'grad_norm': 285.7129211425781, 'learning_rate': 8.87887887887888e-06, 'epoch': 0.5, 'iter_time': 0.11208582137312208, 'flops': 19589166457038.75, 'remaining_time': 99.42012355795929}\n",
            "DEBUG:__main__:Step (114) Logs: {'loss': 3.142, 'grad_norm': 70.63246154785156, 'learning_rate': 8.86886886886887e-06, 'epoch': 0.51, 'iter_time': 0.11207179474619637, 'flops': 19591618188362.414, 'remaining_time': 99.29561014512998}\n",
            "DEBUG:__main__:Step (115) Logs: {'loss': 3.6085, 'grad_norm': 83.25568389892578, 'learning_rate': 8.85885885885886e-06, 'epoch': 0.51, 'iter_time': 0.11216238507053308, 'flops': 19575794603255.44, 'remaining_time': 99.26371078742177}\n",
            "DEBUG:__main__:Step (116) Logs: {'loss': 2.8798, 'grad_norm': 65.0196533203125, 'learning_rate': 8.84884884884885e-06, 'epoch': 0.52, 'iter_time': 0.11214624280514925, 'flops': 19578612331818.44, 'remaining_time': 99.13727863975194}\n",
            "DEBUG:__main__:Step (117) Logs: {'loss': 2.4583, 'grad_norm': 73.97474670410156, 'learning_rate': 8.838838838838838e-06, 'epoch': 0.52, 'iter_time': 0.11212722802984304, 'flops': 19581932514800.203, 'remaining_time': 99.0083423503514}\n",
            "DEBUG:__main__:Step (118) Logs: {'loss': 2.8346, 'grad_norm': 79.47362518310547, 'learning_rate': 8.82882882882883e-06, 'epoch': 0.52, 'iter_time': 0.11211046805748573, 'flops': 19584859918934.152, 'remaining_time': 98.88143282670241}\n",
            "DEBUG:__main__:Step (119) Logs: {'loss': 2.7525, 'grad_norm': 57.2144889831543, 'learning_rate': 8.818818818818819e-06, 'epoch': 0.53, 'iter_time': 0.11209756843114303, 'flops': 19587113646454.42, 'remaining_time': 98.75795778783701}\n",
            "DEBUG:__main__:Step (120) Logs: {'loss': 2.9561, 'grad_norm': 105.5799789428711, 'learning_rate': 8.80880880880881e-06, 'epoch': 0.53, 'iter_time': 0.11207649888110761, 'flops': 19590795878457.95, 'remaining_time': 98.6273190153747}\n",
            "DEBUG:__main__:Step (120) Logs: {'eval_loss': 3.008492946624756, 'eval_runtime': 0.8257, 'eval_samples_per_second': 121.11, 'eval_steps_per_second': 121.11, 'epoch': 0.53, 'iter_time': 0.11907041573724828, 'flops': 18440078492689.254, 'remaining_time': 104.78196584877848}\n",
            "DEBUG:__main__:Step (121) Logs: {'loss': 2.0962, 'grad_norm': 60.37898635864258, 'learning_rate': 8.798798798798799e-06, 'epoch': 0.54, 'iter_time': 0.12417787512143454, 'flops': 17681634592352.613, 'remaining_time': 109.15235223174096}\n",
            "DEBUG:__main__:Step (122) Logs: {'loss': 3.0753, 'grad_norm': 45.99099349975586, 'learning_rate': 8.788788788788788e-06, 'epoch': 0.54, 'iter_time': 0.12406194308572564, 'flops': 17698157531152.113, 'remaining_time': 108.92638602926712}\n",
            "DEBUG:__main__:Step (123) Logs: {'loss': 2.4774, 'grad_norm': 49.006221771240234, 'learning_rate': 8.77877877877878e-06, 'epoch': 0.55, 'iter_time': 0.12395029966948462, 'flops': 17714098458872.484, 'remaining_time': 108.70441281013801}\n",
            "DEBUG:__main__:Step (124) Logs: {'loss': 3.039, 'grad_norm': 59.23491668701172, 'learning_rate': 8.768768768768769e-06, 'epoch': 0.55, 'iter_time': 0.12384607733749761, 'flops': 17729005710600.773, 'remaining_time': 108.48916374764791}\n",
            "DEBUG:__main__:Step (125) Logs: {'loss': 3.4934, 'grad_norm': 62.039344787597656, 'learning_rate': 8.75875875875876e-06, 'epoch': 0.56, 'iter_time': 0.12374330143774709, 'flops': 17743730665345.137, 'remaining_time': 108.2753887580287}\n",
            "DEBUG:__main__:Step (126) Logs: {'loss': 3.6851, 'grad_norm': 76.6738052368164, 'learning_rate': 8.74874874874875e-06, 'epoch': 0.56, 'iter_time': 0.12364770698547363, 'flops': 17757448689363.492, 'remaining_time': 108.06809590530395}\n",
            "DEBUG:__main__:Step (127) Logs: {'loss': 2.579, 'grad_norm': 75.59501647949219, 'learning_rate': 8.738738738738739e-06, 'epoch': 0.56, 'iter_time': 0.12353316753629655, 'flops': 17773913323374.21, 'remaining_time': 107.84445525918689}\n",
            "DEBUG:__main__:Step (128) Logs: {'loss': 2.5834, 'grad_norm': 65.80393981933594, 'learning_rate': 8.72872872872873e-06, 'epoch': 0.57, 'iter_time': 0.12343198671115665, 'flops': 17788483122207.9, 'remaining_time': 107.6326924121286}\n",
            "DEBUG:__main__:Step (129) Logs: {'loss': 3.4776, 'grad_norm': 54.90626907348633, 'learning_rate': 8.718718718718719e-06, 'epoch': 0.57, 'iter_time': 0.1233277004212141, 'flops': 17803525119278.996, 'remaining_time': 107.41842706687748}\n",
            "DEBUG:__main__:Step (130) Logs: {'loss': 2.4503, 'grad_norm': 74.39450073242188, 'learning_rate': 8.70870870870871e-06, 'epoch': 0.58, 'iter_time': 0.1233141865841178, 'flops': 17805476183830.984, 'remaining_time': 107.28334232818248}\n",
            "DEBUG:__main__:Step (131) Logs: {'loss': 3.156, 'grad_norm': 63.00213623046875, 'learning_rate': 8.6986986986987e-06, 'epoch': 0.58, 'iter_time': 0.12322936608241154, 'flops': 17817731942917.023, 'remaining_time': 107.08631912561563}\n",
            "DEBUG:__main__:Step (132) Logs: {'loss': 3.3465, 'grad_norm': 78.04739379882812, 'learning_rate': 8.688688688688689e-06, 'epoch': 0.59, 'iter_time': 0.12313792359737949, 'flops': 17830963428708.703, 'remaining_time': 106.8837176825254}\n",
            "DEBUG:__main__:Step (133) Logs: {'loss': 2.7285, 'grad_norm': 56.30198287963867, 'learning_rate': 8.67867867867868e-06, 'epoch': 0.59, 'iter_time': 0.12304343779881795, 'flops': 17844655933151.223, 'remaining_time': 106.67866057157516}\n",
            "DEBUG:__main__:Step (134) Logs: {'loss': 3.3515, 'grad_norm': 61.401912689208984, 'learning_rate': 8.668668668668669e-06, 'epoch': 0.6, 'iter_time': 0.12296867370605469, 'flops': 17855505359035.93, 'remaining_time': 106.49087142944336}\n",
            "DEBUG:__main__:Step (135) Logs: {'loss': 3.1684, 'grad_norm': 52.88771057128906, 'learning_rate': 8.65865865865866e-06, 'epoch': 0.6, 'iter_time': 0.12287547695102977, 'flops': 17869048135837.973, 'remaining_time': 106.28728756264074}\n",
            "DEBUG:__main__:Step (136) Logs: {'loss': 2.8839, 'grad_norm': 51.81501007080078, 'learning_rate': 8.64864864864865e-06, 'epoch': 0.6, 'iter_time': 0.12277698870058414, 'flops': 17883382184153.16, 'remaining_time': 106.07931823730469}\n",
            "DEBUG:__main__:Step (137) Logs: {'loss': 3.9601, 'grad_norm': 64.8337173461914, 'learning_rate': 8.638638638638639e-06, 'epoch': 0.61, 'iter_time': 0.12268282034817864, 'flops': 17897109033853.387, 'remaining_time': 105.87527396047817}\n",
            "DEBUG:__main__:Step (138) Logs: {'loss': 3.3711, 'grad_norm': 61.46943664550781, 'learning_rate': 8.62862862862863e-06, 'epoch': 0.61, 'iter_time': 0.12261082134107604, 'flops': 17907618498404.316, 'remaining_time': 105.69052799600755}\n",
            "DEBUG:__main__:Step (139) Logs: {'loss': 3.2493, 'grad_norm': 71.14653015136719, 'learning_rate': 8.618618618618619e-06, 'epoch': 0.62, 'iter_time': 0.12252740410790927, 'flops': 17919810089327.336, 'remaining_time': 105.49609493690988}\n",
            "DEBUG:__main__:Step (140) Logs: {'loss': 3.2763, 'grad_norm': 77.3976058959961, 'learning_rate': 8.60860860860861e-06, 'epoch': 0.62, 'iter_time': 0.12243581847321215, 'flops': 17933214640390.484, 'remaining_time': 105.29480388696246}\n",
            "DEBUG:__main__:Step (141) Logs: {'loss': 2.8318, 'grad_norm': 44.367393493652344, 'learning_rate': 8.5985985985986e-06, 'epoch': 0.63, 'iter_time': 0.12234548330307007, 'flops': 17946455832071.598, 'remaining_time': 105.0947701573372}\n",
            "DEBUG:__main__:Step (142) Logs: {'loss': 3.2515, 'grad_norm': 81.36382293701172, 'learning_rate': 8.588588588588589e-06, 'epoch': 0.63, 'iter_time': 0.12226576331659411, 'flops': 17958157318877.184, 'remaining_time': 104.90402492563774}\n",
            "DEBUG:__main__:Step (143) Logs: {'loss': 3.0101, 'grad_norm': 63.499755859375, 'learning_rate': 8.57857857857858e-06, 'epoch': 0.64, 'iter_time': 0.12217394398971343, 'flops': 17971653698409.43, 'remaining_time': 104.70306999918441}\n",
            "DEBUG:__main__:Step (144) Logs: {'loss': 2.8866, 'grad_norm': 59.47566223144531, 'learning_rate': 8.568568568568569e-06, 'epoch': 0.64, 'iter_time': 0.12209241206829365, 'flops': 17983654963945.1, 'remaining_time': 104.51110473045937}\n",
            "DEBUG:__main__:Step (145) Logs: {'loss': 2.9297, 'grad_norm': 71.25533294677734, 'learning_rate': 8.55855855855856e-06, 'epoch': 0.64, 'iter_time': 0.1220242910914951, 'flops': 17993694474370.395, 'remaining_time': 104.3307688832283}\n",
            "DEBUG:__main__:Step (146) Logs: {'loss': 2.7451, 'grad_norm': 48.70436477661133, 'learning_rate': 8.54854854854855e-06, 'epoch': 0.65, 'iter_time': 0.12194376485101108, 'flops': 18005576710171.54, 'remaining_time': 104.13997518276346}\n",
            "DEBUG:__main__:Step (147) Logs: {'loss': 3.1957, 'grad_norm': 64.83050537109375, 'learning_rate': 8.538538538538539e-06, 'epoch': 0.65, 'iter_time': 0.12185613259877244, 'flops': 18018525334145.707, 'remaining_time': 103.94328110675289}\n",
            "DEBUG:__main__:Step (148) Logs: {'loss': 3.9341, 'grad_norm': 77.88224029541016, 'learning_rate': 8.52852852852853e-06, 'epoch': 0.66, 'iter_time': 0.12179185419666524, 'flops': 18028035017896.29, 'remaining_time': 103.7666597755588}\n",
            "DEBUG:__main__:Step (149) Logs: {'loss': 3.3808, 'grad_norm': 57.01641845703125, 'learning_rate': 8.518518518518519e-06, 'epoch': 0.66, 'iter_time': 0.12172427692928829, 'flops': 18038043582937.043, 'remaining_time': 103.58735966682434}\n",
            "DEBUG:__main__:Step (150) Logs: {'loss': 3.455, 'grad_norm': 55.011329650878906, 'learning_rate': 8.50850850850851e-06, 'epoch': 0.67, 'iter_time': 0.12164931649329679, 'flops': 18049158644249.246, 'remaining_time': 103.40191901930227}\n",
            "DEBUG:__main__:Step (151) Logs: {'loss': 2.7555, 'grad_norm': 57.1845703125, 'learning_rate': 8.4984984984985e-06, 'epoch': 0.67, 'iter_time': 0.12157159646352132, 'flops': 18060697368655.766, 'remaining_time': 103.21428539752961}\n",
            "DEBUG:__main__:Step (152) Logs: {'loss': 2.8682, 'grad_norm': 65.48773193359375, 'learning_rate': 8.488488488488489e-06, 'epoch': 0.68, 'iter_time': 0.12149141640063153, 'flops': 18072616793860.89, 'remaining_time': 103.02472110773554}\n",
            "DEBUG:__main__:Step (153) Logs: {'loss': 2.9986, 'grad_norm': 61.142333984375, 'learning_rate': 8.47847847847848e-06, 'epoch': 0.68, 'iter_time': 0.1214312565954108, 'flops': 18081570379096.117, 'remaining_time': 102.85227433631295}\n",
            "DEBUG:__main__:Step (154) Logs: {'loss': 3.1034, 'grad_norm': 54.72853469848633, 'learning_rate': 8.46846846846847e-06, 'epoch': 0.68, 'iter_time': 0.12135675841686773, 'flops': 18092670247583.16, 'remaining_time': 102.66781762067009}\n",
            "DEBUG:__main__:Step (155) Logs: {'loss': 2.7962, 'grad_norm': 43.19428634643555, 'learning_rate': 8.45845845845846e-06, 'epoch': 0.69, 'iter_time': 0.12128442758089536, 'flops': 18103460239258.777, 'remaining_time': 102.48534130585658}\n",
            "DEBUG:__main__:Step (156) Logs: {'loss': 2.4557, 'grad_norm': 59.883697509765625, 'learning_rate': 8.44844844844845e-06, 'epoch': 0.69, 'iter_time': 0.12121695241620464, 'flops': 18113537492784.52, 'remaining_time': 102.30710783927672}\n",
            "DEBUG:__main__:Step (157) Logs: {'loss': 3.3466, 'grad_norm': 79.66273498535156, 'learning_rate': 8.438438438438439e-06, 'epoch': 0.7, 'iter_time': 0.1211709731664413, 'flops': 18120410812711.848, 'remaining_time': 102.14713037931003}\n",
            "DEBUG:__main__:Step (158) Logs: {'loss': 2.84, 'grad_norm': 63.120445251464844, 'learning_rate': 8.428428428428428e-06, 'epoch': 0.7, 'iter_time': 0.12110643629815168, 'flops': 18130067067174.613, 'remaining_time': 101.97161936304371}\n",
            "DEBUG:__main__:Step (159) Logs: {'loss': 3.3291, 'grad_norm': 58.93048095703125, 'learning_rate': 8.41841841841842e-06, 'epoch': 0.71, 'iter_time': 0.12104397785814502, 'flops': 18139422143951.41, 'remaining_time': 101.79798537869996}\n",
            "DEBUG:__main__:Step (160) Logs: {'loss': 3.4501, 'grad_norm': 92.73065948486328, 'learning_rate': 8.408408408408409e-06, 'epoch': 0.71, 'iter_time': 0.12098844996038473, 'flops': 18147747269023.844, 'remaining_time': 101.63029796672318}\n",
            "DEBUG:__main__:Step (161) Logs: {'loss': 2.6231, 'grad_norm': 60.86150360107422, 'learning_rate': 8.398398398398398e-06, 'epoch': 0.72, 'iter_time': 0.12092437744140624, 'flops': 18157362963608.46, 'remaining_time': 101.45555267333984}\n",
            "DEBUG:__main__:Step (162) Logs: {'loss': 3.1234, 'grad_norm': 63.59649658203125, 'learning_rate': 8.388388388388389e-06, 'epoch': 0.72, 'iter_time': 0.12085517148793855, 'flops': 18167760513013.13, 'remaining_time': 101.2766337068925}\n",
            "DEBUG:__main__:Step (163) Logs: {'loss': 3.1536, 'grad_norm': 102.83714294433594, 'learning_rate': 8.378378378378378e-06, 'epoch': 0.72, 'iter_time': 0.12078510243215679, 'flops': 18178299874235.52, 'remaining_time': 101.09713073571523}\n",
            "DEBUG:__main__:Step (164) Logs: {'loss': 2.8414, 'grad_norm': 84.5914077758789, 'learning_rate': 8.36836836836837e-06, 'epoch': 0.73, 'iter_time': 0.12071837238007528, 'flops': 18188348376989.863, 'remaining_time': 100.92055930974294}\n",
            "DEBUG:__main__:Step (165) Logs: {'loss': 3.4764, 'grad_norm': 73.51972198486328, 'learning_rate': 8.358358358358359e-06, 'epoch': 0.73, 'iter_time': 0.1206614811245988, 'flops': 18196924087851.08, 'remaining_time': 100.75233673904}\n",
            "DEBUG:__main__:Step (166) Logs: {'loss': 3.7495, 'grad_norm': 59.423065185546875, 'learning_rate': 8.348348348348348e-06, 'epoch': 0.74, 'iter_time': 0.1206035194974957, 'flops': 18205669465538.21, 'remaining_time': 100.58333526091141}\n",
            "DEBUG:__main__:Step (167) Logs: {'loss': 4.0468, 'grad_norm': 73.54756164550781, 'learning_rate': 8.338338338338339e-06, 'epoch': 0.74, 'iter_time': 0.12055042852838356, 'flops': 18213687327001.336, 'remaining_time': 100.4185069641435}\n",
            "DEBUG:__main__:Step (168) Logs: {'loss': 3.2475, 'grad_norm': 58.892311096191406, 'learning_rate': 8.328328328328328e-06, 'epoch': 0.75, 'iter_time': 0.12048978577117006, 'flops': 18222854313326.895, 'remaining_time': 100.24750176161349}\n",
            "DEBUG:__main__:Step (169) Logs: {'loss': 3.3414, 'grad_norm': 59.43099594116211, 'learning_rate': 8.31831831831832e-06, 'epoch': 0.75, 'iter_time': 0.12043161193529765, 'flops': 18231656764103.023, 'remaining_time': 100.07866951823235}\n",
            "DEBUG:__main__:Step (170) Logs: {'loss': 2.2145, 'grad_norm': 72.30404663085938, 'learning_rate': 8.308308308308309e-06, 'epoch': 0.76, 'iter_time': 0.12037654318047698, 'flops': 18239997214906.73, 'remaining_time': 99.91253083979589}\n",
            "DEBUG:__main__:Step (171) Logs: {'loss': 2.7106, 'grad_norm': 45.073265075683594, 'learning_rate': 8.298298298298298e-06, 'epoch': 0.76, 'iter_time': 0.12032638577853932, 'flops': 18247600458914.523, 'remaining_time': 99.7505738104091}\n",
            "DEBUG:__main__:Step (172) Logs: {'loss': 1.9981, 'grad_norm': 53.17842102050781, 'learning_rate': 8.288288288288289e-06, 'epoch': 0.76, 'iter_time': 0.1202797750283403, 'flops': 18254671758694.74, 'remaining_time': 99.59165372346577}\n",
            "DEBUG:__main__:Step (173) Logs: {'loss': 3.3917, 'grad_norm': 53.84815979003906, 'learning_rate': 8.278278278278278e-06, 'epoch': 0.77, 'iter_time': 0.12022579547970794, 'flops': 18262867827916.273, 'remaining_time': 99.42673286171846}\n",
            "DEBUG:__main__:Step (174) Logs: {'loss': 3.6135, 'grad_norm': 54.74150466918945, 'learning_rate': 8.26826826826827e-06, 'epoch': 0.77, 'iter_time': 0.12017683073275351, 'flops': 18270308835441.633, 'remaining_time': 99.2660621852544}\n",
            "DEBUG:__main__:Step (175) Logs: {'loss': 2.3415, 'grad_norm': 46.8516960144043, 'learning_rate': 8.258258258258259e-06, 'epoch': 0.78, 'iter_time': 0.12012056646675899, 'flops': 18278866616564.016, 'remaining_time': 99.09946733507617}\n",
            "DEBUG:__main__:Step (176) Logs: {'loss': 3.9605, 'grad_norm': 75.69011688232422, 'learning_rate': 8.248248248248248e-06, 'epoch': 0.78, 'iter_time': 0.12006907463073731, 'flops': 18286705540994.617, 'remaining_time': 98.93691749572754}\n",
            "DEBUG:__main__:Step (177) Logs: {'loss': 2.5277, 'grad_norm': 51.05439758300781, 'learning_rate': 8.23823823823824e-06, 'epoch': 0.79, 'iter_time': 0.12001193247058174, 'flops': 18295412524002.305, 'remaining_time': 98.76982042328878}\n",
            "DEBUG:__main__:Step (178) Logs: {'loss': 2.4311, 'grad_norm': 43.74039077758789, 'learning_rate': 8.228228228228229e-06, 'epoch': 0.79, 'iter_time': 0.11996635205328128, 'flops': 18302363744267.45, 'remaining_time': 98.61234138779722}\n",
            "DEBUG:__main__:Step (179) Logs: {'loss': 2.8929, 'grad_norm': 54.49701690673828, 'learning_rate': 8.21821821821822e-06, 'epoch': 0.8, 'iter_time': 0.11991369322444616, 'flops': 18310401033535.85, 'remaining_time': 98.4491421372703}\n",
            "DEBUG:__main__:Step (180) Logs: {'loss': 2.6262, 'grad_norm': 44.48115921020508, 'learning_rate': 8.208208208208209e-06, 'epoch': 0.8, 'iter_time': 0.11986956250068195, 'flops': 18317142121374.71, 'remaining_time': 98.2930412505592}\n",
            "DEBUG:__main__:Step (181) Logs: {'loss': 3.8435, 'grad_norm': 59.15278244018555, 'learning_rate': 8.198198198198198e-06, 'epoch': 0.8, 'iter_time': 0.11981848345862495, 'flops': 18324950783659.316, 'remaining_time': 98.13133795261383}\n",
            "DEBUG:__main__:Step (182) Logs: {'loss': 3.3657, 'grad_norm': 92.86349487304688, 'learning_rate': 8.18818818818819e-06, 'epoch': 0.81, 'iter_time': 0.11976314381341249, 'flops': 18333418299145.41, 'remaining_time': 97.96625163937142}\n",
            "DEBUG:__main__:Step (183) Logs: {'loss': 3.5179, 'grad_norm': 69.80686950683594, 'learning_rate': 8.178178178178179e-06, 'epoch': 0.81, 'iter_time': 0.11971999655713092, 'flops': 18340025689060.367, 'remaining_time': 97.81123718717596}\n",
            "DEBUG:__main__:Step (184) Logs: {'loss': 3.5566, 'grad_norm': 57.84541320800781, 'learning_rate': 8.16816816816817e-06, 'epoch': 0.82, 'iter_time': 0.11966436808226538, 'flops': 18348551432140.18, 'remaining_time': 97.64612435512855}\n",
            "DEBUG:__main__:Step (185) Logs: {'loss': 2.7277, 'grad_norm': 51.88428497314453, 'learning_rate': 8.158158158158159e-06, 'epoch': 0.82, 'iter_time': 0.11962078058201334, 'flops': 18355237289616.46, 'remaining_time': 97.49093617434087}\n",
            "DEBUG:__main__:Step (186) Logs: {'loss': 3.4601, 'grad_norm': 82.99092864990234, 'learning_rate': 8.148148148148148e-06, 'epoch': 0.83, 'iter_time': 0.11956649084348936, 'flops': 18363571573126.574, 'remaining_time': 97.32712354660033}\n",
            "DEBUG:__main__:Step (187) Logs: {'loss': 3.3913, 'grad_norm': 65.5511245727539, 'learning_rate': 8.13813813813814e-06, 'epoch': 0.83, 'iter_time': 0.11953212112508795, 'flops': 18368851750353.18, 'remaining_time': 97.17961447469649}\n",
            "DEBUG:__main__:Step (188) Logs: {'loss': 2.5115, 'grad_norm': 60.051971435546875, 'learning_rate': 8.128128128128129e-06, 'epoch': 0.84, 'iter_time': 0.11950045218442214, 'flops': 18373719699097.703, 'remaining_time': 97.03436717375078}\n",
            "DEBUG:__main__:Step (189) Logs: {'loss': 3.0915, 'grad_norm': 62.46674728393555, 'learning_rate': 8.11811811811812e-06, 'epoch': 0.84, 'iter_time': 0.11945385374921433, 'flops': 18380887208224.05, 'remaining_time': 96.87707539061282}\n",
            "DEBUG:__main__:Step (190) Logs: {'loss': 3.4039, 'grad_norm': 59.62894821166992, 'learning_rate': 8.108108108108109e-06, 'epoch': 0.84, 'iter_time': 0.11940560391340306, 'flops': 18388314621685.36, 'remaining_time': 96.71853916985648}\n",
            "DEBUG:__main__:Step (191) Logs: {'loss': 2.8348, 'grad_norm': 72.44818878173828, 'learning_rate': 8.098098098098098e-06, 'epoch': 0.85, 'iter_time': 0.11935925860154001, 'flops': 18395454513351.6, 'remaining_time': 96.56164020864587}\n",
            "DEBUG:__main__:Step (192) Logs: {'loss': 2.4825, 'grad_norm': 60.14680480957031, 'learning_rate': 8.088088088088088e-06, 'epoch': 0.85, 'iter_time': 0.11931063367434197, 'flops': 18402951562096.88, 'remaining_time': 96.40299200886831}\n",
            "DEBUG:__main__:Step (193) Logs: {'loss': 1.8971, 'grad_norm': 47.05052947998047, 'learning_rate': 8.078078078078079e-06, 'epoch': 0.86, 'iter_time': 0.11925932889183362, 'flops': 18410868422238.37, 'remaining_time': 96.24227841570973}\n",
            "DEBUG:__main__:Step (194) Logs: {'loss': 3.151, 'grad_norm': 56.34596252441406, 'learning_rate': 8.06806806806807e-06, 'epoch': 0.86, 'iter_time': 0.1192254365417006, 'flops': 18416102100695.914, 'remaining_time': 96.09570185261069}\n",
            "DEBUG:__main__:Step (195) Logs: {'loss': 3.3557, 'grad_norm': 75.6905288696289, 'learning_rate': 8.058058058058059e-06, 'epoch': 0.87, 'iter_time': 0.11918720142128542, 'flops': 18422009965575.715, 'remaining_time': 95.94569714413475}\n",
            "DEBUG:__main__:Step (196) Logs: {'loss': 2.6198, 'grad_norm': 42.24513626098633, 'learning_rate': 8.048048048048048e-06, 'epoch': 0.87, 'iter_time': 0.11917913877047025, 'flops': 18423256242694.332, 'remaining_time': 95.82002757145808}\n",
            "DEBUG:__main__:Step (197) Logs: {'loss': 3.432, 'grad_norm': 70.95976257324219, 'learning_rate': 8.038038038038038e-06, 'epoch': 0.88, 'iter_time': 0.11914821911831291, 'flops': 18428037184271.51, 'remaining_time': 95.67601995200528}\n",
            "DEBUG:__main__:Step (198) Logs: {'loss': 2.1224, 'grad_norm': 54.42572021484375, 'learning_rate': 8.028028028028029e-06, 'epoch': 0.88, 'iter_time': 0.11910621526882734, 'flops': 18434535992905.934, 'remaining_time': 95.52318464559953}\n",
            "DEBUG:__main__:Step (199) Logs: {'loss': 2.5219, 'grad_norm': 63.59253692626953, 'learning_rate': 8.018018018018018e-06, 'epoch': 0.88, 'iter_time': 0.11906825412403453, 'flops': 18440413261327.844, 'remaining_time': 95.37367155335166}\n",
            "DEBUG:__main__:Step (200) Logs: {'loss': 3.425, 'grad_norm': 81.82669830322266, 'learning_rate': 8.00800800800801e-06, 'epoch': 0.89, 'iter_time': 0.11903637977101696, 'flops': 18445351047937.383, 'remaining_time': 95.22910381681356}\n",
            "DEBUG:__main__:Step (201) Logs: {'loss': 1.8976, 'grad_norm': 50.73397445678711, 'learning_rate': 7.997997997997999e-06, 'epoch': 0.89, 'iter_time': 0.11899778723716736, 'flops': 18451333115765.81, 'remaining_time': 95.07923200249672}\n",
            "DEBUG:__main__:Step (202) Logs: {'loss': 2.9771, 'grad_norm': 56.737342834472656, 'learning_rate': 7.987987987987988e-06, 'epoch': 0.9, 'iter_time': 0.11895110713901805, 'flops': 18458573990285.984, 'remaining_time': 94.9229834969364}\n",
            "DEBUG:__main__:Step (203) Logs: {'loss': 2.9178, 'grad_norm': 110.73954772949219, 'learning_rate': 7.977977977977979e-06, 'epoch': 0.9, 'iter_time': 0.1189079237456369, 'flops': 18465277528929.74, 'remaining_time': 94.7696152252726}\n",
            "DEBUG:__main__:Step (204) Logs: {'loss': 2.89, 'grad_norm': 59.37161636352539, 'learning_rate': 7.967967967967968e-06, 'epoch': 0.91, 'iter_time': 0.11886499667989797, 'flops': 18471946104242.17, 'remaining_time': 94.61653735719878}\n",
            "DEBUG:__main__:Step (205) Logs: {'loss': 2.7118, 'grad_norm': 47.44810104370117, 'learning_rate': 7.95795795795796e-06, 'epoch': 0.91, 'iter_time': 0.11882397474027147, 'flops': 18478323226868.547, 'remaining_time': 94.46505991851582}\n",
            "DEBUG:__main__:Step (206) Logs: {'loss': 3.9026, 'grad_norm': 82.38681030273438, 'learning_rate': 7.947947947947949e-06, 'epoch': 0.92, 'iter_time': 0.11878343907798208, 'flops': 18484629081252.06, 'remaining_time': 94.31405062791778}\n",
            "DEBUG:__main__:Step (207) Logs: {'loss': 3.0046, 'grad_norm': 52.131126403808594, 'learning_rate': 7.937937937937938e-06, 'epoch': 0.92, 'iter_time': 0.11876028834037411, 'flops': 18488232413675.895, 'remaining_time': 94.17690865391667}\n",
            "DEBUG:__main__:Step (208) Logs: {'loss': 3.1112, 'grad_norm': 59.76778793334961, 'learning_rate': 7.927927927927929e-06, 'epoch': 0.92, 'iter_time': 0.1187295821553843, 'flops': 18493013893357.06, 'remaining_time': 94.03382906706437}\n",
            "DEBUG:__main__:Step (209) Logs: {'loss': 3.7325, 'grad_norm': 66.43669891357422, 'learning_rate': 7.917917917917918e-06, 'epoch': 0.93, 'iter_time': 0.11868846416473389, 'flops': 18499420544396.957, 'remaining_time': 93.8825751543045}\n",
            "DEBUG:__main__:Step (210) Logs: {'loss': 3.0955, 'grad_norm': 55.453086853027344, 'learning_rate': 7.90790790790791e-06, 'epoch': 0.93, 'iter_time': 0.11865162164971019, 'flops': 18505164799467.9, 'remaining_time': 93.73478110327105}\n",
            "DEBUG:__main__:Step (211) Logs: {'loss': 2.9114, 'grad_norm': 65.92420196533203, 'learning_rate': 7.897897897897899e-06, 'epoch': 0.94, 'iter_time': 0.11861514250437419, 'flops': 18510855915980.797, 'remaining_time': 93.58734743595123}\n",
            "DEBUG:__main__:Step (212) Logs: {'loss': 2.4969, 'grad_norm': 285.45294189453125, 'learning_rate': 7.887887887887888e-06, 'epoch': 0.94, 'iter_time': 0.11858412213800078, 'flops': 18515698162329.18, 'remaining_time': 93.44428824474461}\n",
            "DEBUG:__main__:Step (213) Logs: {'loss': 2.3099, 'grad_norm': 84.37510681152344, 'learning_rate': 7.877877877877879e-06, 'epoch': 0.95, 'iter_time': 0.11855186718814778, 'flops': 18520735813189.383, 'remaining_time': 93.3003194770723}\n",
            "DEBUG:__main__:Step (214) Logs: {'loss': 2.9748, 'grad_norm': 47.232521057128906, 'learning_rate': 7.867867867867868e-06, 'epoch': 0.95, 'iter_time': 0.11852428051227695, 'flops': 18525046537823.69, 'remaining_time': 93.16008448264968}\n",
            "DEBUG:__main__:Step (215) Logs: {'loss': 3.3433, 'grad_norm': 64.75787353515625, 'learning_rate': 7.85785785785786e-06, 'epoch': 0.96, 'iter_time': 0.11851298697640962, 'flops': 18526811857244.426, 'remaining_time': 93.03269477648155}\n",
            "DEBUG:__main__:Step (216) Logs: {'loss': 2.8033, 'grad_norm': 48.89570617675781, 'learning_rate': 7.847847847847849e-06, 'epoch': 0.96, 'iter_time': 0.11847817509673363, 'flops': 18532255502410.53, 'remaining_time': 92.88688927583917}\n",
            "DEBUG:__main__:Step (217) Logs: {'loss': 2.5069, 'grad_norm': 46.786865234375, 'learning_rate': 7.837837837837838e-06, 'epoch': 0.96, 'iter_time': 0.11843997240066528, 'flops': 18538233063111.273, 'remaining_time': 92.73849838972092}\n",
            "DEBUG:__main__:Step (218) Logs: {'loss': 2.8268, 'grad_norm': 64.13217163085938, 'learning_rate': 7.827827827827829e-06, 'epoch': 0.97, 'iter_time': 0.11839896083427465, 'flops': 18544654419943.09, 'remaining_time': 92.58798737240278}\n",
            "DEBUG:__main__:Step (219) Logs: {'loss': 3.3969, 'grad_norm': 55.913673400878906, 'learning_rate': 7.817817817817818e-06, 'epoch': 0.97, 'iter_time': 0.11835943886993128, 'flops': 18550846753885.72, 'remaining_time': 92.43872175741633}\n",
            "DEBUG:__main__:Step (220) Logs: {'loss': 3.1246, 'grad_norm': 59.88570785522461, 'learning_rate': 7.807807807807808e-06, 'epoch': 0.98, 'iter_time': 0.11831998498472449, 'flops': 18557032547252.844, 'remaining_time': 92.2895882880851}\n",
            "DEBUG:__main__:Step (221) Logs: {'loss': 2.9163, 'grad_norm': 55.32223129272461, 'learning_rate': 7.797797797797799e-06, 'epoch': 0.98, 'iter_time': 0.11828495155681264, 'flops': 18562528736357.59, 'remaining_time': 92.14397726275705}\n",
            "DEBUG:__main__:Step (222) Logs: {'loss': 3.0288, 'grad_norm': 54.65401840209961, 'learning_rate': 7.787787787787788e-06, 'epoch': 0.99, 'iter_time': 0.118272530007686, 'flops': 18564478262275.387, 'remaining_time': 92.0160283459797}\n",
            "DEBUG:__main__:Step (223) Logs: {'loss': 2.7293, 'grad_norm': 50.44942092895508, 'learning_rate': 7.77777777777778e-06, 'epoch': 0.99, 'iter_time': 0.11824139174040374, 'flops': 18569367122915.285, 'remaining_time': 91.8735613822937}\n",
            "DEBUG:__main__:Step (224) Logs: {'loss': 2.7549, 'grad_norm': 52.94789505004883, 'learning_rate': 7.767767767767769e-06, 'epoch': 1.0, 'iter_time': 0.11820502559165784, 'flops': 18575080047247.637, 'remaining_time': 91.72709985912648}\n",
            "DEBUG:__main__:Step (225) Logs: {'loss': 3.0857, 'grad_norm': 55.133487701416016, 'learning_rate': 7.757757757757758e-06, 'epoch': 1.0, 'iter_time': 0.11816756746598653, 'flops': 18580968191496.395, 'remaining_time': 91.57986478613957}\n",
            "DEBUG:__main__:Step (226) Logs: {'loss': 2.405, 'grad_norm': 53.15193176269531, 'learning_rate': 7.747747747747749e-06, 'epoch': 1.0, 'iter_time': 0.11814192983839247, 'flops': 18585000391947.855, 'remaining_time': 91.44185369491578}\n",
            "DEBUG:__main__:Step (227) Logs: {'loss': 2.1052, 'grad_norm': 57.49134826660156, 'learning_rate': 7.737737737737738e-06, 'epoch': 1.01, 'iter_time': 0.11810286277163345, 'flops': 18591148096025.38, 'remaining_time': 91.29351292247266}\n",
            "DEBUG:__main__:Step (228) Logs: {'loss': 2.5449, 'grad_norm': 56.642574310302734, 'learning_rate': 7.72772772772773e-06, 'epoch': 1.01, 'iter_time': 0.11806887677062451, 'flops': 18596499538295.61, 'remaining_time': 91.14917286692213}\n",
            "DEBUG:__main__:Step (229) Logs: {'loss': 2.6235, 'grad_norm': 51.197288513183594, 'learning_rate': 7.717717717717719e-06, 'epoch': 1.02, 'iter_time': 0.1180375709868314, 'flops': 18601431679723.016, 'remaining_time': 91.00696723084701}\n",
            "DEBUG:__main__:Step (230) Logs: {'loss': 2.3788, 'grad_norm': 58.08443069458008, 'learning_rate': 7.707707707707708e-06, 'epoch': 1.02, 'iter_time': 0.11800063437249463, 'flops': 18607254308658.188, 'remaining_time': 90.86048846682087}\n",
            "DEBUG:__main__:Step (231) Logs: {'loss': 1.816, 'grad_norm': 42.560916900634766, 'learning_rate': 7.697697697697697e-06, 'epoch': 1.03, 'iter_time': 0.11799818432849386, 'flops': 18607640658601.188, 'remaining_time': 90.74060374861178}\n",
            "DEBUG:__main__:Step (232) Logs: {'loss': 2.9289, 'grad_norm': 53.07894515991211, 'learning_rate': 7.687687687687688e-06, 'epoch': 1.03, 'iter_time': 0.11796582622445508, 'flops': 18612744746722.453, 'remaining_time': 90.5977545403815}\n",
            "DEBUG:__main__:Step (233) Logs: {'loss': 2.5112, 'grad_norm': 61.515647888183594, 'learning_rate': 7.67767767767768e-06, 'epoch': 1.04, 'iter_time': 0.11793108438623362, 'flops': 18618227957278.97, 'remaining_time': 90.45314172424119}\n",
            "DEBUG:__main__:Step (234) Logs: {'loss': 2.2934, 'grad_norm': 56.86504364013672, 'learning_rate': 7.667667667667669e-06, 'epoch': 1.04, 'iter_time': 0.11790415657436387, 'flops': 18622480124075.695, 'remaining_time': 90.31458393596273}\n",
            "DEBUG:__main__:Step (235) Logs: {'loss': 2.6565, 'grad_norm': 46.500667572021484, 'learning_rate': 7.657657657657658e-06, 'epoch': 1.04, 'iter_time': 0.11787495348188612, 'flops': 18627093776027.74, 'remaining_time': 90.17433941364288}\n",
            "DEBUG:__main__:Step (236) Logs: {'loss': 2.9219, 'grad_norm': 49.75968933105469, 'learning_rate': 7.647647647647647e-06, 'epoch': 1.05, 'iter_time': 0.11784365633700757, 'flops': 18632040795415.082, 'remaining_time': 90.03255344147378}\n",
            "DEBUG:__main__:Step (237) Logs: {'loss': 2.1249, 'grad_norm': 56.32727813720703, 'learning_rate': 7.637637637637638e-06, 'epoch': 1.05, 'iter_time': 0.11781566324880567, 'flops': 18636467782005.7, 'remaining_time': 89.89335105883873}\n",
            "DEBUG:__main__:Step (238) Logs: {'loss': 2.2662, 'grad_norm': 48.73359680175781, 'learning_rate': 7.6276276276276285e-06, 'epoch': 1.06, 'iter_time': 0.11778453533156512, 'flops': 18641392999269.082, 'remaining_time': 89.75181592265263}\n",
            "DEBUG:__main__:Step (239) Logs: {'loss': 1.729, 'grad_norm': 53.15593338012695, 'learning_rate': 7.617617617617619e-06, 'epoch': 1.06, 'iter_time': 0.1177532362336872, 'flops': 18646347927071.72, 'remaining_time': 89.61021277383597}\n",
            "DEBUG:__main__:Step (240) Logs: {'loss': 2.5731, 'grad_norm': 59.17166519165039, 'learning_rate': 7.607607607607608e-06, 'epoch': 1.07, 'iter_time': 0.11774602195707824, 'flops': 18647490385300.516, 'remaining_time': 89.48697668737947}\n",
            "DEBUG:__main__:Step (240) Logs: {'eval_loss': 2.918529748916626, 'eval_runtime': 0.8285, 'eval_samples_per_second': 120.707, 'eval_steps_per_second': 120.707, 'epoch': 1.07, 'iter_time': 0.12124178898384382, 'flops': 18109826906666.527, 'remaining_time': 92.1437596277213}\n",
            "DEBUG:__main__:Step (241) Logs: {'loss': 2.4124, 'grad_norm': 59.90596008300781, 'learning_rate': 7.597597597597598e-06, 'epoch': 1.07, 'iter_time': 0.12396326859792074, 'flops': 17712245225428.24, 'remaining_time': 94.08812086582185}\n",
            "DEBUG:__main__:Step (242) Logs: {'loss': 2.816, 'grad_norm': 66.85896301269531, 'learning_rate': 7.587587587587588e-06, 'epoch': 1.08, 'iter_time': 0.12391084951978501, 'flops': 17719738189684.633, 'remaining_time': 93.92442393599704}\n",
            "DEBUG:__main__:Step (243) Logs: {'loss': 2.1716, 'grad_norm': 46.54037857055664, 'learning_rate': 7.577577577577579e-06, 'epoch': 1.08, 'iter_time': 0.12385368544208117, 'flops': 17727916650318.656, 'remaining_time': 93.75723987965544}\n",
            "DEBUG:__main__:Step (244) Logs: {'loss': 2.6847, 'grad_norm': 55.68534469604492, 'learning_rate': 7.567567567567569e-06, 'epoch': 1.08, 'iter_time': 0.12379559077353144, 'flops': 17736235988959.41, 'remaining_time': 93.58946662478978}\n",
            "DEBUG:__main__:Step (245) Logs: {'loss': 2.6804, 'grad_norm': 85.47252655029297, 'learning_rate': 7.557557557557558e-06, 'epoch': 1.09, 'iter_time': 0.1237781253017363, 'flops': 17738738626066.426, 'remaining_time': 93.45248460281091}\n",
            "DEBUG:__main__:Step (246) Logs: {'loss': 1.9295, 'grad_norm': 53.79521942138672, 'learning_rate': 7.547547547547548e-06, 'epoch': 1.09, 'iter_time': 0.12372404020659777, 'flops': 17746492991059.895, 'remaining_time': 93.28792631577473}\n",
            "DEBUG:__main__:Step (247) Logs: {'loss': 2.4974, 'grad_norm': 50.18844985961914, 'learning_rate': 7.5375375375375385e-06, 'epoch': 1.1, 'iter_time': 0.1236698268874874, 'flops': 17754272546605.723, 'remaining_time': 93.12337964627801}\n",
            "DEBUG:__main__:Step (248) Logs: {'loss': 2.4877, 'grad_norm': 76.56639862060547, 'learning_rate': 7.527527527527529e-06, 'epoch': 1.1, 'iter_time': 0.12362591650804527, 'flops': 17760578642174.203, 'remaining_time': 92.96668921405005}\n",
            "DEBUG:__main__:Step (249) Logs: {'loss': 2.4287, 'grad_norm': 48.00790786743164, 'learning_rate': 7.517517517517519e-06, 'epoch': 1.11, 'iter_time': 0.12357493273673519, 'flops': 17767906190405.66, 'remaining_time': 92.80477448528812}\n",
            "DEBUG:__main__:Step (250) Logs: {'loss': 2.5763, 'grad_norm': 70.3494873046875, 'learning_rate': 7.507507507507507e-06, 'epoch': 1.11, 'iter_time': 0.12352283316922474, 'flops': 17775400353260.7, 'remaining_time': 92.64212487691856}\n",
            "DEBUG:__main__:Step (251) Logs: {'loss': 2.2123, 'grad_norm': 58.73571014404297, 'learning_rate': 7.4974974974974975e-06, 'epoch': 1.12, 'iter_time': 0.12347180461883545, 'flops': 17782746588422.78, 'remaining_time': 92.48038165950774}\n",
            "DEBUG:__main__:Step (252) Logs: {'loss': 2.5645, 'grad_norm': 55.06093978881836, 'learning_rate': 7.487487487487488e-06, 'epoch': 1.12, 'iter_time': 0.12342318595643062, 'flops': 17789751539286.05, 'remaining_time': 92.3205430954101}\n",
            "DEBUG:__main__:Step (253) Logs: {'loss': 2.8614, 'grad_norm': 86.94307708740234, 'learning_rate': 7.477477477477479e-06, 'epoch': 1.12, 'iter_time': 0.12337052159839207, 'flops': 17797345621181.332, 'remaining_time': 92.15777963399887}\n",
            "DEBUG:__main__:Step (254) Logs: {'loss': 2.389, 'grad_norm': 55.570228576660156, 'learning_rate': 7.467467467467469e-06, 'epoch': 1.13, 'iter_time': 0.12335800747626384, 'flops': 17799151082871.402, 'remaining_time': 92.02507357729283}\n",
            "DEBUG:__main__:Step (255) Logs: {'loss': 2.6332, 'grad_norm': 61.40639877319336, 'learning_rate': 7.457457457457457e-06, 'epoch': 1.13, 'iter_time': 0.1233068319756215, 'flops': 17806538187487.426, 'remaining_time': 91.86358982183802}\n",
            "DEBUG:__main__:Step (256) Logs: {'loss': 2.8767, 'grad_norm': 65.1576919555664, 'learning_rate': 7.447447447447448e-06, 'epoch': 1.14, 'iter_time': 0.12325707977893306, 'flops': 17813725720989.22, 'remaining_time': 91.7032673555262}\n",
            "DEBUG:__main__:Step (257) Logs: {'loss': 1.6137, 'grad_norm': 53.20667266845703, 'learning_rate': 7.437437437437438e-06, 'epoch': 1.14, 'iter_time': 0.1232046727091074, 'flops': 17821303072945.01, 'remaining_time': 91.5410718228668}\n",
            "DEBUG:__main__:Step (258) Logs: {'loss': 2.2158, 'grad_norm': 69.4202880859375, 'learning_rate': 7.427427427427428e-06, 'epoch': 1.15, 'iter_time': 0.12316560652469383, 'flops': 17826955708709.023, 'remaining_time': 91.38888004132282}\n",
            "DEBUG:__main__:Step (259) Logs: {'loss': 1.9412, 'grad_norm': 42.003501892089844, 'learning_rate': 7.417417417417418e-06, 'epoch': 1.15, 'iter_time': 0.12312124588692835, 'flops': 17833378768506.367, 'remaining_time': 91.23284320221391}\n",
            "DEBUG:__main__:Step (260) Logs: {'loss': 2.0143, 'grad_norm': 55.549076080322266, 'learning_rate': 7.4074074074074075e-06, 'epoch': 1.16, 'iter_time': 0.12307739626026522, 'flops': 17839732388463.42, 'remaining_time': 91.07727323259626}\n",
            "DEBUG:__main__:Step (261) Logs: {'loss': 2.4654, 'grad_norm': 47.59748840332031, 'learning_rate': 7.397397397397398e-06, 'epoch': 1.16, 'iter_time': 0.12303228745093713, 'flops': 17846273184407.707, 'remaining_time': 90.92086042624254}\n",
            "DEBUG:__main__:Step (262) Logs: {'loss': 2.2076, 'grad_norm': 62.075069427490234, 'learning_rate': 7.387387387387388e-06, 'epoch': 1.16, 'iter_time': 0.12298265453499396, 'flops': 17853475521844.72, 'remaining_time': 90.76119904682554}\n",
            "DEBUG:__main__:Step (263) Logs: {'loss': 2.2551, 'grad_norm': 60.12742614746094, 'learning_rate': 7.377377377377378e-06, 'epoch': 1.17, 'iter_time': 0.12295462884975754, 'flops': 17857544956969.14, 'remaining_time': 90.61756146227131}\n",
            "DEBUG:__main__:Step (264) Logs: {'loss': 2.3304, 'grad_norm': 56.239105224609375, 'learning_rate': 7.367367367367368e-06, 'epoch': 1.17, 'iter_time': 0.12291088031725285, 'flops': 17863901118311.305, 'remaining_time': 90.4624079134981}\n",
            "DEBUG:__main__:Step (265) Logs: {'loss': 2.5913, 'grad_norm': 57.0100212097168, 'learning_rate': 7.3573573573573575e-06, 'epoch': 1.18, 'iter_time': 0.12286398627541283, 'flops': 17870719312575.246, 'remaining_time': 90.30502991242842}\n",
            "DEBUG:__main__:Step (266) Logs: {'loss': 2.0585, 'grad_norm': 59.54357147216797, 'learning_rate': 7.347347347347348e-06, 'epoch': 1.18, 'iter_time': 0.12281805164409133, 'flops': 17877403060542.945, 'remaining_time': 90.14844990676303}\n",
            "DEBUG:__main__:Step (267) Logs: {'loss': 2.7552, 'grad_norm': 68.87652587890625, 'learning_rate': 7.337337337337338e-06, 'epoch': 1.19, 'iter_time': 0.1227730763585944, 'flops': 17883952064041.426, 'remaining_time': 89.99266497084969}\n",
            "DEBUG:__main__:Step (268) Logs: {'loss': 2.6759, 'grad_norm': 66.68329620361328, 'learning_rate': 7.327327327327328e-06, 'epoch': 1.19, 'iter_time': 0.12272719229651748, 'flops': 17890638344003.773, 'remaining_time': 89.8363047610508}\n",
            "DEBUG:__main__:Step (269) Logs: {'loss': 2.5367, 'grad_norm': 55.71177291870117, 'learning_rate': 7.317317317317318e-06, 'epoch': 1.2, 'iter_time': 0.12267905829557732, 'flops': 17897657863185.242, 'remaining_time': 89.67839161406702}\n",
            "DEBUG:__main__:Step (270) Logs: {'loss': 2.7415, 'grad_norm': 82.37177276611328, 'learning_rate': 7.307307307307308e-06, 'epoch': 1.2, 'iter_time': 0.12263180686638701, 'flops': 17904554034209.746, 'remaining_time': 89.52121901246252}\n",
            "DEBUG:__main__:Step (271) Logs: {'loss': 2.1595, 'grad_norm': 49.54168701171875, 'learning_rate': 7.297297297297298e-06, 'epoch': 1.2, 'iter_time': 0.12258271552898266, 'flops': 17911724364050.906, 'remaining_time': 89.36279962062835}\n",
            "DEBUG:__main__:Step (272) Logs: {'loss': 2.596, 'grad_norm': 57.86631393432617, 'learning_rate': 7.287287287287288e-06, 'epoch': 1.21, 'iter_time': 0.12256714250768683, 'flops': 17914000175163.57, 'remaining_time': 89.228879745596}\n",
            "DEBUG:__main__:Step (273) Logs: {'loss': 2.3639, 'grad_norm': 68.20103454589844, 'learning_rate': 7.277277277277278e-06, 'epoch': 1.21, 'iter_time': 0.12252800166606903, 'flops': 17919722696008.3, 'remaining_time': 89.07785721123219}\n",
            "DEBUG:__main__:Step (274) Logs: {'loss': 2.0843, 'grad_norm': 43.46856689453125, 'learning_rate': 7.267267267267268e-06, 'epoch': 1.22, 'iter_time': 0.1224886165870415, 'flops': 17925484616701.008, 'remaining_time': 88.92673564219213}\n",
            "DEBUG:__main__:Step (275) Logs: {'loss': 2.9091, 'grad_norm': 49.69008255004883, 'learning_rate': 7.257257257257258e-06, 'epoch': 1.22, 'iter_time': 0.12245289600678604, 'flops': 17930713637269.316, 'remaining_time': 88.77834960491988}\n",
            "DEBUG:__main__:Step (276) Logs: {'loss': 1.7796, 'grad_norm': 43.32838439941406, 'learning_rate': 7.247247247247248e-06, 'epoch': 1.23, 'iter_time': 0.12240998441522771, 'flops': 17936999361947.965, 'remaining_time': 88.62482871662486}\n",
            "DEBUG:__main__:Step (277) Logs: {'loss': 2.8493, 'grad_norm': 82.53376007080078, 'learning_rate': 7.237237237237238e-06, 'epoch': 1.23, 'iter_time': 0.1223727974338808, 'flops': 17942450106514.402, 'remaining_time': 88.47553254469582}\n",
            "DEBUG:__main__:Step (278) Logs: {'loss': 1.873, 'grad_norm': 64.0814437866211, 'learning_rate': 7.227227227227228e-06, 'epoch': 1.24, 'iter_time': 0.12234715606331395, 'flops': 17946210463737.746, 'remaining_time': 88.33464667771267}\n",
            "DEBUG:__main__:Step (279) Logs: {'loss': 2.1555, 'grad_norm': 42.73369598388672, 'learning_rate': 7.217217217217218e-06, 'epoch': 1.24, 'iter_time': 0.12231862287727191, 'flops': 17950396764644.89, 'remaining_time': 88.19172709451304}\n",
            "DEBUG:__main__:Step (280) Logs: {'loss': 2.7802, 'grad_norm': 65.59503936767578, 'learning_rate': 7.207207207207208e-06, 'epoch': 1.24, 'iter_time': 0.12228624453254071, 'flops': 17955149581584.598, 'remaining_time': 88.0460960634293}\n",
            "DEBUG:__main__:Step (281) Logs: {'loss': 2.5293, 'grad_norm': 53.27285385131836, 'learning_rate': 7.197197197197198e-06, 'epoch': 1.25, 'iter_time': 0.12224927374294826, 'flops': 17960579602041.63, 'remaining_time': 87.8972278211798}\n",
            "DEBUG:__main__:Step (282) Logs: {'loss': 2.5991, 'grad_norm': 48.46359634399414, 'learning_rate': 7.187187187187188e-06, 'epoch': 1.25, 'iter_time': 0.12224489853475441, 'flops': 17961222420482.18, 'remaining_time': 87.77183714795366}\n",
            "DEBUG:__main__:Step (283) Logs: {'loss': 2.1131, 'grad_norm': 52.31305694580078, 'learning_rate': 7.177177177177178e-06, 'epoch': 1.26, 'iter_time': 0.12221483812264516, 'flops': 17965640228959.77, 'remaining_time': 87.62803893393658}\n",
            "DEBUG:__main__:Step (284) Logs: {'loss': 2.0217, 'grad_norm': 50.16041564941406, 'learning_rate': 7.167167167167167e-06, 'epoch': 1.26, 'iter_time': 0.12217684179649757, 'flops': 17971227444307.23, 'remaining_time': 87.47861872629225}\n",
            "DEBUG:__main__:Step (285) Logs: {'loss': 2.3461, 'grad_norm': 63.49158477783203, 'learning_rate': 7.157157157157158e-06, 'epoch': 1.27, 'iter_time': 0.12214213525745231, 'flops': 17976333946708.492, 'remaining_time': 87.3316267090784}\n",
            "DEBUG:__main__:Step (286) Logs: {'loss': 2.5762, 'grad_norm': 55.11573028564453, 'learning_rate': 7.147147147147148e-06, 'epoch': 1.27, 'iter_time': 0.1221046899494372, 'flops': 17981846669945.375, 'remaining_time': 87.18274862389816}\n",
            "DEBUG:__main__:Step (287) Logs: {'loss': 2.2672, 'grad_norm': 58.05185317993164, 'learning_rate': 7.137137137137138e-06, 'epoch': 1.28, 'iter_time': 0.12207065595613494, 'flops': 17986860111090.047, 'remaining_time': 87.0363776967242}\n",
            "DEBUG:__main__:Step (288) Logs: {'loss': 2.3301, 'grad_norm': 51.777679443359375, 'learning_rate': 7.127127127127128e-06, 'epoch': 1.28, 'iter_time': 0.12203469509031714, 'flops': 17992160432137.758, 'remaining_time': 86.8887029043058}\n",
            "DEBUG:__main__:Step (289) Logs: {'loss': 2.336, 'grad_norm': 52.69462585449219, 'learning_rate': 7.117117117117117e-06, 'epoch': 1.28, 'iter_time': 0.12199266089333428, 'flops': 17998359870777.867, 'remaining_time': 86.73678189516068}\n",
            "DEBUG:__main__:Step (290) Logs: {'loss': 2.5313, 'grad_norm': 86.10975646972656, 'learning_rate': 7.107107107107107e-06, 'epoch': 1.29, 'iter_time': 0.121959128594316, 'flops': 18003308466196.527, 'remaining_time': 86.59098130196436}\n",
            "DEBUG:__main__:Step (291) Logs: {'loss': 2.0772, 'grad_norm': 47.16429901123047, 'learning_rate': 7.097097097097097e-06, 'epoch': 1.29, 'iter_time': 0.12193477482631289, 'flops': 18006904227933.066, 'remaining_time': 86.45175535185584}\n",
            "DEBUG:__main__:Step (292) Logs: {'loss': 3.121, 'grad_norm': 53.10934829711914, 'learning_rate': 7.087087087087087e-06, 'epoch': 1.3, 'iter_time': 0.12190045851612419, 'flops': 18011973368103.22, 'remaining_time': 86.30552462941593}\n",
            "DEBUG:__main__:Step (293) Logs: {'loss': 1.8351, 'grad_norm': 59.83538055419922, 'learning_rate': 7.0770770770770784e-06, 'epoch': 1.3, 'iter_time': 0.12186132555138575, 'flops': 18017757499495.965, 'remaining_time': 86.15595716482973}\n",
            "DEBUG:__main__:Step (294) Logs: {'loss': 1.8528, 'grad_norm': 58.558006286621094, 'learning_rate': 7.067067067067067e-06, 'epoch': 1.31, 'iter_time': 0.12182353950604644, 'flops': 18023346072973.22, 'remaining_time': 86.00741889126878}\n",
            "DEBUG:__main__:Step (295) Logs: {'loss': 2.9176, 'grad_norm': 53.419918060302734, 'learning_rate': 7.057057057057057e-06, 'epoch': 1.31, 'iter_time': 0.12178638354450667, 'flops': 18028844838385.367, 'remaining_time': 85.8594003988772}\n",
            "DEBUG:__main__:Step (296) Logs: {'loss': 2.8996, 'grad_norm': 70.29326629638672, 'learning_rate': 7.047047047047047e-06, 'epoch': 1.32, 'iter_time': 0.12174976720648296, 'flops': 18034267027617.65, 'remaining_time': 85.711836113364}\n",
            "DEBUG:__main__:Step (297) Logs: {'loss': 2.0437, 'grad_norm': 41.153106689453125, 'learning_rate': 7.0370370370370375e-06, 'epoch': 1.32, 'iter_time': 0.1217192806102134, 'flops': 18038784006481.9, 'remaining_time': 85.56865426898003}\n",
            "DEBUG:__main__:Step (298) Logs: {'loss': 2.1902, 'grad_norm': 42.371055603027344, 'learning_rate': 7.027027027027028e-06, 'epoch': 1.32, 'iter_time': 0.12168473828119862, 'flops': 18043904629010.082, 'remaining_time': 85.42268627340142}\n",
            "DEBUG:__main__:Step (299) Logs: {'loss': 1.8443, 'grad_norm': 58.87738037109375, 'learning_rate': 7.017017017017017e-06, 'epoch': 1.33, 'iter_time': 0.12165648905222848, 'flops': 18048094511500.95, 'remaining_time': 85.28119882561217}\n",
            "DEBUG:__main__:Step (300) Logs: {'loss': 1.9437, 'grad_norm': 64.29208374023438, 'learning_rate': 7.007007007007007e-06, 'epoch': 1.33, 'iter_time': 0.12163762822996414, 'flops': 18050893003281.367, 'remaining_time': 85.1463397609749}\n",
            "DEBUG:__main__:Step (301) Logs: {'loss': 2.2286, 'grad_norm': 42.944889068603516, 'learning_rate': 6.996996996996997e-06, 'epoch': 1.34, 'iter_time': 0.12159830729166667, 'flops': 18056730075077.887, 'remaining_time': 84.997216796875}\n",
            "DEBUG:__main__:Step (302) Logs: {'loss': 2.4174, 'grad_norm': 54.42333984375, 'learning_rate': 6.9869869869869876e-06, 'epoch': 1.34, 'iter_time': 0.121559364851131, 'flops': 18062514681949.42, 'remaining_time': 84.84843666608944}\n",
            "DEBUG:__main__:Step (303) Logs: {'loss': 2.7228, 'grad_norm': 74.73959350585938, 'learning_rate': 6.976976976976978e-06, 'epoch': 1.35, 'iter_time': 0.12152061636084753, 'flops': 18068274158782.31, 'remaining_time': 84.69986960351073}\n",
            "DEBUG:__main__:Step (304) Logs: {'loss': 2.2868, 'grad_norm': 48.37367630004883, 'learning_rate': 6.966966966966967e-06, 'epoch': 1.35, 'iter_time': 0.12148380830343014, 'flops': 18073748617329.15, 'remaining_time': 84.55273057918738}\n",
            "DEBUG:__main__:Step (305) Logs: {'loss': 1.8134, 'grad_norm': 50.92813491821289, 'learning_rate': 6.956956956956957e-06, 'epoch': 1.36, 'iter_time': 0.12144673654907628, 'flops': 18079265649635.113, 'remaining_time': 84.40548190160801}\n",
            "DEBUG:__main__:Step (306) Logs: {'loss': 2.8029, 'grad_norm': 54.58119201660156, 'learning_rate': 6.9469469469469474e-06, 'epoch': 1.36, 'iter_time': 0.12140909882842517, 'flops': 18084870356009.383, 'remaining_time': 84.25791458692707}\n",
            "DEBUG:__main__:Step (307) Logs: {'loss': 2.4961, 'grad_norm': 74.33130645751953, 'learning_rate': 6.936936936936938e-06, 'epoch': 1.36, 'iter_time': 0.121371601921281, 'flops': 18090457550161.22, 'remaining_time': 84.11052013144774}\n",
            "DEBUG:__main__:Step (308) Logs: {'loss': 2.2758, 'grad_norm': 59.047279357910156, 'learning_rate': 6.926926926926928e-06, 'epoch': 1.37, 'iter_time': 0.1213340324377004, 'flops': 18096059021852.566, 'remaining_time': 83.96315044688868}\n",
            "DEBUG:__main__:Step (309) Logs: {'loss': 3.2799, 'grad_norm': 92.44387817382812, 'learning_rate': 6.916916916916917e-06, 'epoch': 1.37, 'iter_time': 0.12130628081111165, 'flops': 18100198915264.055, 'remaining_time': 83.82264004047815}\n",
            "DEBUG:__main__:Step (310) Logs: {'loss': 2.7971, 'grad_norm': 83.31153869628906, 'learning_rate': 6.906906906906907e-06, 'epoch': 1.38, 'iter_time': 0.12127934150325442, 'flops': 18104219441965.566, 'remaining_time': 83.68274563724555}\n",
            "DEBUG:__main__:Step (311) Logs: {'loss': 2.5623, 'grad_norm': 58.25346755981445, 'learning_rate': 6.8968968968968975e-06, 'epoch': 1.38, 'iter_time': 0.1212493819575156, 'flops': 18108692818915.457, 'remaining_time': 83.54082416872825}\n",
            "DEBUG:__main__:Step (312) Logs: {'loss': 2.1549, 'grad_norm': 48.84262466430664, 'learning_rate': 6.886886886886888e-06, 'epoch': 1.39, 'iter_time': 0.12121491723505247, 'flops': 18113841616492.605, 'remaining_time': 83.3958630577161}\n",
            "DEBUG:__main__:Step (313) Logs: {'loss': 2.4551, 'grad_norm': 59.393707275390625, 'learning_rate': 6.876876876876878e-06, 'epoch': 1.39, 'iter_time': 0.12117859033437875, 'flops': 18119271781370.79, 'remaining_time': 83.2496915597182}\n",
            "DEBUG:__main__:Step (314) Logs: {'loss': 1.8023, 'grad_norm': 65.22990417480469, 'learning_rate': 6.866866866866867e-06, 'epoch': 1.4, 'iter_time': 0.12114316510697143, 'flops': 18124570300051.09, 'remaining_time': 83.1042112633824}\n",
            "DEBUG:__main__:Step (315) Logs: {'loss': 2.8875, 'grad_norm': 66.13529968261719, 'learning_rate': 6.856856856856857e-06, 'epoch': 1.4, 'iter_time': 0.12110800803846615, 'flops': 18129831775076.47, 'remaining_time': 82.95898550634931}\n",
            "DEBUG:__main__:Step (316) Logs: {'loss': 2.8831, 'grad_norm': 58.79201126098633, 'learning_rate': 6.846846846846848e-06, 'epoch': 1.4, 'iter_time': 0.12107276008242653, 'flops': 18135109919499.53, 'remaining_time': 82.81376789637974}\n",
            "DEBUG:__main__:Step (317) Logs: {'loss': 2.877, 'grad_norm': 52.52479553222656, 'learning_rate': 6.836836836836838e-06, 'epoch': 1.41, 'iter_time': 0.1210379525075985, 'flops': 18140325136565.414, 'remaining_time': 82.66892156268977}\n",
            "DEBUG:__main__:Step (318) Logs: {'loss': 2.6515, 'grad_norm': 65.24302673339844, 'learning_rate': 6.826826826826828e-06, 'epoch': 1.41, 'iter_time': 0.12101383464945603, 'flops': 18143940473518.99, 'remaining_time': 82.53143523092902}\n",
            "DEBUG:__main__:Step (319) Logs: {'loss': 2.0953, 'grad_norm': 39.889827728271484, 'learning_rate': 6.816816816816817e-06, 'epoch': 1.42, 'iter_time': 0.12098049892569487, 'flops': 18148939968420.523, 'remaining_time': 82.38771976839821}\n",
            "DEBUG:__main__:Step (320) Logs: {'loss': 2.2481, 'grad_norm': 66.9882583618164, 'learning_rate': 6.8068068068068075e-06, 'epoch': 1.42, 'iter_time': 0.12094774365798806, 'flops': 18153855094319.37, 'remaining_time': 82.24446568743188}\n",
            "DEBUG:__main__:Step (321) Logs: {'loss': 2.0384, 'grad_norm': 48.14229965209961, 'learning_rate': 6.796796796796798e-06, 'epoch': 1.43, 'iter_time': 0.12091429382562638, 'flops': 18158877192124.44, 'remaining_time': 82.10080550760031}\n",
            "DEBUG:__main__:Step (322) Logs: {'loss': 2.0933, 'grad_norm': 67.04708862304688, 'learning_rate': 6.786786786786788e-06, 'epoch': 1.43, 'iter_time': 0.12088152924059337, 'flops': 18163799102689.297, 'remaining_time': 81.9576768251223}\n",
            "DEBUG:__main__:Step (323) Logs: {'loss': 2.5692, 'grad_norm': 80.49688720703125, 'learning_rate': 6.776776776776778e-06, 'epoch': 1.44, 'iter_time': 0.12084953607239338, 'flops': 18168607706004.87, 'remaining_time': 81.81513592101031}\n",
            "DEBUG:__main__:Step (324) Logs: {'loss': 2.5202, 'grad_norm': 56.23851776123047, 'learning_rate': 6.7667667667667665e-06, 'epoch': 1.44, 'iter_time': 0.12081695783987134, 'flops': 18173506862025.938, 'remaining_time': 81.67226349975303}\n",
            "DEBUG:__main__:Step (325) Logs: {'loss': 2.5003, 'grad_norm': 60.9483757019043, 'learning_rate': 6.7567567567567575e-06, 'epoch': 1.44, 'iter_time': 0.1207831421016175, 'flops': 18178594911074.07, 'remaining_time': 81.52862091859181}\n",
            "DEBUG:__main__:Step (326) Logs: {'loss': 2.8873, 'grad_norm': 78.5687026977539, 'learning_rate': 6.746746746746748e-06, 'epoch': 1.45, 'iter_time': 0.1207551332620474, 'flops': 18182811388955.547, 'remaining_time': 81.38895981861995}\n",
            "DEBUG:__main__:Step (327) Logs: {'loss': 1.9153, 'grad_norm': 59.49421691894531, 'learning_rate': 6.736736736736738e-06, 'epoch': 1.45, 'iter_time': 0.12072707246417648, 'flops': 18187037650594.266, 'remaining_time': 81.24931976839078}\n",
            "DEBUG:__main__:Step (328) Logs: {'loss': 2.082, 'grad_norm': 63.057159423828125, 'learning_rate': 6.726726726726728e-06, 'epoch': 1.46, 'iter_time': 0.12070045267040941, 'flops': 18191048697618.38, 'remaining_time': 81.11070419451512}\n",
            "DEBUG:__main__:Step (329) Logs: {'loss': 2.1145, 'grad_norm': 47.69715881347656, 'learning_rate': 6.716716716716717e-06, 'epoch': 1.46, 'iter_time': 0.12066951466769707, 'flops': 18195712632129.902, 'remaining_time': 80.96924434202474}\n",
            "DEBUG:__main__:Step (330) Logs: {'loss': 2.7573, 'grad_norm': 60.978580474853516, 'learning_rate': 6.706706706706707e-06, 'epoch': 1.47, 'iter_time': 0.12063823644875755, 'flops': 18200430286334.918, 'remaining_time': 80.82761842066756}\n",
            "DEBUG:__main__:Step (331) Logs: {'loss': 2.9955, 'grad_norm': 52.406497955322266, 'learning_rate': 6.696696696696697e-06, 'epoch': 1.47, 'iter_time': 0.12060621723984227, 'flops': 18205262237730.32, 'remaining_time': 80.68555933345448}\n",
            "DEBUG:__main__:Step (332) Logs: {'loss': 2.7439, 'grad_norm': 75.29283142089844, 'learning_rate': 6.686686686686687e-06, 'epoch': 1.48, 'iter_time': 0.1205745658125402, 'flops': 18210041210230.445, 'remaining_time': 80.54380996277685}\n",
            "DEBUG:__main__:Step (333) Logs: {'loss': 3.2948, 'grad_norm': 56.065853118896484, 'learning_rate': 6.676676676676678e-06, 'epoch': 1.48, 'iter_time': 0.12054366088775267, 'flops': 18214709891684.41, 'remaining_time': 80.40262181213103}\n",
            "DEBUG:__main__:Step (334) Logs: {'loss': 3.1257, 'grad_norm': 75.64991760253906, 'learning_rate': 6.666666666666667e-06, 'epoch': 1.48, 'iter_time': 0.12051213467801297, 'flops': 18219474895357.504, 'remaining_time': 80.26108169555664}\n",
            "DEBUG:__main__:Step (335) Logs: {'loss': 3.3627, 'grad_norm': 53.89800262451172, 'learning_rate': 6.656656656656657e-06, 'epoch': 1.49, 'iter_time': 0.12048145182832272, 'flops': 18224114824584.504, 'remaining_time': 80.1201654658346}\n",
            "DEBUG:__main__:Step (336) Logs: {'loss': 1.3993, 'grad_norm': 59.092002868652344, 'learning_rate': 6.646646646646647e-06, 'epoch': 1.49, 'iter_time': 0.12045920001926706, 'flops': 18227481271673.812, 'remaining_time': 79.98490881279334}\n",
            "DEBUG:__main__:Step (337) Logs: {'loss': 1.9265, 'grad_norm': 55.29474639892578, 'learning_rate': 6.636636636636637e-06, 'epoch': 1.5, 'iter_time': 0.1204672363542375, 'flops': 18226265321598.094, 'remaining_time': 79.86977770285947}\n",
            "DEBUG:__main__:Step (338) Logs: {'loss': 2.8771, 'grad_norm': 72.92961883544922, 'learning_rate': 6.626626626626627e-06, 'epoch': 1.5, 'iter_time': 0.12043875756532572, 'flops': 18230575080127.96, 'remaining_time': 79.73045750824564}\n",
            "DEBUG:__main__:Step (339) Logs: {'loss': 1.8864, 'grad_norm': 39.76726150512695, 'learning_rate': 6.616616616616617e-06, 'epoch': 1.51, 'iter_time': 0.12041190672202928, 'flops': 18234640345166.996, 'remaining_time': 79.59227034326136}\n",
            "DEBUG:__main__:Step (340) Logs: {'loss': 1.9131, 'grad_norm': 56.29669952392578, 'learning_rate': 6.606606606606607e-06, 'epoch': 1.51, 'iter_time': 0.120385365500211, 'flops': 18238660515161.633, 'remaining_time': 79.45434123013926}\n",
            "DEBUG:__main__:Step (341) Logs: {'loss': 2.6534, 'grad_norm': 65.01545715332031, 'learning_rate': 6.596596596596597e-06, 'epoch': 1.52, 'iter_time': 0.12035834298414343, 'flops': 18242755407834.65, 'remaining_time': 79.31614802655052}\n",
            "DEBUG:__main__:Step (342) Logs: {'loss': 2.5138, 'grad_norm': 46.98349380493164, 'learning_rate': 6.586586586586587e-06, 'epoch': 1.52, 'iter_time': 0.12033381350229214, 'flops': 18246474107713.51, 'remaining_time': 79.17964928450823}\n",
            "DEBUG:__main__:Step (343) Logs: {'loss': 2.7219, 'grad_norm': 58.96601867675781, 'learning_rate': 6.5765765765765775e-06, 'epoch': 1.52, 'iter_time': 0.12030864040753995, 'flops': 18250291956706.324, 'remaining_time': 79.04277674775375}\n",
            "DEBUG:__main__:Step (344) Logs: {'loss': 2.8486, 'grad_norm': 59.504093170166016, 'learning_rate': 6.566566566566567e-06, 'epoch': 1.53, 'iter_time': 0.12028636946275005, 'flops': 18253670986652.8, 'remaining_time': 78.90785836756403}\n",
            "DEBUG:__main__:Step (345) Logs: {'loss': 2.2057, 'grad_norm': 55.182186126708984, 'learning_rate': 6.556556556556557e-06, 'epoch': 1.53, 'iter_time': 0.12026500701904297, 'flops': 18256913351398.5, 'remaining_time': 78.77357959747314}\n",
            "DEBUG:__main__:Step (346) Logs: {'loss': 1.7941, 'grad_norm': 66.51471710205078, 'learning_rate': 6.546546546546547e-06, 'epoch': 1.54, 'iter_time': 0.12024100483327672, 'flops': 18260557747304.758, 'remaining_time': 78.63761716096298}\n",
            "DEBUG:__main__:Step (347) Logs: {'loss': 3.0943, 'grad_norm': 64.87953186035156, 'learning_rate': 6.536536536536537e-06, 'epoch': 1.54, 'iter_time': 0.1202155951130597, 'flops': 18264417443402.668, 'remaining_time': 78.50078360882799}\n",
            "DEBUG:__main__:Step (348) Logs: {'loss': 2.2625, 'grad_norm': 53.99821853637695, 'learning_rate': 6.526526526526527e-06, 'epoch': 1.55, 'iter_time': 0.12018931083789133, 'flops': 18268411700217.4, 'remaining_time': 78.36343066630515}\n",
            "DEBUG:__main__:Step (349) Logs: {'loss': 2.6225, 'grad_norm': 53.71630859375, 'learning_rate': 6.516516516516517e-06, 'epoch': 1.55, 'iter_time': 0.12016393672460797, 'flops': 18272269303094.133, 'remaining_time': 78.22672280771978}\n",
            "DEBUG:__main__:Step (350) Logs: {'loss': 2.5982, 'grad_norm': 93.86664581298828, 'learning_rate': 6.506506506506507e-06, 'epoch': 1.56, 'iter_time': 0.12013972249618574, 'flops': 18275952089216.03, 'remaining_time': 78.09081962252073}\n",
            "DEBUG:__main__:Step (351) Logs: {'loss': 2.7154, 'grad_norm': 56.35530090332031, 'learning_rate': 6.496496496496497e-06, 'epoch': 1.56, 'iter_time': 0.12011661393301827, 'flops': 18279468097364.035, 'remaining_time': 77.95568244252885}\n",
            "DEBUG:__main__:Step (352) Logs: {'loss': 2.1109, 'grad_norm': 46.02549362182617, 'learning_rate': 6.486486486486487e-06, 'epoch': 1.56, 'iter_time': 0.120089285733693, 'flops': 18283627876853.71, 'remaining_time': 77.81785715543306}\n",
            "DEBUG:__main__:Step (353) Logs: {'loss': 2.7078, 'grad_norm': 106.91314697265625, 'learning_rate': 6.476476476476477e-06, 'epoch': 1.57, 'iter_time': 0.12007159875197844, 'flops': 18286321121511.855, 'remaining_time': 77.68632439253005}\n",
            "DEBUG:__main__:Step (354) Logs: {'loss': 2.5704, 'grad_norm': 60.812782287597656, 'learning_rate': 6.466466466466467e-06, 'epoch': 1.57, 'iter_time': 0.12004718564387422, 'flops': 18290039875366.63, 'remaining_time': 77.55048192594275}\n",
            "DEBUG:__main__:Step (355) Logs: {'loss': 1.8973, 'grad_norm': 50.141605377197266, 'learning_rate': 6.456456456456457e-06, 'epoch': 1.58, 'iter_time': 0.12002601865994728, 'flops': 18293265384172.03, 'remaining_time': 77.41678203566599}\n",
            "DEBUG:__main__:Step (356) Logs: {'loss': 2.276, 'grad_norm': 50.410865783691406, 'learning_rate': 6.446446446446447e-06, 'epoch': 1.58, 'iter_time': 0.1199976383800238, 'flops': 18297591869253.957, 'remaining_time': 77.27847911673533}\n",
            "DEBUG:__main__:Step (357) Logs: {'loss': 2.025, 'grad_norm': 51.85963439941406, 'learning_rate': 6.4364364364364375e-06, 'epoch': 1.59, 'iter_time': 0.11997353494837043, 'flops': 18301267969614.188, 'remaining_time': 77.14298297180218}\n",
            "DEBUG:__main__:Step (358) Logs: {'loss': 2.0634, 'grad_norm': 44.242088317871094, 'learning_rate': 6.426426426426427e-06, 'epoch': 1.59, 'iter_time': 0.11994532710697804, 'flops': 18305571924396.07, 'remaining_time': 77.0049000026799}\n",
            "DEBUG:__main__:Step (359) Logs: {'loss': 2.2672, 'grad_norm': 45.100582122802734, 'learning_rate': 6.416416416416417e-06, 'epoch': 1.6, 'iter_time': 0.11991922282639829, 'flops': 18309556721615.6, 'remaining_time': 76.8682218317213}\n",
            "DEBUG:__main__:Step (360) Logs: {'loss': 2.6375, 'grad_norm': 64.23889923095703, 'learning_rate': 6.406406406406407e-06, 'epoch': 1.6, 'iter_time': 0.11989252613779562, 'flops': 18313633744179.027, 'remaining_time': 76.7312167281892}\n",
            "DEBUG:__main__:Step (360) Logs: {'eval_loss': 2.8833043575286865, 'eval_runtime': 0.8233, 'eval_samples_per_second': 121.456, 'eval_steps_per_second': 121.456, 'epoch': 1.6, 'iter_time': 0.12220364360756197, 'flops': 17967285978829.293, 'remaining_time': 78.21033190883966}\n",
            "DEBUG:__main__:Step (361) Logs: {'loss': 1.8277, 'grad_norm': 52.10296630859375, 'learning_rate': 6.396396396396397e-06, 'epoch': 1.6, 'iter_time': 0.12404232687420315, 'flops': 17700956340320.223, 'remaining_time': 79.26304687261582}\n",
            "DEBUG:__main__:Step (362) Logs: {'loss': 2.4048, 'grad_norm': 63.31590270996094, 'learning_rate': 6.3863863863863875e-06, 'epoch': 1.61, 'iter_time': 0.12401188839835804, 'flops': 17705301005488.69, 'remaining_time': 79.11958479815243}\n",
            "DEBUG:__main__:Step (363) Logs: {'loss': 1.7373, 'grad_norm': 118.28223419189453, 'learning_rate': 6.376376376376376e-06, 'epoch': 1.61, 'iter_time': 0.12397747211034785, 'flops': 17710216017291.56, 'remaining_time': 78.97364973429158}\n",
            "DEBUG:__main__:Step (364) Logs: {'loss': 2.6108, 'grad_norm': 67.33453369140625, 'learning_rate': 6.366366366366366e-06, 'epoch': 1.62, 'iter_time': 0.12394393508427727, 'flops': 17715008086995.363, 'remaining_time': 78.82834271360035}\n",
            "DEBUG:__main__:Step (365) Logs: {'loss': 1.7337, 'grad_norm': 41.8443489074707, 'learning_rate': 6.356356356356357e-06, 'epoch': 1.62, 'iter_time': 0.12390963585822137, 'flops': 17719911749755.32, 'remaining_time': 78.68261876997057}\n",
            "DEBUG:__main__:Step (366) Logs: {'loss': 1.9671, 'grad_norm': 76.34542846679688, 'learning_rate': 6.3463463463463474e-06, 'epoch': 1.63, 'iter_time': 0.123876164710685, 'flops': 17724699642421.297, 'remaining_time': 78.53748842657428}\n",
            "DEBUG:__main__:Step (367) Logs: {'loss': 2.2777, 'grad_norm': 49.6240119934082, 'learning_rate': 6.336336336336338e-06, 'epoch': 1.63, 'iter_time': 0.12384572836870704, 'flops': 17729055666862.99, 'remaining_time': 78.39434605739156}\n",
            "DEBUG:__main__:Step (368) Logs: {'loss': 2.2284, 'grad_norm': 54.35356521606445, 'learning_rate': 6.326326326326326e-06, 'epoch': 1.64, 'iter_time': 0.12383069069573925, 'flops': 17731208636693.395, 'remaining_time': 78.2609965197072}\n",
            "DEBUG:__main__:Step (369) Logs: {'loss': 2.6221, 'grad_norm': 45.241249084472656, 'learning_rate': 6.316316316316316e-06, 'epoch': 1.64, 'iter_time': 0.1238096103720043, 'flops': 17734227623807.16, 'remaining_time': 78.12386414473471}\n",
            "DEBUG:__main__:Step (370) Logs: {'loss': 2.0568, 'grad_norm': 56.7150993347168, 'learning_rate': 6.3063063063063065e-06, 'epoch': 1.64, 'iter_time': 0.12378077907613945, 'flops': 17738358319763.13, 'remaining_time': 77.98189081796785}\n",
            "DEBUG:__main__:Step (371) Logs: {'loss': 2.4952, 'grad_norm': 99.55496215820312, 'learning_rate': 6.296296296296297e-06, 'epoch': 1.65, 'iter_time': 0.12374957638817864, 'flops': 17742830936767.105, 'remaining_time': 77.83848354816436}\n",
            "DEBUG:__main__:Step (372) Logs: {'loss': 2.9673, 'grad_norm': 61.61757278442383, 'learning_rate': 6.286286286286287e-06, 'epoch': 1.65, 'iter_time': 0.123713461215284, 'flops': 17748010530003.176, 'remaining_time': 77.69205364319835}\n",
            "DEBUG:__main__:Step (373) Logs: {'loss': 2.1529, 'grad_norm': 48.91282272338867, 'learning_rate': 6.276276276276276e-06, 'epoch': 1.66, 'iter_time': 0.12367814587008569, 'flops': 17753078338176.082, 'remaining_time': 77.54619746054372}\n",
            "DEBUG:__main__:Step (374) Logs: {'loss': 1.6456, 'grad_norm': 51.05181121826172, 'learning_rate': 6.266266266266266e-06, 'epoch': 1.66, 'iter_time': 0.12364383996651575, 'flops': 17758004061881.4, 'remaining_time': 77.40104381903886}\n",
            "DEBUG:__main__:Step (375) Logs: {'loss': 2.1674, 'grad_norm': 89.02985382080078, 'learning_rate': 6.2562562562562565e-06, 'epoch': 1.67, 'iter_time': 0.12362310146902972, 'flops': 17760983070806.25, 'remaining_time': 77.26443841814357}\n",
            "DEBUG:__main__:Step (376) Logs: {'loss': 2.2729, 'grad_norm': 66.09895324707031, 'learning_rate': 6.246246246246247e-06, 'epoch': 1.67, 'iter_time': 0.12360883522033692, 'flops': 17763032945324.242, 'remaining_time': 77.13191317749023}\n",
            "DEBUG:__main__:Step (377) Logs: {'loss': 2.3594, 'grad_norm': 53.20282745361328, 'learning_rate': 6.236236236236237e-06, 'epoch': 1.68, 'iter_time': 0.12358085652615161, 'flops': 17767054494296.72, 'remaining_time': 76.99087361579245}\n",
            "DEBUG:__main__:Step (378) Logs: {'loss': 3.3419, 'grad_norm': 69.42753601074219, 'learning_rate': 6.226226226226226e-06, 'epoch': 1.68, 'iter_time': 0.12355319195147851, 'flops': 17771032683755.164, 'remaining_time': 76.85008539381964}\n",
            "DEBUG:__main__:Step (379) Logs: {'loss': 2.5751, 'grad_norm': 77.41242218017578, 'learning_rate': 6.2162162162162164e-06, 'epoch': 1.68, 'iter_time': 0.12352321324525056, 'flops': 17775345659059.133, 'remaining_time': 76.7079154253006}\n",
            "DEBUG:__main__:Step (380) Logs: {'loss': 2.7124, 'grad_norm': 74.09866333007812, 'learning_rate': 6.206206206206207e-06, 'epoch': 1.69, 'iter_time': 0.12349095319380546, 'flops': 17779989185978.19, 'remaining_time': 76.56439098015939}\n",
            "DEBUG:__main__:Step (381) Logs: {'loss': 2.0581, 'grad_norm': 62.30557632446289, 'learning_rate': 6.196196196196197e-06, 'epoch': 1.69, 'iter_time': 0.12346060777965345, 'flops': 17784359334037.316, 'remaining_time': 76.42211621560548}\n",
            "DEBUG:__main__:Step (382) Logs: {'loss': 2.7319, 'grad_norm': 58.863712310791016, 'learning_rate': 6.186186186186187e-06, 'epoch': 1.7, 'iter_time': 0.1234324116093593, 'flops': 17788421887930.71, 'remaining_time': 76.28123037458406}\n",
            "DEBUG:__main__:Step (383) Logs: {'loss': 2.7646, 'grad_norm': 39.98856735229492, 'learning_rate': 6.176176176176176e-06, 'epoch': 1.7, 'iter_time': 0.12339851681474616, 'flops': 17793307966969.156, 'remaining_time': 76.13688487469838}\n",
            "DEBUG:__main__:Step (384) Logs: {'loss': 2.4325, 'grad_norm': 76.89251708984375, 'learning_rate': 6.1661661661661665e-06, 'epoch': 1.71, 'iter_time': 0.12337141435389108, 'flops': 17797216833826.06, 'remaining_time': 75.9967912419969}\n",
            "DEBUG:__main__:Step (385) Logs: {'loss': 2.1345, 'grad_norm': 50.763423919677734, 'learning_rate': 6.156156156156157e-06, 'epoch': 1.71, 'iter_time': 0.12334030928711097, 'flops': 17801705095784.504, 'remaining_time': 75.85429021157324}\n",
            "DEBUG:__main__:Step (386) Logs: {'loss': 2.0305, 'grad_norm': 66.47007751464844, 'learning_rate': 6.146146146146147e-06, 'epoch': 1.72, 'iter_time': 0.1233070707940436, 'flops': 17806503700175.99, 'remaining_time': 75.71054146754277}\n",
            "DEBUG:__main__:Step (387) Logs: {'loss': 2.4922, 'grad_norm': 75.7891616821289, 'learning_rate': 6.136136136136137e-06, 'epoch': 1.72, 'iter_time': 0.12327452830082394, 'flops': 17811204330824.64, 'remaining_time': 75.56728584840508}\n",
            "DEBUG:__main__:Step (388) Logs: {'loss': 2.4983, 'grad_norm': 48.88908004760742, 'learning_rate': 6.126126126126126e-06, 'epoch': 1.72, 'iter_time': 0.12324034027967035, 'flops': 17816145325218.613, 'remaining_time': 75.42308825115825}\n",
            "DEBUG:__main__:Step (389) Logs: {'loss': 2.7463, 'grad_norm': 99.64883422851562, 'learning_rate': 6.1161161161161166e-06, 'epoch': 1.73, 'iter_time': 0.12321112143624689, 'flops': 17820370326619.453, 'remaining_time': 75.28199519754685}\n",
            "DEBUG:__main__:Step (390) Logs: {'loss': 1.8512, 'grad_norm': 60.164306640625, 'learning_rate': 6.106106106106107e-06, 'epoch': 1.73, 'iter_time': 0.12318265713885389, 'flops': 17824488149147.492, 'remaining_time': 75.14142085470087}\n",
            "DEBUG:__main__:Step (391) Logs: {'loss': 2.2743, 'grad_norm': 52.609188079833984, 'learning_rate': 6.096096096096097e-06, 'epoch': 1.74, 'iter_time': 0.12314840524624555, 'flops': 17829445764738.72, 'remaining_time': 74.99737879496354}\n",
            "DEBUG:__main__:Step (392) Logs: {'loss': 2.5423, 'grad_norm': 67.59449768066406, 'learning_rate': 6.086086086086087e-06, 'epoch': 1.74, 'iter_time': 0.12311397184191457, 'flops': 17834432432830.32, 'remaining_time': 74.85329487988406}\n",
            "DEBUG:__main__:Step (393) Logs: {'loss': 2.2259, 'grad_norm': 52.78776550292969, 'learning_rate': 6.0760760760760765e-06, 'epoch': 1.75, 'iter_time': 0.12308074990097358, 'flops': 17839246300648.613, 'remaining_time': 74.71001518989097}\n",
            "DEBUG:__main__:Step (394) Logs: {'loss': 2.2666, 'grad_norm': 54.36861801147461, 'learning_rate': 6.066066066066067e-06, 'epoch': 1.75, 'iter_time': 0.12304885272154674, 'flops': 17843870656158.688, 'remaining_time': 74.56760474925733}\n",
            "DEBUG:__main__:Step (395) Logs: {'loss': 2.0111, 'grad_norm': 90.12368774414062, 'learning_rate': 6.056056056056057e-06, 'epoch': 1.76, 'iter_time': 0.12301982780398452, 'flops': 17848080683794.324, 'remaining_time': 74.42699582141063}\n",
            "DEBUG:__main__:Step (396) Logs: {'loss': 2.7911, 'grad_norm': 61.14247131347656, 'learning_rate': 6.046046046046047e-06, 'epoch': 1.76, 'iter_time': 0.12298862903932982, 'flops': 17852608241123.332, 'remaining_time': 74.28513193975522}\n",
            "DEBUG:__main__:Step (397) Logs: {'loss': 2.4787, 'grad_norm': 50.392765045166016, 'learning_rate': 6.036036036036037e-06, 'epoch': 1.76, 'iter_time': 0.12295538789094096, 'flops': 17857434716887.027, 'remaining_time': 74.14209889823739}\n",
            "DEBUG:__main__:Step (398) Logs: {'loss': 2.2859, 'grad_norm': 51.36845016479492, 'learning_rate': 6.0260260260260265e-06, 'epoch': 1.77, 'iter_time': 0.12292208059008236, 'flops': 17862273415905.324, 'remaining_time': 73.99909251522958}\n",
            "DEBUG:__main__:Step (399) Logs: {'loss': 2.6836, 'grad_norm': 49.23635482788086, 'learning_rate': 6.016016016016017e-06, 'epoch': 1.77, 'iter_time': 0.1228894324757945, 'flops': 17867018897531.977, 'remaining_time': 73.8565489179525}\n",
            "DEBUG:__main__:Step (400) Logs: {'loss': 2.4756, 'grad_norm': 57.89114761352539, 'learning_rate': 6.006006006006007e-06, 'epoch': 1.78, 'iter_time': 0.12285817356635455, 'flops': 17871564818323.953, 'remaining_time': 73.71490413981273}\n",
            "DEBUG:__main__:Step (401) Logs: {'loss': 2.8097, 'grad_norm': 80.51004028320312, 'learning_rate': 5.995995995995997e-06, 'epoch': 1.78, 'iter_time': 0.1228251302242279, 'flops': 17876372761369.098, 'remaining_time': 73.57225300431251}\n",
            "DEBUG:__main__:Step (402) Logs: {'loss': 2.5614, 'grad_norm': 61.57530975341797, 'learning_rate': 5.985985985985987e-06, 'epoch': 1.79, 'iter_time': 0.12279334092080742, 'flops': 17881000678758.652, 'remaining_time': 73.43041787064284}\n",
            "DEBUG:__main__:Step (403) Logs: {'loss': 2.4736, 'grad_norm': 52.07500457763672, 'learning_rate': 5.975975975975976e-06, 'epoch': 1.79, 'iter_time': 0.12276699056672813, 'flops': 17884838605362.555, 'remaining_time': 73.29189336833669}\n",
            "DEBUG:__main__:Step (404) Logs: {'loss': 3.0752, 'grad_norm': 57.83262252807617, 'learning_rate': 5.965965965965966e-06, 'epoch': 1.8, 'iter_time': 0.12273498267748811, 'flops': 17889502768103.02, 'remaining_time': 73.15004967578291}\n",
            "DEBUG:__main__:Step (405) Logs: {'loss': 2.5001, 'grad_norm': 49.83452224731445, 'learning_rate': 5.955955955955957e-06, 'epoch': 1.8, 'iter_time': 0.12270467293144453, 'flops': 17893921721943.926, 'remaining_time': 73.0092803942095}\n",
            "DEBUG:__main__:Step (406) Logs: {'loss': 2.3516, 'grad_norm': 52.77252197265625, 'learning_rate': 5.945945945945947e-06, 'epoch': 1.8, 'iter_time': 0.12268476780549979, 'flops': 17896824941079.37, 'remaining_time': 72.87475207646688}\n",
            "DEBUG:__main__:Step (407) Logs: {'loss': 2.6888, 'grad_norm': 48.90542221069336, 'learning_rate': 5.935935935935936e-06, 'epoch': 1.81, 'iter_time': 0.12265415497014089, 'flops': 17901291749036.277, 'remaining_time': 72.73391389729355}\n",
            "DEBUG:__main__:Step (408) Logs: {'loss': 2.212, 'grad_norm': 68.43303680419922, 'learning_rate': 5.925925925925926e-06, 'epoch': 1.81, 'iter_time': 0.12262306693730834, 'flops': 17905830176915.62, 'remaining_time': 72.59285562688655}\n",
            "DEBUG:__main__:Step (409) Logs: {'loss': 1.9448, 'grad_norm': 54.3255615234375, 'learning_rate': 5.915915915915916e-06, 'epoch': 1.82, 'iter_time': 0.12259131728434096, 'flops': 17910467568101.258, 'remaining_time': 72.4514685150455}\n",
            "DEBUG:__main__:Step (410) Logs: {'loss': 2.2868, 'grad_norm': 58.8881950378418, 'learning_rate': 5.905905905905906e-06, 'epoch': 1.82, 'iter_time': 0.12255900937945452, 'flops': 17915188964639.887, 'remaining_time': 72.30981553387817}\n",
            "DEBUG:__main__:Step (411) Logs: {'loss': 2.3622, 'grad_norm': 38.70575714111328, 'learning_rate': 5.895895895895896e-06, 'epoch': 1.83, 'iter_time': 0.12253193855285645, 'flops': 17919146944736.023, 'remaining_time': 72.17131180763245}\n",
            "DEBUG:__main__:Step (412) Logs: {'loss': 2.2723, 'grad_norm': 53.15407943725586, 'learning_rate': 5.885885885885886e-06, 'epoch': 1.83, 'iter_time': 0.12250192263990713, 'flops': 17923537566068.56, 'remaining_time': 72.03113051226539}\n",
            "DEBUG:__main__:Step (413) Logs: {'loss': 2.0911, 'grad_norm': 47.90118408203125, 'learning_rate': 5.875875875875876e-06, 'epoch': 1.84, 'iter_time': 0.12247381164032278, 'flops': 17927651495000.152, 'remaining_time': 71.89212743286947}\n",
            "DEBUG:__main__:Step (414) Logs: {'loss': 2.68, 'grad_norm': 70.26539611816406, 'learning_rate': 5.865865865865866e-06, 'epoch': 1.84, 'iter_time': 0.12244684528784948, 'flops': 17931599684666.42, 'remaining_time': 71.7538513386798}\n",
            "DEBUG:__main__:Step (415) Logs: {'loss': 2.3994, 'grad_norm': 55.736968994140625, 'learning_rate': 5.855855855855856e-06, 'epoch': 1.84, 'iter_time': 0.12243044779496493, 'flops': 17934001319909.402, 'remaining_time': 71.62181196005449}\n",
            "DEBUG:__main__:Step (416) Logs: {'loss': 2.1686, 'grad_norm': 60.227630615234375, 'learning_rate': 5.8458458458458464e-06, 'epoch': 1.85, 'iter_time': 0.12240044237619423, 'flops': 17938397686535.137, 'remaining_time': 71.48185834769743}\n",
            "DEBUG:__main__:Step (417) Logs: {'loss': 2.2621, 'grad_norm': 42.53583908081055, 'learning_rate': 5.835835835835836e-06, 'epoch': 1.85, 'iter_time': 0.12237072048278955, 'flops': 17942754636807.117, 'remaining_time': 71.3421300414663}\n",
            "DEBUG:__main__:Step (418) Logs: {'loss': 2.4486, 'grad_norm': 48.10940933227539, 'learning_rate': 5.825825825825826e-06, 'epoch': 1.86, 'iter_time': 0.12234152821328143, 'flops': 17947036009916.688, 'remaining_time': 71.20276942012978}\n",
            "DEBUG:__main__:Step (419) Logs: {'loss': 2.2903, 'grad_norm': 58.21808624267578, 'learning_rate': 5.815815815815816e-06, 'epoch': 1.86, 'iter_time': 0.1223123518473794, 'flops': 17951317092583.918, 'remaining_time': 71.06347642332743}\n",
            "DEBUG:__main__:Step (420) Logs: {'loss': 2.7863, 'grad_norm': 47.808902740478516, 'learning_rate': 5.805805805805806e-06, 'epoch': 1.87, 'iter_time': 0.12228511512137256, 'flops': 17955315413267.734, 'remaining_time': 70.92536677039608}\n",
            "DEBUG:__main__:Step (421) Logs: {'loss': 1.8847, 'grad_norm': 42.44965744018555, 'learning_rate': 5.7957957957957965e-06, 'epoch': 1.87, 'iter_time': 0.12225893849418276, 'flops': 17959159791465.656, 'remaining_time': 70.78792538813182}\n",
            "DEBUG:__main__:Step (422) Logs: {'loss': 2.1816, 'grad_norm': 57.874046325683594, 'learning_rate': 5.785785785785786e-06, 'epoch': 1.88, 'iter_time': 0.1222353179777603, 'flops': 17962630184767.742, 'remaining_time': 70.65201379114545}\n",
            "DEBUG:__main__:Step (423) Logs: {'loss': 1.9157, 'grad_norm': 48.92235565185547, 'learning_rate': 5.775775775775776e-06, 'epoch': 1.88, 'iter_time': 0.12220790939873429, 'flops': 17966658812467.508, 'remaining_time': 70.51396372306968}\n",
            "DEBUG:__main__:Step (424) Logs: {'loss': 2.4407, 'grad_norm': 80.60108184814453, 'learning_rate': 5.765765765765766e-06, 'epoch': 1.88, 'iter_time': 0.12219363183276309, 'flops': 17968758104817.113, 'remaining_time': 70.38353193567154}\n",
            "DEBUG:__main__:Step (425) Logs: {'loss': 2.1462, 'grad_norm': 58.396018981933594, 'learning_rate': 5.755755755755756e-06, 'epoch': 1.89, 'iter_time': 0.1221653734737972, 'flops': 17972914500383.7, 'remaining_time': 70.2450897474334}\n",
            "DEBUG:__main__:Step (426) Logs: {'loss': 2.3524, 'grad_norm': 44.351219177246094, 'learning_rate': 5.7457457457457466e-06, 'epoch': 1.89, 'iter_time': 0.1221462625615737, 'flops': 17975726529046.832, 'remaining_time': 70.1119547103433}\n",
            "DEBUG:__main__:Step (427) Logs: {'loss': 2.7186, 'grad_norm': 52.52401351928711, 'learning_rate': 5.735735735735736e-06, 'epoch': 1.9, 'iter_time': 0.12212244725563157, 'flops': 17979232006020.49, 'remaining_time': 69.97616227747689}\n",
            "DEBUG:__main__:Step (428) Logs: {'loss': 2.5986, 'grad_norm': 55.14075469970703, 'learning_rate': 5.725725725725726e-06, 'epoch': 1.9, 'iter_time': 0.12209427998830898, 'flops': 17983379832062.93, 'remaining_time': 69.83792815331273}\n",
            "DEBUG:__main__:Step (429) Logs: {'loss': 2.0762, 'grad_norm': 54.782493591308594, 'learning_rate': 5.715715715715716e-06, 'epoch': 1.91, 'iter_time': 0.12206871153038239, 'flops': 17987146622789.637, 'remaining_time': 69.70123428384834}\n",
            "DEBUG:__main__:Step (430) Logs: {'loss': 1.8363, 'grad_norm': 75.17726135253906, 'learning_rate': 5.7057057057057065e-06, 'epoch': 1.91, 'iter_time': 0.12204635059916889, 'flops': 17990442168673.51, 'remaining_time': 69.56641984152627}\n",
            "DEBUG:__main__:Step (431) Logs: {'loss': 2.1938, 'grad_norm': 77.02195739746094, 'learning_rate': 5.695695695695697e-06, 'epoch': 1.92, 'iter_time': 0.12202348598214083, 'flops': 17993813196529.68, 'remaining_time': 69.43136352383813}\n",
            "DEBUG:__main__:Step (432) Logs: {'loss': 1.7951, 'grad_norm': 56.32469177246094, 'learning_rate': 5.685685685685686e-06, 'epoch': 1.92, 'iter_time': 0.12200211427604515, 'flops': 17996965260651.344, 'remaining_time': 69.29720090879364}\n",
            "DEBUG:__main__:Step (433) Logs: {'loss': 1.8907, 'grad_norm': 47.76392364501953, 'learning_rate': 5.675675675675676e-06, 'epoch': 1.92, 'iter_time': 0.12198544928321133, 'flops': 17999423908784.066, 'remaining_time': 69.16574974358082}\n",
            "DEBUG:__main__:Step (434) Logs: {'loss': 2.3354, 'grad_norm': 54.01570129394531, 'learning_rate': 5.665665665665666e-06, 'epoch': 1.93, 'iter_time': 0.12196012622489665, 'flops': 18003161199613.3, 'remaining_time': 69.0294314432915}\n",
            "DEBUG:__main__:Step (435) Logs: {'loss': 2.7049, 'grad_norm': 55.18291091918945, 'learning_rate': 5.6556556556556565e-06, 'epoch': 1.93, 'iter_time': 0.1219349923771098, 'flops': 18006872100843.965, 'remaining_time': 68.89327069306704}\n",
            "DEBUG:__main__:Step (436) Logs: {'loss': 1.308, 'grad_norm': 49.65386962890625, 'learning_rate': 5.645645645645647e-06, 'epoch': 1.94, 'iter_time': 0.12190797246735671, 'flops': 18010863177467.2, 'remaining_time': 68.75609647158919}\n",
            "DEBUG:__main__:Step (437) Logs: {'loss': 2.6932, 'grad_norm': 54.27156448364258, 'learning_rate': 5.635635635635636e-06, 'epoch': 1.94, 'iter_time': 0.12188510501056636, 'flops': 18014242283022.65, 'remaining_time': 68.62131412094887}\n",
            "DEBUG:__main__:Step (438) Logs: {'loss': 2.3632, 'grad_norm': 51.877159118652344, 'learning_rate': 5.625625625625626e-06, 'epoch': 1.95, 'iter_time': 0.1218660963481842, 'flops': 18017052142859.71, 'remaining_time': 68.48874614767952}\n",
            "DEBUG:__main__:Step (439) Logs: {'loss': 2.7323, 'grad_norm': 47.48407745361328, 'learning_rate': 5.615615615615616e-06, 'epoch': 1.95, 'iter_time': 0.12184461284445845, 'flops': 18020228889026.832, 'remaining_time': 68.3548278057412}\n",
            "DEBUG:__main__:Step (440) Logs: {'loss': 2.6426, 'grad_norm': 47.39619445800781, 'learning_rate': 5.605605605605607e-06, 'epoch': 1.96, 'iter_time': 0.12181914911726341, 'flops': 18023995638308.43, 'remaining_time': 68.21872350566751}\n",
            "DEBUG:__main__:Step (441) Logs: {'loss': 2.248, 'grad_norm': 51.28709411621094, 'learning_rate': 5.595595595595597e-06, 'epoch': 1.96, 'iter_time': 0.12179521918296814, 'flops': 18027536935202.152, 'remaining_time': 68.08352752327919}\n",
            "DEBUG:__main__:Step (442) Logs: {'loss': 2.8457, 'grad_norm': 56.65482711791992, 'learning_rate': 5.585585585585585e-06, 'epoch': 1.96, 'iter_time': 0.12177385332362722, 'flops': 18030699960826.36, 'remaining_time': 67.94981015458399}\n",
            "DEBUG:__main__:Step (443) Logs: {'loss': 2.0568, 'grad_norm': 60.49949645996094, 'learning_rate': 5.5755755755755755e-06, 'epoch': 1.97, 'iter_time': 0.1217508251311013, 'flops': 18034110323176.082, 'remaining_time': 67.81520959802343}\n",
            "DEBUG:__main__:Step (444) Logs: {'loss': 3.2379, 'grad_norm': 80.46794891357422, 'learning_rate': 5.565565565565566e-06, 'epoch': 1.97, 'iter_time': 0.12172973774894903, 'flops': 18037234392801.086, 'remaining_time': 67.68173418841566}\n",
            "DEBUG:__main__:Step (445) Logs: {'loss': 1.9583, 'grad_norm': 45.4428596496582, 'learning_rate': 5.555555555555557e-06, 'epoch': 1.98, 'iter_time': 0.12170704528018161, 'flops': 18040597463337.938, 'remaining_time': 67.5474101305008}\n",
            "DEBUG:__main__:Step (446) Logs: {'loss': 3.073, 'grad_norm': 51.7972526550293, 'learning_rate': 5.545545545545547e-06, 'epoch': 1.98, 'iter_time': 0.12168386384342493, 'flops': 18044034295107.902, 'remaining_time': 67.41286056925742}\n",
            "DEBUG:__main__:Step (447) Logs: {'loss': 2.3576, 'grad_norm': 46.668121337890625, 'learning_rate': 5.535535535535535e-06, 'epoch': 1.99, 'iter_time': 0.12166116697371274, 'flops': 18047400554906.863, 'remaining_time': 67.27862533646314}\n",
            "DEBUG:__main__:Step (448) Logs: {'loss': 2.6565, 'grad_norm': 58.5439453125, 'learning_rate': 5.5255255255255255e-06, 'epoch': 1.99, 'iter_time': 0.12164072222357629, 'flops': 18050433869640.72, 'remaining_time': 67.14567866741412}\n",
            "DEBUG:__main__:Step (449) Logs: {'loss': 2.4116, 'grad_norm': 52.46156692504883, 'learning_rate': 5.515515515515516e-06, 'epoch': 2.0, 'iter_time': 0.12162264063954353, 'flops': 18053117419637.047, 'remaining_time': 67.01407499238849}\n",
            "DEBUG:__main__:Step (450) Logs: {'loss': 2.4182, 'grad_norm': 52.28232192993164, 'learning_rate': 5.505505505505506e-06, 'epoch': 2.0, 'iter_time': 0.12159585846558976, 'flops': 18057093720616.72, 'remaining_time': 66.87772215607437}\n",
            "DEBUG:__main__:Step (451) Logs: {'loss': 2.2734, 'grad_norm': 71.29779815673828, 'learning_rate': 5.495495495495496e-06, 'epoch': 2.0, 'iter_time': 0.12157642364501953, 'flops': 18059980270212.098, 'remaining_time': 66.74545658111572}\n",
            "DEBUG:__main__:Step (452) Logs: {'loss': 2.9252, 'grad_norm': 65.27690124511719, 'learning_rate': 5.485485485485485e-06, 'epoch': 2.01, 'iter_time': 0.12156641826925679, 'flops': 18061466674857.75, 'remaining_time': 66.61839721155272}\n",
            "DEBUG:__main__:Step (453) Logs: {'loss': 2.3088, 'grad_norm': 62.488590240478516, 'learning_rate': 5.475475475475476e-06, 'epoch': 2.01, 'iter_time': 0.12154213622608016, 'flops': 18065075047453.87, 'remaining_time': 66.48354851566585}\n",
            "DEBUG:__main__:Step (454) Logs: {'loss': 2.1633, 'grad_norm': 55.68025588989258, 'learning_rate': 5.465465465465466e-06, 'epoch': 2.02, 'iter_time': 0.12151733928958312, 'flops': 18068761422759.527, 'remaining_time': 66.34846725211239}\n",
            "DEBUG:__main__:Step (455) Logs: {'loss': 2.141, 'grad_norm': 57.358341217041016, 'learning_rate': 5.455455455455456e-06, 'epoch': 2.02, 'iter_time': 0.12149345769756166, 'flops': 18072313143130.395, 'remaining_time': 66.2139344451711}\n",
            "DEBUG:__main__:Step (456) Logs: {'loss': 2.1536, 'grad_norm': 51.95610046386719, 'learning_rate': 5.445445445445446e-06, 'epoch': 2.03, 'iter_time': 0.12146897682776818, 'flops': 18075955438936.93, 'remaining_time': 66.0791233943059}\n",
            "DEBUG:__main__:Step (457) Logs: {'loss': 2.8363, 'grad_norm': 82.11906433105469, 'learning_rate': 5.4354354354354355e-06, 'epoch': 2.03, 'iter_time': 0.12144907367856879, 'flops': 18078917737677.676, 'remaining_time': 65.94684700746285}\n",
            "DEBUG:__main__:Step (458) Logs: {'loss': 2.2488, 'grad_norm': 49.920249938964844, 'learning_rate': 5.425425425425426e-06, 'epoch': 2.04, 'iter_time': 0.12142337751075527, 'flops': 18082743680536.438, 'remaining_time': 65.81147061082936}\n",
            "DEBUG:__main__:Step (459) Logs: {'loss': 1.8387, 'grad_norm': 54.15597915649414, 'learning_rate': 5.415415415415416e-06, 'epoch': 2.04, 'iter_time': 0.12139661707732355, 'flops': 18086729805275.133, 'remaining_time': 65.67556983883205}\n",
            "DEBUG:__main__:Step (460) Logs: {'loss': 1.6577, 'grad_norm': 36.8856086730957, 'learning_rate': 5.405405405405406e-06, 'epoch': 2.04, 'iter_time': 0.1213747712262056, 'flops': 18089985177067.348, 'remaining_time': 65.54237646215103}\n",
            "DEBUG:__main__:Step (461) Logs: {'loss': 2.4762, 'grad_norm': 57.04267883300781, 'learning_rate': 5.395395395395396e-06, 'epoch': 2.05, 'iter_time': 0.12136960081432177, 'flops': 18090755820405.633, 'remaining_time': 65.41821483891944}\n",
            "DEBUG:__main__:Step (462) Logs: {'loss': 2.1039, 'grad_norm': 46.807830810546875, 'learning_rate': 5.3853853853853856e-06, 'epoch': 2.05, 'iter_time': 0.12134598444444239, 'flops': 18094276645448.246, 'remaining_time': 65.28413963111001}\n",
            "DEBUG:__main__:Step (463) Logs: {'loss': 1.7244, 'grad_norm': 41.187965393066406, 'learning_rate': 5.375375375375376e-06, 'epoch': 2.06, 'iter_time': 0.12131981622605097, 'flops': 18098179511423.664, 'remaining_time': 65.14874131338937}\n",
            "DEBUG:__main__:Step (464) Logs: {'loss': 1.5127, 'grad_norm': 56.603240966796875, 'learning_rate': 5.365365365365366e-06, 'epoch': 2.06, 'iter_time': 0.1212968239258999, 'flops': 18101610094039.49, 'remaining_time': 65.01509762428235}\n",
            "DEBUG:__main__:Step (465) Logs: {'loss': 2.0363, 'grad_norm': 59.26718521118164, 'learning_rate': 5.355355355355356e-06, 'epoch': 2.07, 'iter_time': 0.12127714989514186, 'flops': 18104546604619.33, 'remaining_time': 64.8832751939009}\n",
            "DEBUG:__main__:Step (466) Logs: {'loss': 2.1081, 'grad_norm': 60.14741134643555, 'learning_rate': 5.345345345345346e-06, 'epoch': 2.07, 'iter_time': 0.1212540703435098, 'flops': 18107992631766.73, 'remaining_time': 64.74967356343423}\n",
            "DEBUG:__main__:Step (467) Logs: {'loss': 2.6237, 'grad_norm': 59.689334869384766, 'learning_rate': 5.335335335335336e-06, 'epoch': 2.08, 'iter_time': 0.12123407979891536, 'flops': 18110978497084.645, 'remaining_time': 64.61776453282188}\n",
            "DEBUG:__main__:Step (468) Logs: {'loss': 1.8202, 'grad_norm': 49.01112365722656, 'learning_rate': 5.325325325325326e-06, 'epoch': 2.08, 'iter_time': 0.121211666111262, 'flops': 18114327463633.44, 'remaining_time': 64.48460637119138}\n",
            "DEBUG:__main__:Step (469) Logs: {'loss': 1.5766, 'grad_norm': 44.11582565307617, 'learning_rate': 5.315315315315316e-06, 'epoch': 2.08, 'iter_time': 0.12119139871026716, 'flops': 18117356806824.164, 'remaining_time': 64.35263271515186}\n",
            "DEBUG:__main__:Step (470) Logs: {'loss': 2.0445, 'grad_norm': 55.3209114074707, 'learning_rate': 5.305305305305306e-06, 'epoch': 2.09, 'iter_time': 0.12117903471501397, 'flops': 18119205335442.062, 'remaining_time': 64.2248883989574}\n",
            "DEBUG:__main__:Step (471) Logs: {'loss': 1.9007, 'grad_norm': 44.56013107299805, 'learning_rate': 5.2952952952952955e-06, 'epoch': 2.09, 'iter_time': 0.1211577963321767, 'flops': 18122381545568.617, 'remaining_time': 64.09247425972147}\n",
            "DEBUG:__main__:Step (472) Logs: {'loss': 1.8742, 'grad_norm': 60.80909729003906, 'learning_rate': 5.285285285285286e-06, 'epoch': 2.1, 'iter_time': 0.1211381996260074, 'flops': 18125313230101.926, 'remaining_time': 63.96096940253191}\n",
            "DEBUG:__main__:Step (473) Logs: {'loss': 2.1233, 'grad_norm': 50.34368133544922, 'learning_rate': 5.275275275275276e-06, 'epoch': 2.1, 'iter_time': 0.12112094689223726, 'flops': 18127895039538.55, 'remaining_time': 63.83073901220904}\n",
            "DEBUG:__main__:Step (474) Logs: {'loss': 2.321, 'grad_norm': 59.629432678222656, 'learning_rate': 5.265265265265266e-06, 'epoch': 2.11, 'iter_time': 0.12110072966609899, 'flops': 18130921410679.63, 'remaining_time': 63.69898380436807}\n",
            "DEBUG:__main__:Step (475) Logs: {'loss': 1.9071, 'grad_norm': 56.325172424316406, 'learning_rate': 5.255255255255256e-06, 'epoch': 2.11, 'iter_time': 0.12108494662031342, 'flops': 18133284719833.63, 'remaining_time': 63.569596975664545}\n",
            "DEBUG:__main__:Step (476) Logs: {'loss': 1.8329, 'grad_norm': 50.43437576293945, 'learning_rate': 5.245245245245245e-06, 'epoch': 2.12, 'iter_time': 0.12106877979479339, 'flops': 18135706133931.2, 'remaining_time': 63.44004061247173}\n",
            "DEBUG:__main__:Step (477) Logs: {'loss': 2.1818, 'grad_norm': 53.798030853271484, 'learning_rate': 5.235235235235236e-06, 'epoch': 2.12, 'iter_time': 0.1210485721836571, 'flops': 18138733673129.93, 'remaining_time': 63.30840325205266}\n",
            "DEBUG:__main__:Step (478) Logs: {'loss': 2.4823, 'grad_norm': 55.334434509277344, 'learning_rate': 5.225225225225226e-06, 'epoch': 2.12, 'iter_time': 0.12103042062723411, 'flops': 18141454032573.473, 'remaining_time': 63.177879567416205}\n",
            "DEBUG:__main__:Step (479) Logs: {'loss': 1.7656, 'grad_norm': 46.16357421875, 'learning_rate': 5.215215215215216e-06, 'epoch': 2.13, 'iter_time': 0.12103123146120973, 'flops': 18141332496114.504, 'remaining_time': 63.05727159129027}\n",
            "DEBUG:__main__:Step (480) Logs: {'loss': 2.0982, 'grad_norm': 50.506080627441406, 'learning_rate': 5.205205205205206e-06, 'epoch': 2.13, 'iter_time': 0.12101503055628257, 'flops': 18143761169657.535, 'remaining_time': 62.92781588926694}\n",
            "DEBUG:__main__:Step (480) Logs: {'eval_loss': 2.8985157012939453, 'eval_runtime': 0.8454, 'eval_samples_per_second': 118.294, 'eval_steps_per_second': 118.294, 'epoch': 2.13, 'iter_time': 0.12279441311862126, 'flops': 17880844548122.492, 'remaining_time': 63.85309482168305}\n",
            "DEBUG:__main__:Step (481) Logs: {'loss': 1.8588, 'grad_norm': 45.394775390625, 'learning_rate': 5.195195195195195e-06, 'epoch': 2.14, 'iter_time': 0.12409248600403468, 'flops': 17693801478685.914, 'remaining_time': 64.40400023609399}\n",
            "DEBUG:__main__:Step (482) Logs: {'loss': 2.7096, 'grad_norm': 52.68914031982422, 'learning_rate': 5.185185185185185e-06, 'epoch': 2.14, 'iter_time': 0.12406634987020194, 'flops': 17697528900053.117, 'remaining_time': 64.2663692327646}\n",
            "DEBUG:__main__:Step (483) Logs: {'loss': 2.0746, 'grad_norm': 62.95238494873047, 'learning_rate': 5.175175175175175e-06, 'epoch': 2.15, 'iter_time': 0.12404385889219545, 'flops': 17700737722616.484, 'remaining_time': 64.13067504726504}\n",
            "DEBUG:__main__:Step (484) Logs: {'loss': 2.5368, 'grad_norm': 55.77303695678711, 'learning_rate': 5.165165165165165e-06, 'epoch': 2.15, 'iter_time': 0.12401653125913, 'flops': 17704638164441.137, 'remaining_time': 63.99253012971108}\n",
            "DEBUG:__main__:Step (485) Logs: {'loss': 1.7476, 'grad_norm': 44.004451751708984, 'learning_rate': 5.155155155155156e-06, 'epoch': 2.16, 'iter_time': 0.12399102833645403, 'flops': 17708279718383.96, 'remaining_time': 63.85537959327383}\n",
            "DEBUG:__main__:Step (486) Logs: {'loss': 1.6565, 'grad_norm': 46.25627517700195, 'learning_rate': 5.145145145145145e-06, 'epoch': 2.16, 'iter_time': 0.12396336830768388, 'flops': 17712230978608.39, 'remaining_time': 63.71717131014952}\n",
            "DEBUG:__main__:Step (487) Logs: {'loss': 2.1001, 'grad_norm': 50.02909469604492, 'learning_rate': 5.135135135135135e-06, 'epoch': 2.16, 'iter_time': 0.12393481594054297, 'flops': 17716311560145.934, 'remaining_time': 63.57856057749854}\n",
            "DEBUG:__main__:Step (488) Logs: {'loss': 2.2629, 'grad_norm': 55.96889877319336, 'learning_rate': 5.125125125125125e-06, 'epoch': 2.17, 'iter_time': 0.12390594560752415, 'flops': 17720439496154.97, 'remaining_time': 63.43984415105236}\n",
            "DEBUG:__main__:Step (489) Logs: {'loss': 2.8181, 'grad_norm': 94.38877868652344, 'learning_rate': 5.115115115115115e-06, 'epoch': 2.17, 'iter_time': 0.1238805998544224, 'flops': 17724065066945.324, 'remaining_time': 63.302986525609846}\n",
            "DEBUG:__main__:Step (490) Logs: {'loss': 2.0963, 'grad_norm': 50.7500114440918, 'learning_rate': 5.105105105105106e-06, 'epoch': 2.18, 'iter_time': 0.12385223004471793, 'flops': 17728124972471.105, 'remaining_time': 63.16463732280614}\n",
            "DEBUG:__main__:Step (491) Logs: {'loss': 2.4214, 'grad_norm': 63.111934661865234, 'learning_rate': 5.095095095095095e-06, 'epoch': 2.18, 'iter_time': 0.1238252440277411, 'flops': 17731988574640.684, 'remaining_time': 63.02704921012022}\n",
            "DEBUG:__main__:Step (492) Logs: {'loss': 1.5925, 'grad_norm': 46.54095458984375, 'learning_rate': 5.085085085085085e-06, 'epoch': 2.19, 'iter_time': 0.12380085700398308, 'flops': 17735481526443.375, 'remaining_time': 62.8908353580234}\n",
            "DEBUG:__main__:Step (493) Logs: {'loss': 2.6727, 'grad_norm': 49.36661911010742, 'learning_rate': 5.075075075075075e-06, 'epoch': 2.19, 'iter_time': 0.12378245737494492, 'flops': 17738117815040.484, 'remaining_time': 62.757705889097075}\n",
            "DEBUG:__main__:Step (494) Logs: {'loss': 1.8331, 'grad_norm': 50.42158126831055, 'learning_rate': 5.0650650650650655e-06, 'epoch': 2.2, 'iter_time': 0.12375572390295188, 'flops': 17741949568925.176, 'remaining_time': 62.62039629489365}\n",
            "DEBUG:__main__:Step (495) Logs: {'loss': 2.5272, 'grad_norm': 51.07295227050781, 'learning_rate': 5.055055055055056e-06, 'epoch': 2.2, 'iter_time': 0.12372734430830488, 'flops': 17746019076274.81, 'remaining_time': 62.48230887569397}\n",
            "DEBUG:__main__:Step (496) Logs: {'loss': 2.3484, 'grad_norm': 82.72970581054688, 'learning_rate': 5.045045045045045e-06, 'epoch': 2.2, 'iter_time': 0.12370004220442339, 'flops': 17749935838530.258, 'remaining_time': 62.34482127102939}\n",
            "DEBUG:__main__:Step (497) Logs: {'loss': 2.7478, 'grad_norm': 116.11959075927734, 'learning_rate': 5.035035035035035e-06, 'epoch': 2.21, 'iter_time': 0.123673893270954, 'flops': 17753688788154.887, 'remaining_time': 62.20796831528986}\n",
            "DEBUG:__main__:Step (498) Logs: {'loss': 1.9981, 'grad_norm': 50.230712890625, 'learning_rate': 5.025025025025025e-06, 'epoch': 2.21, 'iter_time': 0.12364813595470528, 'flops': 17757387083912.984, 'remaining_time': 62.071364249262054}\n",
            "DEBUG:__main__:Step (499) Logs: {'loss': 1.9593, 'grad_norm': 59.45732116699219, 'learning_rate': 5.0150150150150156e-06, 'epoch': 2.22, 'iter_time': 0.12362090507185602, 'flops': 17761298633720.113, 'remaining_time': 61.93407344099987}\n",
            "DEBUG:__main__:Step (500) Logs: {'loss': 2.3204, 'grad_norm': 66.21830749511719, 'learning_rate': 5.005005005005006e-06, 'epoch': 2.22, 'iter_time': 0.12359474273865113, 'flops': 17765058316395.203, 'remaining_time': 61.79737136932557}\n",
            "DEBUG:__main__:Step (501) Logs: {'loss': 2.2281, 'grad_norm': 47.040428161621094, 'learning_rate': 4.994994994994996e-06, 'epoch': 2.23, 'iter_time': 0.12357267761230468, 'flops': 17768230443631.395, 'remaining_time': 61.662766128540035}\n",
            "DEBUG:__main__:Step (502) Logs: {'loss': 2.28, 'grad_norm': 62.0599479675293, 'learning_rate': 4.984984984984985e-06, 'epoch': 2.23, 'iter_time': 0.12355321895576522, 'flops': 17771028799647.035, 'remaining_time': 61.52950303997108}\n",
            "DEBUG:__main__:Step (503) Logs: {'loss': 1.4402, 'grad_norm': 47.17046356201172, 'learning_rate': 4.9749749749749754e-06, 'epoch': 2.24, 'iter_time': 0.12353051326189383, 'flops': 17774295227746.863, 'remaining_time': 61.39466509116124}\n",
            "DEBUG:__main__:Step (504) Logs: {'loss': 1.9272, 'grad_norm': 41.076866149902344, 'learning_rate': 4.964964964964966e-06, 'epoch': 2.24, 'iter_time': 0.12350656071429698, 'flops': 17777742329260.992, 'remaining_time': 61.2592541142913}\n",
            "DEBUG:__main__:Step (505) Logs: {'loss': 2.3652, 'grad_norm': 59.55451202392578, 'learning_rate': 4.954954954954955e-06, 'epoch': 2.24, 'iter_time': 0.12348242742674691, 'flops': 17781216794223.85, 'remaining_time': 61.12380157623972}\n",
            "DEBUG:__main__:Step (506) Logs: {'loss': 2.7554, 'grad_norm': 74.99695587158203, 'learning_rate': 4.944944944944945e-06, 'epoch': 2.25, 'iter_time': 0.123456076820298, 'flops': 17785012037503.85, 'remaining_time': 60.98730194922721}\n",
            "DEBUG:__main__:Step (507) Logs: {'loss': 2.3748, 'grad_norm': 59.584251403808594, 'learning_rate': 4.934934934934935e-06, 'epoch': 2.25, 'iter_time': 0.12342852660318608, 'flops': 17788981791955.727, 'remaining_time': 60.850263615370736}\n",
            "DEBUG:__main__:Step (508) Logs: {'loss': 1.3953, 'grad_norm': 50.74531555175781, 'learning_rate': 4.9249249249249255e-06, 'epoch': 2.26, 'iter_time': 0.12340165595331136, 'flops': 17792855333989.395, 'remaining_time': 60.71361472902919}\n",
            "DEBUG:__main__:Step (509) Logs: {'loss': 1.9522, 'grad_norm': 51.08030319213867, 'learning_rate': 4.914914914914916e-06, 'epoch': 2.26, 'iter_time': 0.12337433540914941, 'flops': 17796795460501.99, 'remaining_time': 60.57679868589236}\n",
            "DEBUG:__main__:Step (510) Logs: {'loss': 2.1824, 'grad_norm': 52.25380325317383, 'learning_rate': 4.904904904904905e-06, 'epoch': 2.27, 'iter_time': 0.12334929046555915, 'flops': 17800408936807.473, 'remaining_time': 60.441152328123984}\n",
            "DEBUG:__main__:Step (511) Logs: {'loss': 2.1818, 'grad_norm': 67.46753692626953, 'learning_rate': 4.894894894894895e-06, 'epoch': 2.27, 'iter_time': 0.12332383885103114, 'flops': 17804082591073.523, 'remaining_time': 60.305357198154226}\n",
            "DEBUG:__main__:Step (512) Logs: {'loss': 2.4976, 'grad_norm': 84.47836303710938, 'learning_rate': 4.884884884884885e-06, 'epoch': 2.28, 'iter_time': 0.12330153310368906, 'flops': 17807303421812.098, 'remaining_time': 60.17114815460026}\n",
            "DEBUG:__main__:Step (513) Logs: {'loss': 2.4639, 'grad_norm': 45.785682678222656, 'learning_rate': 4.874874874874876e-06, 'epoch': 2.28, 'iter_time': 0.12327550910413265, 'flops': 17811062621508.113, 'remaining_time': 60.0351729337126}\n",
            "DEBUG:__main__:Step (514) Logs: {'loss': 1.838, 'grad_norm': 55.81745910644531, 'learning_rate': 4.864864864864866e-06, 'epoch': 2.28, 'iter_time': 0.12324950801931162, 'flops': 17814820096547.297, 'remaining_time': 59.899260897385446}\n",
            "DEBUG:__main__:Step (515) Logs: {'loss': 1.7246, 'grad_norm': 81.19437408447266, 'learning_rate': 4.854854854854855e-06, 'epoch': 2.29, 'iter_time': 0.12322453905172386, 'flops': 17818429910542.105, 'remaining_time': 59.76390144008607}\n",
            "DEBUG:__main__:Step (516) Logs: {'loss': 1.9485, 'grad_norm': 50.95743179321289, 'learning_rate': 4.844844844844845e-06, 'epoch': 2.29, 'iter_time': 0.12320250029702788, 'flops': 17821617313435.06, 'remaining_time': 59.630010143761496}\n",
            "DEBUG:__main__:Step (517) Logs: {'loss': 1.7335, 'grad_norm': 47.61662673950195, 'learning_rate': 4.8348348348348355e-06, 'epoch': 2.3, 'iter_time': 0.12317612975142724, 'flops': 17825432709916.418, 'remaining_time': 59.494070669939354}\n",
            "DEBUG:__main__:Step (518) Logs: {'loss': 2.0786, 'grad_norm': 90.09313201904297, 'learning_rate': 4.824824824824826e-06, 'epoch': 2.3, 'iter_time': 0.12314938484354222, 'flops': 17829303939613.934, 'remaining_time': 59.35800349458735}\n",
            "DEBUG:__main__:Step (519) Logs: {'loss': 2.6449, 'grad_norm': 59.76216125488281, 'learning_rate': 4.814814814814815e-06, 'epoch': 2.31, 'iter_time': 0.1231240227415755, 'flops': 17832976566729.613, 'remaining_time': 59.222654938697815}\n",
            "DEBUG:__main__:Step (520) Logs: {'loss': 2.1417, 'grad_norm': 63.6441535949707, 'learning_rate': 4.804804804804805e-06, 'epoch': 2.31, 'iter_time': 0.1231021123125374, 'flops': 17836150583489.062, 'remaining_time': 59.089013910017954}\n",
            "DEBUG:__main__:Step (521) Logs: {'loss': 1.5273, 'grad_norm': 47.306636810302734, 'learning_rate': 4.794794794794795e-06, 'epoch': 2.32, 'iter_time': 0.1230930548447829, 'flops': 17837463008133.8, 'remaining_time': 58.96157327065101}\n",
            "DEBUG:__main__:Step (522) Logs: {'loss': 1.832, 'grad_norm': 62.284244537353516, 'learning_rate': 4.784784784784785e-06, 'epoch': 2.32, 'iter_time': 0.12306829652035763, 'flops': 17841051468432.395, 'remaining_time': 58.826645736730946}\n",
            "DEBUG:__main__:Step (523) Logs: {'loss': 1.9617, 'grad_norm': 55.56808090209961, 'learning_rate': 4.774774774774775e-06, 'epoch': 2.32, 'iter_time': 0.1230419572742506, 'flops': 17844870652195.766, 'remaining_time': 58.69101361981754}\n",
            "DEBUG:__main__:Step (524) Logs: {'loss': 1.9923, 'grad_norm': 50.328895568847656, 'learning_rate': 4.764764764764765e-06, 'epoch': 2.33, 'iter_time': 0.12302369688482631, 'flops': 17847519363749.61, 'remaining_time': 58.559279717177326}\n",
            "DEBUG:__main__:Step (525) Logs: {'loss': 2.1306, 'grad_norm': 69.75251007080078, 'learning_rate': 4.754754754754755e-06, 'epoch': 2.33, 'iter_time': 0.12300052442623459, 'flops': 17850881714482.26, 'remaining_time': 58.42524910246143}\n",
            "DEBUG:__main__:Step (526) Logs: {'loss': 1.9518, 'grad_norm': 56.387428283691406, 'learning_rate': 4.7447447447447454e-06, 'epoch': 2.34, 'iter_time': 0.12297920136224656, 'flops': 17853976835354.934, 'remaining_time': 58.29214144570487}\n",
            "DEBUG:__main__:Step (527) Logs: {'loss': 2.4304, 'grad_norm': 60.849735260009766, 'learning_rate': 4.734734734734735e-06, 'epoch': 2.34, 'iter_time': 0.12295774361933139, 'flops': 17857092589057.543, 'remaining_time': 58.15901273194375}\n",
            "DEBUG:__main__:Step (528) Logs: {'loss': 1.8115, 'grad_norm': 62.295143127441406, 'learning_rate': 4.724724724724725e-06, 'epoch': 2.35, 'iter_time': 0.12293666951796588, 'flops': 17860153695078.965, 'remaining_time': 58.026108012479895}\n",
            "DEBUG:__main__:Step (529) Logs: {'loss': 1.8638, 'grad_norm': 56.829505920410156, 'learning_rate': 4.714714714714715e-06, 'epoch': 2.35, 'iter_time': 0.12291674270774379, 'flops': 17863049117503.766, 'remaining_time': 57.89378581534732}\n",
            "DEBUG:__main__:Step (530) Logs: {'loss': 1.9674, 'grad_norm': 73.83729553222656, 'learning_rate': 4.704704704704705e-06, 'epoch': 2.36, 'iter_time': 0.12289525836086454, 'flops': 17866171906362.18, 'remaining_time': 57.760771429606336}\n",
            "DEBUG:__main__:Step (531) Logs: {'loss': 2.256, 'grad_norm': 81.10871887207031, 'learning_rate': 4.6946946946946955e-06, 'epoch': 2.36, 'iter_time': 0.12287217491077927, 'flops': 17869528344772.383, 'remaining_time': 57.62705003315548}\n",
            "DEBUG:__main__:Step (532) Logs: {'loss': 1.7339, 'grad_norm': 71.43212127685547, 'learning_rate': 4.684684684684685e-06, 'epoch': 2.36, 'iter_time': 0.1228512734343103, 'flops': 17872568602441.418, 'remaining_time': 57.494395967257226}\n",
            "DEBUG:__main__:Step (533) Logs: {'loss': 1.3936, 'grad_norm': 41.234989166259766, 'learning_rate': 4.674674674674675e-06, 'epoch': 2.37, 'iter_time': 0.12283027440981757, 'flops': 17875624091062.887, 'remaining_time': 57.361738149384806}\n",
            "DEBUG:__main__:Step (534) Logs: {'loss': 2.3276, 'grad_norm': 49.757469177246094, 'learning_rate': 4.664664664664665e-06, 'epoch': 2.37, 'iter_time': 0.12280614291078377, 'flops': 17879136664581.258, 'remaining_time': 57.22766259642524}\n",
            "DEBUG:__main__:Step (535) Logs: {'loss': 1.6049, 'grad_norm': 66.23676300048828, 'learning_rate': 4.654654654654655e-06, 'epoch': 2.38, 'iter_time': 0.12278380867247278, 'flops': 17882388859666.09, 'remaining_time': 57.09447103269984}\n",
            "DEBUG:__main__:Step (536) Logs: {'loss': 2.5926, 'grad_norm': 73.58853149414062, 'learning_rate': 4.6446446446446456e-06, 'epoch': 2.38, 'iter_time': 0.12276326429064029, 'flops': 17885381470093.43, 'remaining_time': 56.96215463085709}\n",
            "DEBUG:__main__:Step (537) Logs: {'loss': 1.914, 'grad_norm': 54.19509506225586, 'learning_rate': 4.634634634634635e-06, 'epoch': 2.39, 'iter_time': 0.12273994532983694, 'flops': 17888779455226.41, 'remaining_time': 56.8285946877145}\n",
            "DEBUG:__main__:Step (538) Logs: {'loss': 2.3616, 'grad_norm': 77.85344696044922, 'learning_rate': 4.624624624624625e-06, 'epoch': 2.39, 'iter_time': 0.12271780408294507, 'flops': 17892007021800.57, 'remaining_time': 56.69562548632062}\n",
            "DEBUG:__main__:Step (539) Logs: {'loss': 2.0994, 'grad_norm': 67.42849731445312, 'learning_rate': 4.614614614614614e-06, 'epoch': 2.4, 'iter_time': 0.12270160324068317, 'flops': 17894369383626.77, 'remaining_time': 56.56543909395494}\n",
            "DEBUG:__main__:Step (540) Logs: {'loss': 2.2895, 'grad_norm': 46.873199462890625, 'learning_rate': 4.604604604604605e-06, 'epoch': 2.4, 'iter_time': 0.12268309336646369, 'flops': 17897069205724.82, 'remaining_time': 56.43422294857329}\n",
            "DEBUG:__main__:Step (541) Logs: {'loss': 2.0516, 'grad_norm': 53.19938278198242, 'learning_rate': 4.594594594594596e-06, 'epoch': 2.4, 'iter_time': 0.12266443040635851, 'flops': 17899792181631.36, 'remaining_time': 56.30297355651855}\n",
            "DEBUG:__main__:Step (542) Logs: {'loss': 2.1199, 'grad_norm': 51.03596115112305, 'learning_rate': 4.584584584584585e-06, 'epoch': 2.41, 'iter_time': 0.1226467235692107, 'flops': 17902376422742.055, 'remaining_time': 56.1721993946985}\n",
            "DEBUG:__main__:Step (543) Logs: {'loss': 1.9606, 'grad_norm': 43.99641799926758, 'learning_rate': 4.574574574574575e-06, 'epoch': 2.41, 'iter_time': 0.12262789965555676, 'flops': 17905124515051.625, 'remaining_time': 56.04095014258944}\n",
            "DEBUG:__main__:Step (544) Logs: {'loss': 1.9517, 'grad_norm': 52.30866241455078, 'learning_rate': 4.5645645645645645e-06, 'epoch': 2.42, 'iter_time': 0.12260564124386614, 'flops': 17908375096581.027, 'remaining_time': 55.90817240720296}\n",
            "DEBUG:__main__:Step (545) Logs: {'loss': 2.2552, 'grad_norm': 76.48980712890625, 'learning_rate': 4.554554554554555e-06, 'epoch': 2.42, 'iter_time': 0.12258544783381854, 'flops': 17911325129949.6, 'remaining_time': 55.77637876438744}\n",
            "DEBUG:__main__:Step (546) Logs: {'loss': 1.8758, 'grad_norm': 58.01593780517578, 'learning_rate': 4.544544544544545e-06, 'epoch': 2.43, 'iter_time': 0.12256267092643527, 'flops': 17914653750242.492, 'remaining_time': 55.64345260060161}\n",
            "DEBUG:__main__:Step (547) Logs: {'loss': 2.2833, 'grad_norm': 52.63179016113281, 'learning_rate': 4.534534534534535e-06, 'epoch': 2.43, 'iter_time': 0.12253972942575866, 'flops': 17918007675072.082, 'remaining_time': 55.51049742986868}\n",
            "DEBUG:__main__:Step (548) Logs: {'loss': 1.9014, 'grad_norm': 44.168087005615234, 'learning_rate': 4.524524524524525e-06, 'epoch': 2.44, 'iter_time': 0.12251766115917366, 'flops': 17921235122986.973, 'remaining_time': 55.3779828439465}\n",
            "DEBUG:__main__:Step (549) Logs: {'loss': 2.0403, 'grad_norm': 74.31909942626953, 'learning_rate': 4.5145145145145146e-06, 'epoch': 2.44, 'iter_time': 0.122496097192277, 'flops': 17924389941220.348, 'remaining_time': 55.245739833716925}\n",
            "DEBUG:__main__:Step (550) Logs: {'loss': 2.038, 'grad_norm': 54.7297477722168, 'learning_rate': 4.504504504504505e-06, 'epoch': 2.44, 'iter_time': 0.12247390000112286, 'flops': 17927638560802.504, 'remaining_time': 55.11325500050529}\n",
            "DEBUG:__main__:Step (551) Logs: {'loss': 2.0689, 'grad_norm': 61.90913009643555, 'learning_rate': 4.494494494494495e-06, 'epoch': 2.45, 'iter_time': 0.12245638500560414, 'flops': 17930202759549.996, 'remaining_time': 54.98291686751626}\n",
            "DEBUG:__main__:Step (552) Logs: {'loss': 1.1075, 'grad_norm': 41.0832633972168, 'learning_rate': 4.484484484484485e-06, 'epoch': 2.45, 'iter_time': 0.12243382035063313, 'flops': 17933507310838.77, 'remaining_time': 54.850351517083645}\n",
            "DEBUG:__main__:Step (553) Logs: {'loss': 2.042, 'grad_norm': 60.302947998046875, 'learning_rate': 4.474474474474475e-06, 'epoch': 2.46, 'iter_time': 0.12240995315537936, 'flops': 17937003942522.22, 'remaining_time': 54.71724906045458}\n",
            "DEBUG:__main__:Step (554) Logs: {'loss': 1.9402, 'grad_norm': 55.209632873535156, 'learning_rate': 4.464464464464465e-06, 'epoch': 2.46, 'iter_time': 0.12238641026653821, 'flops': 17940454398247.188, 'remaining_time': 54.58433897887604}\n",
            "DEBUG:__main__:Step (555) Logs: {'loss': 2.2026, 'grad_norm': 62.61130142211914, 'learning_rate': 4.454454454454455e-06, 'epoch': 2.47, 'iter_time': 0.12237052323585813, 'flops': 17942783558423.203, 'remaining_time': 54.454882839956866}\n",
            "DEBUG:__main__:Step (556) Logs: {'loss': 1.9423, 'grad_norm': 54.79612731933594, 'learning_rate': 4.444444444444444e-06, 'epoch': 2.47, 'iter_time': 0.12235086028640335, 'flops': 17945667134765.547, 'remaining_time': 54.323781967163086}\n",
            "DEBUG:__main__:Step (557) Logs: {'loss': 1.9355, 'grad_norm': 43.41558074951172, 'learning_rate': 4.434434434434435e-06, 'epoch': 2.48, 'iter_time': 0.12232841905072439, 'flops': 17948959280194.33, 'remaining_time': 54.1914896394709}\n",
            "DEBUG:__main__:Step (558) Logs: {'loss': 1.6616, 'grad_norm': 43.487403869628906, 'learning_rate': 4.424424424424425e-06, 'epoch': 2.48, 'iter_time': 0.12230814209532268, 'flops': 17951934963093.246, 'remaining_time': 54.060198806132625}\n",
            "DEBUG:__main__:Step (559) Logs: {'loss': 2.3246, 'grad_norm': 94.47113800048828, 'learning_rate': 4.414414414414415e-06, 'epoch': 2.48, 'iter_time': 0.12228807027194662, 'flops': 17954881514355.656, 'remaining_time': 53.92903898992846}\n",
            "DEBUG:__main__:Step (560) Logs: {'loss': 1.8714, 'grad_norm': 66.34449768066406, 'learning_rate': 4.404404404404405e-06, 'epoch': 2.49, 'iter_time': 0.12226665467823554, 'flops': 17958026398368.832, 'remaining_time': 53.79732805842364}\n",
            "DEBUG:__main__:Step (561) Logs: {'loss': 2.5079, 'grad_norm': 56.0257568359375, 'learning_rate': 4.394394394394394e-06, 'epoch': 2.49, 'iter_time': 0.1222436785697937, 'flops': 17961401669521.973, 'remaining_time': 53.66497489213944}\n",
            "DEBUG:__main__:Step (562) Logs: {'loss': 2.7785, 'grad_norm': 55.23953628540039, 'learning_rate': 4.384384384384384e-06, 'epoch': 2.5, 'iter_time': 0.12222417025642598, 'flops': 17964268505529.59, 'remaining_time': 53.53418657231458}\n",
            "DEBUG:__main__:Step (563) Logs: {'loss': 2.4006, 'grad_norm': 41.648616790771484, 'learning_rate': 4.374374374374375e-06, 'epoch': 2.5, 'iter_time': 0.12220408186793752, 'flops': 17967221542769.707, 'remaining_time': 53.4031837762887}\n",
            "DEBUG:__main__:Step (564) Logs: {'loss': 1.6885, 'grad_norm': 38.60881805419922, 'learning_rate': 4.364364364364365e-06, 'epoch': 2.51, 'iter_time': 0.12218918935867228, 'flops': 17969411401092.695, 'remaining_time': 53.27448656038111}\n",
            "DEBUG:__main__:Step (565) Logs: {'loss': 1.6198, 'grad_norm': 40.9995002746582, 'learning_rate': 4.354354354354355e-06, 'epoch': 2.51, 'iter_time': 0.122170294007511, 'flops': 17972190622844.95, 'remaining_time': 53.14407789326729}\n",
            "DEBUG:__main__:Step (566) Logs: {'loss': 2.1656, 'grad_norm': 46.65772247314453, 'learning_rate': 4.344344344344344e-06, 'epoch': 2.52, 'iter_time': 0.1221499059052594, 'flops': 17975190370224.11, 'remaining_time': 53.01305916288258}\n",
            "DEBUG:__main__:Step (567) Logs: {'loss': 2.3621, 'grad_norm': 62.27556228637695, 'learning_rate': 4.3343343343343345e-06, 'epoch': 2.52, 'iter_time': 0.12212974149009785, 'flops': 17978158191139.89, 'remaining_time': 52.88217806521237}\n",
            "DEBUG:__main__:Step (568) Logs: {'loss': 1.1027, 'grad_norm': 60.5047492980957, 'learning_rate': 4.324324324324325e-06, 'epoch': 2.52, 'iter_time': 0.1221099164750841, 'flops': 17981077014330.895, 'remaining_time': 52.75148391723633}\n",
            "DEBUG:__main__:Step (569) Logs: {'loss': 1.9651, 'grad_norm': 60.72483444213867, 'learning_rate': 4.314314314314315e-06, 'epoch': 2.53, 'iter_time': 0.12208896959331673, 'flops': 17984162039092.13, 'remaining_time': 52.62034589471951}\n",
            "DEBUG:__main__:Step (570) Logs: {'loss': 1.5694, 'grad_norm': 51.06675338745117, 'learning_rate': 4.304304304304305e-06, 'epoch': 2.53, 'iter_time': 0.12207781828560184, 'flops': 17985804818490.62, 'remaining_time': 52.49346186280879}\n",
            "DEBUG:__main__:Step (571) Logs: {'loss': 2.3669, 'grad_norm': 72.13720703125, 'learning_rate': 4.294294294294294e-06, 'epoch': 2.54, 'iter_time': 0.1220631156051368, 'flops': 17987971234937.08, 'remaining_time': 52.365076594603686}\n",
            "DEBUG:__main__:Step (572) Logs: {'loss': 2.6803, 'grad_norm': 80.42378997802734, 'learning_rate': 4.2842842842842845e-06, 'epoch': 2.54, 'iter_time': 0.12204759383994936, 'flops': 17990258908597.188, 'remaining_time': 52.23637016349832}\n",
            "DEBUG:__main__:Step (573) Logs: {'loss': 2.4132, 'grad_norm': 104.07247924804688, 'learning_rate': 4.274274274274275e-06, 'epoch': 2.55, 'iter_time': 0.12203380402985152, 'flops': 17992291806415.4, 'remaining_time': 52.108434320746596}\n",
            "DEBUG:__main__:Step (574) Logs: {'loss': 2.0589, 'grad_norm': 47.274436950683594, 'learning_rate': 4.264264264264265e-06, 'epoch': 2.55, 'iter_time': 0.12201907871905422, 'flops': 17994463123324.086, 'remaining_time': 51.9801275343171}\n",
            "DEBUG:__main__:Step (575) Logs: {'loss': 2.0197, 'grad_norm': 67.3869400024414, 'learning_rate': 4.254254254254255e-06, 'epoch': 2.56, 'iter_time': 0.12200280515159048, 'flops': 17996863347722.594, 'remaining_time': 51.85119218942595}\n",
            "DEBUG:__main__:Step (576) Logs: {'loss': 2.2336, 'grad_norm': 54.29016876220703, 'learning_rate': 4.2442442442442444e-06, 'epoch': 2.56, 'iter_time': 0.1219864795518958, 'flops': 17999271889946.734, 'remaining_time': 51.72226733000382}\n",
            "DEBUG:__main__:Step (577) Logs: {'loss': 2.3511, 'grad_norm': 50.407711029052734, 'learning_rate': 4.234234234234235e-06, 'epoch': 2.56, 'iter_time': 0.12197223471270667, 'flops': 18001373980920.12, 'remaining_time': 51.59425528347492}\n",
            "DEBUG:__main__:Step (578) Logs: {'loss': 1.6115, 'grad_norm': 80.57953643798828, 'learning_rate': 4.224224224224225e-06, 'epoch': 2.57, 'iter_time': 0.12195480675589894, 'flops': 18003946468028.79, 'remaining_time': 51.464928450989355}\n",
            "DEBUG:__main__:Step (579) Logs: {'loss': 1.7143, 'grad_norm': 52.327720642089844, 'learning_rate': 4.214214214214214e-06, 'epoch': 2.57, 'iter_time': 0.12193657700165746, 'flops': 18006638092868.188, 'remaining_time': 51.33529891769779}\n",
            "DEBUG:__main__:Step (580) Logs: {'loss': 1.755, 'grad_norm': 62.275794982910156, 'learning_rate': 4.204204204204204e-06, 'epoch': 2.58, 'iter_time': 0.12191755989878494, 'flops': 18009446827633.586, 'remaining_time': 51.20537515748968}\n",
            "DEBUG:__main__:Step (581) Logs: {'loss': 2.3243, 'grad_norm': 45.51963806152344, 'learning_rate': 4.1941941941941945e-06, 'epoch': 2.58, 'iter_time': 0.12189881267218754, 'flops': 18012216560768.555, 'remaining_time': 51.07560250964658}\n",
            "DEBUG:__main__:Step (582) Logs: {'loss': 1.7782, 'grad_norm': 41.315765380859375, 'learning_rate': 4.184184184184185e-06, 'epoch': 2.59, 'iter_time': 0.12188171109316066, 'flops': 18014743907506.637, 'remaining_time': 50.94655523694116}\n",
            "DEBUG:__main__:Step (583) Logs: {'loss': 2.2799, 'grad_norm': 69.23638916015625, 'learning_rate': 4.174174174174174e-06, 'epoch': 2.59, 'iter_time': 0.12186596319847501, 'flops': 18017071828136.8, 'remaining_time': 50.818106653764076}\n",
            "DEBUG:__main__:Step (584) Logs: {'loss': 2.6009, 'grad_norm': 63.42970275878906, 'learning_rate': 4.164164164164164e-06, 'epoch': 2.6, 'iter_time': 0.12185137717637967, 'flops': 18019228532589.945, 'remaining_time': 50.69017290537394}\n",
            "DEBUG:__main__:Step (585) Logs: {'loss': 2.1092, 'grad_norm': 62.824703216552734, 'learning_rate': 4.154154154154154e-06, 'epoch': 2.6, 'iter_time': 0.12183424912086904, 'flops': 18021761763998.945, 'remaining_time': 50.561213385160656}\n",
            "DEBUG:__main__:Step (586) Logs: {'loss': 1.8521, 'grad_norm': 61.02901077270508, 'learning_rate': 4.1441441441441446e-06, 'epoch': 2.6, 'iter_time': 0.12181620312552167, 'flops': 18024431528944.824, 'remaining_time': 50.43190809396597}\n",
            "DEBUG:__main__:Step (587) Logs: {'loss': 2.3916, 'grad_norm': 56.69029235839844, 'learning_rate': 4.134134134134135e-06, 'epoch': 2.61, 'iter_time': 0.12179812595705937, 'flops': 18027106698883.816, 'remaining_time': 50.30262602026552}\n",
            "DEBUG:__main__:Step (588) Logs: {'loss': 2.0866, 'grad_norm': 39.062992095947266, 'learning_rate': 4.124124124124124e-06, 'epoch': 2.61, 'iter_time': 0.12178108192586817, 'flops': 18029629706267.26, 'remaining_time': 50.173805753457685}\n",
            "DEBUG:__main__:Step (589) Logs: {'loss': 2.5508, 'grad_norm': 52.054527282714844, 'learning_rate': 4.114114114114114e-06, 'epoch': 2.62, 'iter_time': 0.12176339966910225, 'flops': 18032247935905.453, 'remaining_time': 50.04475726400103}\n",
            "DEBUG:__main__:Step (590) Logs: {'loss': 2.3541, 'grad_norm': 92.72904205322266, 'learning_rate': 4.1041041041041045e-06, 'epoch': 2.62, 'iter_time': 0.12174477803889276, 'flops': 18035006081743.965, 'remaining_time': 49.91535899594603}\n",
            "DEBUG:__main__:Step (591) Logs: {'loss': 2.6347, 'grad_norm': 54.12592315673828, 'learning_rate': 4.094094094094095e-06, 'epoch': 2.63, 'iter_time': 0.12172852370698574, 'flops': 18037414284569.98, 'remaining_time': 49.78696619615717}\n",
            "DEBUG:__main__:Step (592) Logs: {'loss': 1.7912, 'grad_norm': 53.22959899902344, 'learning_rate': 4.084084084084085e-06, 'epoch': 2.63, 'iter_time': 0.121711336820057, 'flops': 18039961352147.21, 'remaining_time': 49.65822542258326}\n",
            "DEBUG:__main__:Step (593) Logs: {'loss': 2.3162, 'grad_norm': 137.8553924560547, 'learning_rate': 4.074074074074074e-06, 'epoch': 2.64, 'iter_time': 0.12169514636735658, 'flops': 18042361407939.97, 'remaining_time': 49.52992457151413}\n",
            "DEBUG:__main__:Step (594) Logs: {'loss': 1.7646, 'grad_norm': 51.201297760009766, 'learning_rate': 4.064064064064064e-06, 'epoch': 2.64, 'iter_time': 0.12167799774350042, 'flops': 18044904198543.027, 'remaining_time': 49.40126708386117}\n",
            "DEBUG:__main__:Step (595) Logs: {'loss': 2.2672, 'grad_norm': 52.42465591430664, 'learning_rate': 4.0540540540540545e-06, 'epoch': 2.64, 'iter_time': 0.12166186534997189, 'flops': 18047296957316.52, 'remaining_time': 49.27305546673862}\n",
            "DEBUG:__main__:Step (596) Logs: {'loss': 2.0501, 'grad_norm': 78.99576568603516, 'learning_rate': 4.044044044044044e-06, 'epoch': 2.65, 'iter_time': 0.12164535201898143, 'flops': 18049746874088.457, 'remaining_time': 49.144722215668494}\n",
            "DEBUG:__main__:Step (597) Logs: {'loss': 1.9271, 'grad_norm': 47.01629638671875, 'learning_rate': 4.034034034034035e-06, 'epoch': 2.65, 'iter_time': 0.12162731077847065, 'flops': 18052424231849.883, 'remaining_time': 49.015806243723674}\n",
            "DEBUG:__main__:Step (598) Logs: {'loss': 1.6508, 'grad_norm': 70.1778564453125, 'learning_rate': 4.024024024024024e-06, 'epoch': 2.66, 'iter_time': 0.12160870338005436, 'flops': 18055186440809.65, 'remaining_time': 48.886698758781854}\n",
            "DEBUG:__main__:Step (599) Logs: {'loss': 1.9235, 'grad_norm': 74.17858123779297, 'learning_rate': 4.014014014014014e-06, 'epoch': 2.66, 'iter_time': 0.12159144240478209, 'flops': 18057749533413.27, 'remaining_time': 48.758168404317615}\n",
            "DEBUG:__main__:Step (600) Logs: {'loss': 1.759, 'grad_norm': 50.84315872192383, 'learning_rate': 4.004004004004005e-06, 'epoch': 2.67, 'iter_time': 0.12157443130951692, 'flops': 18060276233265.19, 'remaining_time': 48.62977252380677}\n",
            "DEBUG:__main__:Step (600) Logs: {'eval_loss': 2.892916679382324, 'eval_runtime': 0.829, 'eval_samples_per_second': 120.634, 'eval_steps_per_second': 120.634, 'epoch': 2.67, 'iter_time': 0.12296928746473411, 'flops': 17855416239454.81, 'remaining_time': 49.18771498589364}\n",
            "DEBUG:__main__:Step (601) Logs: {'loss': 2.3547, 'grad_norm': 57.819820404052734, 'learning_rate': 3.993993993993994e-06, 'epoch': 2.67, 'iter_time': 0.12409262339274088, 'flops': 17693781889056.6, 'remaining_time': 49.51295673370361}\n",
            "DEBUG:__main__:Step (602) Logs: {'loss': 1.5257, 'grad_norm': 49.50148391723633, 'learning_rate': 3.983983983983984e-06, 'epoch': 2.68, 'iter_time': 0.1240700215547533, 'flops': 17697005165611.504, 'remaining_time': 49.379868578791815}\n",
            "DEBUG:__main__:Step (603) Logs: {'loss': 1.9708, 'grad_norm': 52.71395492553711, 'learning_rate': 3.973973973973974e-06, 'epoch': 2.68, 'iter_time': 0.12404699064172384, 'flops': 17700290841344.086, 'remaining_time': 49.246655284764365}\n",
            "DEBUG:__main__:Step (604) Logs: {'loss': 2.36, 'grad_norm': 72.13583374023438, 'learning_rate': 3.9639639639639645e-06, 'epoch': 2.68, 'iter_time': 0.12402488224541963, 'flops': 17703446055342.562, 'remaining_time': 49.113853369186174}\n",
            "DEBUG:__main__:Step (605) Logs: {'loss': 1.6255, 'grad_norm': 46.806884765625, 'learning_rate': 3.953953953953955e-06, 'epoch': 2.69, 'iter_time': 0.12400164746290801, 'flops': 17706763234809.273, 'remaining_time': 48.980650747848664}\n",
            "DEBUG:__main__:Step (606) Logs: {'loss': 2.5214, 'grad_norm': 53.04594421386719, 'learning_rate': 3.943943943943944e-06, 'epoch': 2.69, 'iter_time': 0.1239788138176784, 'flops': 17710024356104.26, 'remaining_time': 48.847652644165294}\n",
            "DEBUG:__main__:Step (607) Logs: {'loss': 1.6569, 'grad_norm': 45.10271072387695, 'learning_rate': 3.933933933933934e-06, 'epoch': 2.7, 'iter_time': 0.1239577315428076, 'flops': 17713036411881.637, 'remaining_time': 48.71538849632339}\n",
            "DEBUG:__main__:Step (608) Logs: {'loss': 1.9175, 'grad_norm': 52.36405944824219, 'learning_rate': 3.923923923923924e-06, 'epoch': 2.7, 'iter_time': 0.12394327975969142, 'flops': 17715101751455.11, 'remaining_time': 48.58576566579904}\n",
            "DEBUG:__main__:Step (609) Logs: {'loss': 1.6323, 'grad_norm': 52.08634948730469, 'learning_rate': 3.9139139139139145e-06, 'epoch': 2.71, 'iter_time': 0.1239217127624311, 'flops': 17718184839498.547, 'remaining_time': 48.453389690110555}\n",
            "DEBUG:__main__:Step (610) Logs: {'loss': 2.1446, 'grad_norm': 49.076351165771484, 'learning_rate': 3.903903903903904e-06, 'epoch': 2.71, 'iter_time': 0.1238999985317487, 'flops': 17721290059494.004, 'remaining_time': 48.32099942738199}\n",
            "DEBUG:__main__:Step (611) Logs: {'loss': 2.3039, 'grad_norm': 57.7092399597168, 'learning_rate': 3.893893893893894e-06, 'epoch': 2.72, 'iter_time': 0.12387902150388624, 'flops': 17724290890391.953, 'remaining_time': 48.18893936501175}\n",
            "DEBUG:__main__:Step (612) Logs: {'loss': 2.0136, 'grad_norm': 66.99267578125, 'learning_rate': 3.883883883883884e-06, 'epoch': 2.72, 'iter_time': 0.12385613438345601, 'flops': 17727566125665.27, 'remaining_time': 48.05618014078093}\n",
            "DEBUG:__main__:Step (613) Logs: {'loss': 2.5662, 'grad_norm': 73.67552947998047, 'learning_rate': 3.8738738738738744e-06, 'epoch': 2.72, 'iter_time': 0.12383360956229415, 'flops': 17730790696587.71, 'remaining_time': 47.92360690060784}\n",
            "DEBUG:__main__:Step (614) Logs: {'loss': 2.4355, 'grad_norm': 60.894962310791016, 'learning_rate': 3.863863863863865e-06, 'epoch': 2.73, 'iter_time': 0.1238106253874438, 'flops': 17734082236326.97, 'remaining_time': 47.790901399553306}\n",
            "DEBUG:__main__:Step (615) Logs: {'loss': 2.147, 'grad_norm': 74.70272064208984, 'learning_rate': 3.853853853853854e-06, 'epoch': 2.73, 'iter_time': 0.12378801390868445, 'flops': 17737321595382.355, 'remaining_time': 47.65838535484351}\n",
            "DEBUG:__main__:Step (616) Logs: {'loss': 2.719, 'grad_norm': 65.83447265625, 'learning_rate': 3.843843843843844e-06, 'epoch': 2.74, 'iter_time': 0.12376828387500793, 'flops': 17740149120669.54, 'remaining_time': 47.52702100800305}\n",
            "DEBUG:__main__:Step (617) Logs: {'loss': 1.7552, 'grad_norm': 47.56088638305664, 'learning_rate': 3.833833833833834e-06, 'epoch': 2.74, 'iter_time': 0.12375039055749967, 'flops': 17742714204459.82, 'remaining_time': 47.396399583522374}\n",
            "DEBUG:__main__:Step (618) Logs: {'loss': 2.6473, 'grad_norm': 81.20954132080078, 'learning_rate': 3.823823823823824e-06, 'epoch': 2.75, 'iter_time': 0.12373024486065684, 'flops': 17745603064349.613, 'remaining_time': 47.26495353677091}\n",
            "DEBUG:__main__:Step (619) Logs: {'loss': 2.1919, 'grad_norm': 56.75724411010742, 'learning_rate': 3.8138138138138143e-06, 'epoch': 2.75, 'iter_time': 0.12371113693829879, 'flops': 17748343978498.027, 'remaining_time': 47.133943173491836}\n",
            "DEBUG:__main__:Step (620) Logs: {'loss': 1.668, 'grad_norm': 43.949520111083984, 'learning_rate': 3.803803803803804e-06, 'epoch': 2.76, 'iter_time': 0.12369040795789975, 'flops': 17751318381125.68, 'remaining_time': 47.00235502400191}\n",
            "DEBUG:__main__:Step (621) Logs: {'loss': 2.0231, 'grad_norm': 58.17148208618164, 'learning_rate': 3.793793793793794e-06, 'epoch': 2.76, 'iter_time': 0.12367063299302132, 'flops': 17754156821336.08, 'remaining_time': 46.87116990435508}\n",
            "DEBUG:__main__:Step (622) Logs: {'loss': 2.3323, 'grad_norm': 74.13912200927734, 'learning_rate': 3.7837837837837844e-06, 'epoch': 2.76, 'iter_time': 0.12365438742338171, 'flops': 17756489341815.484, 'remaining_time': 46.741358446038284}\n",
            "DEBUG:__main__:Step (623) Logs: {'loss': 2.5844, 'grad_norm': 47.280391693115234, 'learning_rate': 3.773773773773774e-06, 'epoch': 2.77, 'iter_time': 0.12363321068202568, 'flops': 17759530794675.184, 'remaining_time': 46.60972042712368}\n",
            "DEBUG:__main__:Step (624) Logs: {'loss': 2.7895, 'grad_norm': 63.90058898925781, 'learning_rate': 3.7637637637637643e-06, 'epoch': 2.77, 'iter_time': 0.12361260172260707, 'flops': 17762491701931.73, 'remaining_time': 46.47833824770026}\n",
            "DEBUG:__main__:Step (625) Logs: {'loss': 2.1753, 'grad_norm': 70.0203628540039, 'learning_rate': 3.7537537537537537e-06, 'epoch': 2.78, 'iter_time': 0.12359259373102432, 'flops': 17765367212297.945, 'remaining_time': 46.347222649134125}\n",
            "DEBUG:__main__:Step (626) Logs: {'loss': 1.5249, 'grad_norm': 60.320072174072266, 'learning_rate': 3.743743743743744e-06, 'epoch': 2.78, 'iter_time': 0.12357120552062988, 'flops': 17768442114821.312, 'remaining_time': 46.21563086471557}\n",
            "DEBUG:__main__:Step (627) Logs: {'loss': 2.3629, 'grad_norm': 70.09028625488281, 'learning_rate': 3.7337337337337345e-06, 'epoch': 2.79, 'iter_time': 0.12356145465716767, 'flops': 17769844313051.164, 'remaining_time': 46.08842258712354}\n",
            "DEBUG:__main__:Step (628) Logs: {'loss': 1.5249, 'grad_norm': 39.42600631713867, 'learning_rate': 3.723723723723724e-06, 'epoch': 2.79, 'iter_time': 0.1235420913027044, 'flops': 17772629467410.805, 'remaining_time': 45.957657964606035}\n",
            "DEBUG:__main__:Step (629) Logs: {'loss': 1.7544, 'grad_norm': 73.40766906738281, 'learning_rate': 3.713713713713714e-06, 'epoch': 2.8, 'iter_time': 0.12351974712055959, 'flops': 17775844458367.87, 'remaining_time': 45.82582618172761}\n",
            "DEBUG:__main__:Step (630) Logs: {'loss': 3.0196, 'grad_norm': 57.52819061279297, 'learning_rate': 3.7037037037037037e-06, 'epoch': 2.8, 'iter_time': 0.12350022546437663, 'flops': 17778654282581.336, 'remaining_time': 45.695083421819355}\n",
            "DEBUG:__main__:Step (631) Logs: {'loss': 2.0784, 'grad_norm': 45.251014709472656, 'learning_rate': 3.693693693693694e-06, 'epoch': 2.8, 'iter_time': 0.12347947832137819, 'flops': 17781641469502.88, 'remaining_time': 45.563927500588555}\n",
            "DEBUG:__main__:Step (632) Logs: {'loss': 2.303, 'grad_norm': 60.253299713134766, 'learning_rate': 3.683683683683684e-06, 'epoch': 2.81, 'iter_time': 0.12345818785593363, 'flops': 17784707928113.918, 'remaining_time': 45.432613130983576}\n",
            "DEBUG:__main__:Step (633) Logs: {'loss': 2.507, 'grad_norm': 45.3293571472168, 'learning_rate': 3.673673673673674e-06, 'epoch': 2.81, 'iter_time': 0.12343839716307725, 'flops': 17787559323629.695, 'remaining_time': 45.30189175884935}\n",
            "DEBUG:__main__:Step (634) Logs: {'loss': 1.6004, 'grad_norm': 51.20840072631836, 'learning_rate': 3.663663663663664e-06, 'epoch': 2.82, 'iter_time': 0.12342067314738535, 'flops': 17790113733458.56, 'remaining_time': 45.171966371943036}\n",
            "DEBUG:__main__:Step (635) Logs: {'loss': 2.6674, 'grad_norm': 196.42184448242188, 'learning_rate': 3.653653653653654e-06, 'epoch': 2.82, 'iter_time': 0.12340245412351206, 'flops': 17792740249350.164, 'remaining_time': 45.0418957550819}\n",
            "DEBUG:__main__:Step (636) Logs: {'loss': 1.5717, 'grad_norm': 42.951080322265625, 'learning_rate': 3.643643643643644e-06, 'epoch': 2.83, 'iter_time': 0.12338319725877657, 'flops': 17795517227089.984, 'remaining_time': 44.911483802194674}\n",
            "DEBUG:__main__:Step (637) Logs: {'loss': 2.5048, 'grad_norm': 72.3809814453125, 'learning_rate': 3.633633633633634e-06, 'epoch': 2.83, 'iter_time': 0.12336648860067692, 'flops': 17797927437645.754, 'remaining_time': 44.782035362045725}\n",
            "DEBUG:__main__:Step (638) Logs: {'loss': 1.8092, 'grad_norm': 73.66197967529297, 'learning_rate': 3.623623623623624e-06, 'epoch': 2.84, 'iter_time': 0.12334933984597773, 'flops': 17800401810773.03, 'remaining_time': 44.65246102424394}\n",
            "DEBUG:__main__:Step (639) Logs: {'loss': 2.1227, 'grad_norm': 64.81378936767578, 'learning_rate': 3.613613613613614e-06, 'epoch': 2.84, 'iter_time': 0.12332869771879669, 'flops': 17803381151063.23, 'remaining_time': 44.52165987648561}\n",
            "DEBUG:__main__:Step (640) Logs: {'loss': 2.0698, 'grad_norm': 74.59635925292969, 'learning_rate': 3.603603603603604e-06, 'epoch': 2.84, 'iter_time': 0.12330873583404112, 'flops': 17806263258647.85, 'remaining_time': 44.3911449002548}\n",
            "DEBUG:__main__:Step (641) Logs: {'loss': 2.2969, 'grad_norm': 62.38369369506836, 'learning_rate': 3.593593593593594e-06, 'epoch': 2.85, 'iter_time': 0.12328837886452675, 'flops': 17809203369967.83, 'remaining_time': 44.2605280123651}\n",
            "DEBUG:__main__:Step (642) Logs: {'loss': 2.3882, 'grad_norm': 46.21842956542969, 'learning_rate': 3.5835835835835834e-06, 'epoch': 2.85, 'iter_time': 0.12326963420219243, 'flops': 17811911478138.777, 'remaining_time': 44.13052904438489}\n",
            "DEBUG:__main__:Step (643) Logs: {'loss': 2.1209, 'grad_norm': 64.2359619140625, 'learning_rate': 3.573573573573574e-06, 'epoch': 2.86, 'iter_time': 0.12325025050439567, 'flops': 17814712776374.375, 'remaining_time': 44.00033943006925}\n",
            "DEBUG:__main__:Step (644) Logs: {'loss': 1.9915, 'grad_norm': 46.59039306640625, 'learning_rate': 3.563563563563564e-06, 'epoch': 2.86, 'iter_time': 0.12322957334028989, 'flops': 17817701975554.33, 'remaining_time': 43.8697281091432}\n",
            "DEBUG:__main__:Step (645) Logs: {'loss': 2.9027, 'grad_norm': 57.58051300048828, 'learning_rate': 3.5535535535535535e-06, 'epoch': 2.87, 'iter_time': 0.12321836126517065, 'flops': 17819323271365.69, 'remaining_time': 43.74251824913558}\n",
            "DEBUG:__main__:Step (646) Logs: {'loss': 2.281, 'grad_norm': 64.60279846191406, 'learning_rate': 3.5435435435435437e-06, 'epoch': 2.87, 'iter_time': 0.12320111481718314, 'flops': 17821817729572.73, 'remaining_time': 43.61319464528283}\n",
            "DEBUG:__main__:Step (647) Logs: {'loss': 2.0411, 'grad_norm': 59.44171142578125, 'learning_rate': 3.5335335335335335e-06, 'epoch': 2.88, 'iter_time': 0.12318080349972374, 'flops': 17824756374128.734, 'remaining_time': 43.48282363540248}\n",
            "DEBUG:__main__:Step (648) Logs: {'loss': 2.0369, 'grad_norm': 41.84474563598633, 'learning_rate': 3.5235235235235237e-06, 'epoch': 2.88, 'iter_time': 0.12315955670576376, 'flops': 17827831400835.535, 'remaining_time': 43.35216396042884}\n",
            "DEBUG:__main__:Step (649) Logs: {'loss': 1.9356, 'grad_norm': 107.24658203125, 'learning_rate': 3.513513513513514e-06, 'epoch': 2.88, 'iter_time': 0.12313986707616735, 'flops': 17830682008076.914, 'remaining_time': 43.22209334373474}\n",
            "DEBUG:__main__:Step (650) Logs: {'loss': 2.3754, 'grad_norm': 80.05209350585938, 'learning_rate': 3.5035035035035036e-06, 'epoch': 2.89, 'iter_time': 0.12311940347468725, 'flops': 17833645634933.723, 'remaining_time': 43.091791216140535}\n",
            "DEBUG:__main__:Step (651) Logs: {'loss': 1.9762, 'grad_norm': 52.761653900146484, 'learning_rate': 3.4934934934934938e-06, 'epoch': 2.89, 'iter_time': 0.123100067285391, 'flops': 17836446890493.07, 'remaining_time': 42.961923482601456}\n",
            "DEBUG:__main__:Step (652) Logs: {'loss': 1.8146, 'grad_norm': 97.76249694824219, 'learning_rate': 3.4834834834834835e-06, 'epoch': 2.9, 'iter_time': 0.12307938965418005, 'flops': 17839443456140.26, 'remaining_time': 42.83162759965466}\n",
            "DEBUG:__main__:Step (653) Logs: {'loss': 2.1738, 'grad_norm': 58.45570755004883, 'learning_rate': 3.4734734734734737e-06, 'epoch': 2.9, 'iter_time': 0.12305945999051895, 'flops': 17842332580698.5, 'remaining_time': 42.70163261671008}\n",
            "DEBUG:__main__:Step (654) Logs: {'loss': 2.0007, 'grad_norm': 46.31528091430664, 'learning_rate': 3.463463463463464e-06, 'epoch': 2.91, 'iter_time': 0.12305859511698188, 'flops': 17842457979182.65, 'remaining_time': 42.57827391047573}\n",
            "DEBUG:__main__:Step (655) Logs: {'loss': 2.2813, 'grad_norm': 49.89136505126953, 'learning_rate': 3.4534534534534537e-06, 'epoch': 2.91, 'iter_time': 0.12304350979831241, 'flops': 17844645491266.004, 'remaining_time': 42.45001088041778}\n",
            "DEBUG:__main__:Step (656) Logs: {'loss': 1.854, 'grad_norm': 43.91365432739258, 'learning_rate': 3.443443443443444e-06, 'epoch': 2.92, 'iter_time': 0.12302626762681335, 'flops': 17847146424146.727, 'remaining_time': 42.321036063623794}\n",
            "DEBUG:__main__:Step (657) Logs: {'loss': 2.4746, 'grad_norm': 89.20600891113281, 'learning_rate': 3.4334334334334336e-06, 'epoch': 2.92, 'iter_time': 0.12300710743520318, 'flops': 17849926383389.01, 'remaining_time': 42.19143785027469}\n",
            "DEBUG:__main__:Step (658) Logs: {'loss': 2.6857, 'grad_norm': 66.83251190185547, 'learning_rate': 3.423423423423424e-06, 'epoch': 2.92, 'iter_time': 0.1229885237764913, 'flops': 17852623520729.598, 'remaining_time': 42.06207513156003}\n",
            "DEBUG:__main__:Step (659) Logs: {'loss': 2.4648, 'grad_norm': 60.17351150512695, 'learning_rate': 3.413413413413414e-06, 'epoch': 2.93, 'iter_time': 0.12297080171869156, 'flops': 17855196369092.703, 'remaining_time': 41.93304338607382}\n",
            "DEBUG:__main__:Step (660) Logs: {'loss': 1.7547, 'grad_norm': 49.58919143676758, 'learning_rate': 3.4034034034034037e-06, 'epoch': 2.93, 'iter_time': 0.12295261391739563, 'flops': 17857837604226.418, 'remaining_time': 41.80388873191452}\n",
            "DEBUG:__main__:Step (661) Logs: {'loss': 1.9404, 'grad_norm': 51.559207916259766, 'learning_rate': 3.393393393393394e-06, 'epoch': 2.94, 'iter_time': 0.12293410228960441, 'flops': 17860526668015.297, 'remaining_time': 41.6746606761759}\n",
            "DEBUG:__main__:Step (662) Logs: {'loss': 2.1369, 'grad_norm': 48.22620391845703, 'learning_rate': 3.3833833833833833e-06, 'epoch': 2.94, 'iter_time': 0.1229219119234994, 'flops': 17862297925519.387, 'remaining_time': 41.5476062301428}\n",
            "DEBUG:__main__:Step (663) Logs: {'loss': 1.8792, 'grad_norm': 59.368019104003906, 'learning_rate': 3.373373373373374e-06, 'epoch': 2.95, 'iter_time': 0.12291354643254121, 'flops': 17863513632787.832, 'remaining_time': 41.42186514776639}\n",
            "DEBUG:__main__:Step (664) Logs: {'loss': 1.8986, 'grad_norm': 52.68195724487305, 'learning_rate': 3.363363363363364e-06, 'epoch': 2.95, 'iter_time': 0.12289966357419574, 'flops': 17865531511617.637, 'remaining_time': 41.29428696092977}\n",
            "DEBUG:__main__:Step (665) Logs: {'loss': 1.341, 'grad_norm': 57.7369384765625, 'learning_rate': 3.3533533533533534e-06, 'epoch': 2.96, 'iter_time': 0.12288113279515002, 'flops': 17868225677999.777, 'remaining_time': 41.16517948637526}\n",
            "DEBUG:__main__:Step (666) Logs: {'loss': 2.1727, 'grad_norm': 59.97798156738281, 'learning_rate': 3.3433433433433436e-06, 'epoch': 2.96, 'iter_time': 0.12286191775386494, 'flops': 17871020186667.48, 'remaining_time': 41.035880529790894}\n",
            "DEBUG:__main__:Step (667) Logs: {'loss': 2.0751, 'grad_norm': 54.277191162109375, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.96, 'iter_time': 0.12284819714657895, 'flops': 17873016156127.973, 'remaining_time': 40.90844964981079}\n",
            "DEBUG:__main__:Step (668) Logs: {'loss': 2.2367, 'grad_norm': 63.85875701904297, 'learning_rate': 3.3233233233233235e-06, 'epoch': 2.97, 'iter_time': 0.12283167417260303, 'flops': 17875420384376.168, 'remaining_time': 40.78011582530421}\n",
            "DEBUG:__main__:Step (669) Logs: {'loss': 1.9629, 'grad_norm': 61.29084014892578, 'learning_rate': 3.3133133133133137e-06, 'epoch': 2.97, 'iter_time': 0.12281194989552754, 'flops': 17878291275562.266, 'remaining_time': 40.65075541541962}\n",
            "DEBUG:__main__:Step (670) Logs: {'loss': 2.0364, 'grad_norm': 56.60102462768555, 'learning_rate': 3.3033033033033035e-06, 'epoch': 2.98, 'iter_time': 0.12279194281596596, 'flops': 17881204271217.94, 'remaining_time': 40.52134112926877}\n",
            "DEBUG:__main__:Step (671) Logs: {'loss': 1.6169, 'grad_norm': 48.69011306762695, 'learning_rate': 3.2932932932932936e-06, 'epoch': 2.98, 'iter_time': 0.12277359962463379, 'flops': 17883875841915.547, 'remaining_time': 40.392514276504514}\n",
            "DEBUG:__main__:Step (672) Logs: {'loss': 1.7804, 'grad_norm': 36.282142639160156, 'learning_rate': 3.2832832832832834e-06, 'epoch': 2.99, 'iter_time': 0.12276397732082316, 'flops': 17885277589320.758, 'remaining_time': 40.26658456123}\n",
            "DEBUG:__main__:Step (673) Logs: {'loss': 1.894, 'grad_norm': 71.8219985961914, 'learning_rate': 3.2732732732732736e-06, 'epoch': 2.99, 'iter_time': 0.12275090920073646, 'flops': 17887181664466.457, 'remaining_time': 40.13954730864082}\n",
            "DEBUG:__main__:Step (674) Logs: {'loss': 2.6579, 'grad_norm': 48.30643081665039, 'learning_rate': 3.2632632632632633e-06, 'epoch': 3.0, 'iter_time': 0.12273167217645745, 'flops': 17889985310353.95, 'remaining_time': 40.01052512952513}\n",
            "DEBUG:__main__:Step (675) Logs: {'loss': 2.0968, 'grad_norm': 54.09431076049805, 'learning_rate': 3.2532532532532535e-06, 'epoch': 3.0, 'iter_time': 0.12271442469927961, 'flops': 17892499742655.68, 'remaining_time': 39.882188027265876}\n",
            "DEBUG:__main__:Step (676) Logs: {'loss': 2.2074, 'grad_norm': 78.2652587890625, 'learning_rate': 3.2432432432432437e-06, 'epoch': 3.0, 'iter_time': 0.12270001305474175, 'flops': 17894601293745.734, 'remaining_time': 39.75480422973633}\n",
            "DEBUG:__main__:Step (677) Logs: {'loss': 2.0753, 'grad_norm': 59.952545166015625, 'learning_rate': 3.2332332332332335e-06, 'epoch': 3.01, 'iter_time': 0.1226865977225219, 'flops': 17896558003164.312, 'remaining_time': 39.62777106437457}\n",
            "DEBUG:__main__:Step (678) Logs: {'loss': 1.3793, 'grad_norm': 73.22164154052734, 'learning_rate': 3.2232232232232236e-06, 'epoch': 3.01, 'iter_time': 0.12267256100033376, 'flops': 17898605804325.11, 'remaining_time': 39.50056464210747}\n",
            "DEBUG:__main__:Step (679) Logs: {'loss': 1.973, 'grad_norm': 45.89640426635742, 'learning_rate': 3.2132132132132134e-06, 'epoch': 3.02, 'iter_time': 0.12265556048502964, 'flops': 17901086617430.49, 'remaining_time': 39.37243491569451}\n",
            "DEBUG:__main__:Step (680) Logs: {'loss': 1.8688, 'grad_norm': 46.477752685546875, 'learning_rate': 3.2032032032032036e-06, 'epoch': 3.02, 'iter_time': 0.12264087168562922, 'flops': 17903230645491.926, 'remaining_time': 39.24507893940135}\n",
            "DEBUG:__main__:Step (681) Logs: {'loss': 1.9794, 'grad_norm': 63.41972732543945, 'learning_rate': 3.1931931931931938e-06, 'epoch': 3.03, 'iter_time': 0.12263554790440728, 'flops': 17904007849856.82, 'remaining_time': 39.120739781505925}\n",
            "DEBUG:__main__:Step (682) Logs: {'loss': 1.9966, 'grad_norm': 45.80357360839844, 'learning_rate': 3.183183183183183e-06, 'epoch': 3.03, 'iter_time': 0.12262189720870814, 'flops': 17906000986225.746, 'remaining_time': 38.99376331236919}\n",
            "DEBUG:__main__:Step (683) Logs: {'loss': 1.83, 'grad_norm': 42.641685485839844, 'learning_rate': 3.1731731731731737e-06, 'epoch': 3.04, 'iter_time': 0.122611081495313, 'flops': 17907580502305.03, 'remaining_time': 38.86771283401422}\n",
            "DEBUG:__main__:Step (684) Logs: {'loss': 2.518, 'grad_norm': 75.46916198730469, 'learning_rate': 3.163163163163163e-06, 'epoch': 3.04, 'iter_time': 0.12260099211339545, 'flops': 17909054196895.85, 'remaining_time': 38.74191350783296}\n",
            "DEBUG:__main__:Step (685) Logs: {'loss': 2.0197, 'grad_norm': 41.6472282409668, 'learning_rate': 3.1531531531531532e-06, 'epoch': 3.04, 'iter_time': 0.12258515371913799, 'flops': 17911368104025.246, 'remaining_time': 38.61432342152847}\n",
            "DEBUG:__main__:Step (686) Logs: {'loss': 2.5849, 'grad_norm': 52.19874954223633, 'learning_rate': 3.1431431431431434e-06, 'epoch': 3.05, 'iter_time': 0.12256993133656299, 'flops': 17913592578614.96, 'remaining_time': 38.48695843968078}\n",
            "DEBUG:__main__:Step (687) Logs: {'loss': 1.828, 'grad_norm': 51.531471252441406, 'learning_rate': 3.133133133133133e-06, 'epoch': 3.05, 'iter_time': 0.12255666520088129, 'flops': 17915531633902.61, 'remaining_time': 38.36023620787584}\n",
            "DEBUG:__main__:Step (688) Logs: {'loss': 1.9963, 'grad_norm': 59.869163513183594, 'learning_rate': 3.1231231231231234e-06, 'epoch': 3.06, 'iter_time': 0.12254047012051467, 'flops': 17917899369837.82, 'remaining_time': 38.23262667760058}\n",
            "DEBUG:__main__:Step (689) Logs: {'loss': 1.5969, 'grad_norm': 45.1409797668457, 'learning_rate': 3.113113113113113e-06, 'epoch': 3.06, 'iter_time': 0.12252779408942821, 'flops': 17919753054147.605, 'remaining_time': 38.10614396181217}\n",
            "DEBUG:__main__:Step (690) Logs: {'loss': 1.9752, 'grad_norm': 54.19895935058594, 'learning_rate': 3.1031031031031033e-06, 'epoch': 3.07, 'iter_time': 0.12251145400225856, 'flops': 17922143119054.99, 'remaining_time': 37.97855074070015}\n",
            "DEBUG:__main__:Step (691) Logs: {'loss': 1.3545, 'grad_norm': 42.83186340332031, 'learning_rate': 3.0930930930930935e-06, 'epoch': 3.07, 'iter_time': 0.12249675833660623, 'flops': 17924293198996.918, 'remaining_time': 37.851498326011324}\n",
            "DEBUG:__main__:Step (692) Logs: {'loss': 1.7627, 'grad_norm': 40.85564041137695, 'learning_rate': 3.0830830830830832e-06, 'epoch': 3.08, 'iter_time': 0.12248076233263472, 'flops': 17926634114090.336, 'remaining_time': 37.7240747984515}\n",
            "DEBUG:__main__:Step (693) Logs: {'loss': 1.7435, 'grad_norm': 44.25999069213867, 'learning_rate': 3.0730730730730734e-06, 'epoch': 3.08, 'iter_time': 0.12246430195824948, 'flops': 17929043625305.168, 'remaining_time': 37.59654070118259}\n",
            "DEBUG:__main__:Step (694) Logs: {'loss': 1.8652, 'grad_norm': 44.24723815917969, 'learning_rate': 3.063063063063063e-06, 'epoch': 3.08, 'iter_time': 0.12244869551445327, 'flops': 17931328734268.418, 'remaining_time': 37.4693008274227}\n",
            "DEBUG:__main__:Step (695) Logs: {'loss': 1.5987, 'grad_norm': 42.75104904174805, 'learning_rate': 3.0530530530530534e-06, 'epoch': 3.09, 'iter_time': 0.12243466315420629, 'flops': 17933383861942.426, 'remaining_time': 37.34257226203292}\n",
            "DEBUG:__main__:Step (696) Logs: {'loss': 2.0268, 'grad_norm': 84.13370513916016, 'learning_rate': 3.0430430430430436e-06, 'epoch': 3.09, 'iter_time': 0.123056862165602, 'flops': 17842709246049.293, 'remaining_time': 37.409286098343}\n",
            "DEBUG:__main__:Step (697) Logs: {'loss': 2.6246, 'grad_norm': 105.3775634765625, 'learning_rate': 3.0330330330330333e-06, 'epoch': 3.1, 'iter_time': 0.12303976868760996, 'flops': 17845188070262.543, 'remaining_time': 37.28104991234582}\n",
            "DEBUG:__main__:Step (698) Logs: {'loss': 1.568, 'grad_norm': 65.04859924316406, 'learning_rate': 3.0230230230230235e-06, 'epoch': 3.1, 'iter_time': 0.12302235140862047, 'flops': 17847714559275.97, 'remaining_time': 37.15275012540338}\n",
            "DEBUG:__main__:Step (699) Logs: {'loss': 2.0208, 'grad_norm': 50.04125213623047, 'learning_rate': 3.0130130130130133e-06, 'epoch': 3.11, 'iter_time': 0.12300690436431536, 'flops': 17849955851656.805, 'remaining_time': 37.02507821365892}\n",
            "DEBUG:__main__:Step (700) Logs: {'loss': 1.2679, 'grad_norm': 45.98645782470703, 'learning_rate': 3.0030030030030034e-06, 'epoch': 3.11, 'iter_time': 0.12299079615329639, 'flops': 17852293675823.58, 'remaining_time': 36.897238845988916}\n",
            "DEBUG:__main__:Step (701) Logs: {'loss': 2.3347, 'grad_norm': 54.181949615478516, 'learning_rate': 2.9929929929929936e-06, 'epoch': 3.12, 'iter_time': 0.1229719751221793, 'flops': 17855025994097.316, 'remaining_time': 36.76862056153161}\n",
            "DEBUG:__main__:Step (702) Logs: {'loss': 1.8523, 'grad_norm': 62.466453552246094, 'learning_rate': 2.982982982982983e-06, 'epoch': 3.12, 'iter_time': 0.12295671638510537, 'flops': 17857241775024.965, 'remaining_time': 36.6411014827614}\n",
            "DEBUG:__main__:Step (703) Logs: {'loss': 2.0377, 'grad_norm': 53.6295166015625, 'learning_rate': 2.9729729729729736e-06, 'epoch': 3.12, 'iter_time': 0.12294217765840709, 'flops': 17859353512125.258, 'remaining_time': 36.513826764546906}\n",
            "DEBUG:__main__:Step (704) Logs: {'loss': 1.3994, 'grad_norm': 56.27705383300781, 'learning_rate': 2.962962962962963e-06, 'epoch': 3.13, 'iter_time': 0.12292443366342384, 'flops': 17861931488445.17, 'remaining_time': 36.38563236437346}\n",
            "DEBUG:__main__:Step (705) Logs: {'loss': 1.5497, 'grad_norm': 56.088592529296875, 'learning_rate': 2.952952952952953e-06, 'epoch': 3.13, 'iter_time': 0.12290628830140288, 'flops': 17864568548092.246, 'remaining_time': 36.25735504891385}\n",
            "DEBUG:__main__:Step (706) Logs: {'loss': 1.2006, 'grad_norm': 39.96525192260742, 'learning_rate': 2.942942942942943e-06, 'epoch': 3.14, 'iter_time': 0.12289060937597397, 'flops': 17866847788463.074, 'remaining_time': 36.12983915653635}\n",
            "DEBUG:__main__:Step (707) Logs: {'loss': 1.5558, 'grad_norm': 52.995216369628906, 'learning_rate': 2.932932932932933e-06, 'epoch': 3.14, 'iter_time': 0.12287466215344393, 'flops': 17869166627779.492, 'remaining_time': 36.00227601095907}\n",
            "DEBUG:__main__:Step (708) Logs: {'loss': 1.6349, 'grad_norm': 54.86974334716797, 'learning_rate': 2.9229229229229232e-06, 'epoch': 3.15, 'iter_time': 0.12285848520432706, 'flops': 17871519486019.75, 'remaining_time': 35.8746776796635}\n",
            "DEBUG:__main__:Step (709) Logs: {'loss': 2.0244, 'grad_norm': 61.33913803100586, 'learning_rate': 2.912912912912913e-06, 'epoch': 3.15, 'iter_time': 0.12284225360148371, 'flops': 17873880916211.72, 'remaining_time': 35.74709579803176}\n",
            "DEBUG:__main__:Step (710) Logs: {'loss': 2.2148, 'grad_norm': 62.87237548828125, 'learning_rate': 2.902902902902903e-06, 'epoch': 3.16, 'iter_time': 0.1228237908717103, 'flops': 17876567697258.094, 'remaining_time': 35.618899352795985}\n",
            "DEBUG:__main__:Step (711) Logs: {'loss': 2.0771, 'grad_norm': 64.36898040771484, 'learning_rate': 2.892892892892893e-06, 'epoch': 3.16, 'iter_time': 0.1228065507512697, 'flops': 17879077287978.457, 'remaining_time': 35.491093167116944}\n",
            "DEBUG:__main__:Step (712) Logs: {'loss': 1.798, 'grad_norm': 54.89597702026367, 'learning_rate': 2.882882882882883e-06, 'epoch': 3.16, 'iter_time': 0.12279179595861421, 'flops': 17881225656899.98, 'remaining_time': 35.36403723608089}\n",
            "DEBUG:__main__:Step (713) Logs: {'loss': 1.8748, 'grad_norm': 53.750770568847656, 'learning_rate': 2.8728728728728733e-06, 'epoch': 3.17, 'iter_time': 0.1227758801385258, 'flops': 17883543655925.477, 'remaining_time': 35.23667759975691}\n",
            "DEBUG:__main__:Step (714) Logs: {'loss': 1.9225, 'grad_norm': 71.48187255859375, 'learning_rate': 2.862862862862863e-06, 'epoch': 3.17, 'iter_time': 0.122760876030942, 'flops': 17885729422447.098, 'remaining_time': 35.10961054484941}\n",
            "DEBUG:__main__:Step (715) Logs: {'loss': 2.3185, 'grad_norm': 83.57661437988281, 'learning_rate': 2.8528528528528532e-06, 'epoch': 3.18, 'iter_time': 0.12274358319301232, 'flops': 17888249269204.953, 'remaining_time': 34.98192121000851}\n",
            "DEBUG:__main__:Step (716) Logs: {'loss': 2.488, 'grad_norm': 78.77494812011719, 'learning_rate': 2.842842842842843e-06, 'epoch': 3.18, 'iter_time': 0.12272880194070455, 'flops': 17890403700125.902, 'remaining_time': 34.854979751160094}\n",
            "DEBUG:__main__:Step (717) Logs: {'loss': 2.3049, 'grad_norm': 43.41885757446289, 'learning_rate': 2.832832832832833e-06, 'epoch': 3.19, 'iter_time': 0.12271391612857414, 'flops': 17892573895624.664, 'remaining_time': 34.728038264386484}\n",
            "DEBUG:__main__:Step (718) Logs: {'loss': 2.381, 'grad_norm': 53.41317367553711, 'learning_rate': 2.8228228228228234e-06, 'epoch': 3.19, 'iter_time': 0.12269737963230873, 'flops': 17894985360990.023, 'remaining_time': 34.60066105631106}\n",
            "DEBUG:__main__:Step (719) Logs: {'loss': 1.6935, 'grad_norm': 51.29901123046875, 'learning_rate': 2.812812812812813e-06, 'epoch': 3.2, 'iter_time': 0.1226797120484801, 'flops': 17897562487628.96, 'remaining_time': 34.47299908562291}\n",
            "DEBUG:__main__:Step (720) Logs: {'loss': 2.1051, 'grad_norm': 69.87874603271484, 'learning_rate': 2.8028028028028033e-06, 'epoch': 3.2, 'iter_time': 0.12266173581586262, 'flops': 17900185398061.652, 'remaining_time': 34.345286028441535}\n",
            "DEBUG:__main__:Step (720) Logs: {'eval_loss': 2.9176137447357178, 'eval_runtime': 0.8317, 'eval_samples_per_second': 120.239, 'eval_steps_per_second': 120.239, 'epoch': 3.2, 'iter_time': 0.12382800489539729, 'flops': 17731593222444.09, 'remaining_time': 34.67184137071124}\n",
            "DEBUG:__main__:Step (721) Logs: {'loss': 2.6425, 'grad_norm': 85.55027770996094, 'learning_rate': 2.7927927927927926e-06, 'epoch': 3.2, 'iter_time': 0.12475714915328556, 'flops': 17599534994617.785, 'remaining_time': 34.80724461376667}\n",
            "DEBUG:__main__:Step (722) Logs: {'loss': 1.2713, 'grad_norm': 55.45558547973633, 'learning_rate': 2.782782782782783e-06, 'epoch': 3.21, 'iter_time': 0.12473737350283978, 'flops': 17602325194878.45, 'remaining_time': 34.676989833789456}\n",
            "DEBUG:__main__:Step (723) Logs: {'loss': 2.2876, 'grad_norm': 51.28318405151367, 'learning_rate': 2.7727727727727734e-06, 'epoch': 3.21, 'iter_time': 0.12471844383884335, 'flops': 17604996861483.953, 'remaining_time': 34.54700894335961}\n",
            "DEBUG:__main__:Step (724) Logs: {'loss': 2.2725, 'grad_norm': 56.45276641845703, 'learning_rate': 2.7627627627627628e-06, 'epoch': 3.22, 'iter_time': 0.12469905969348026, 'flops': 17607733512579.15, 'remaining_time': 34.41694047540055}\n",
            "DEBUG:__main__:Step (725) Logs: {'loss': 1.6901, 'grad_norm': 49.059757232666016, 'learning_rate': 2.752752752752753e-06, 'epoch': 3.22, 'iter_time': 0.1246843301788878, 'flops': 17609813592468.43, 'remaining_time': 34.28819079919415}\n",
            "DEBUG:__main__:Step (726) Logs: {'loss': 1.9285, 'grad_norm': 59.88516616821289, 'learning_rate': 2.7427427427427427e-06, 'epoch': 3.23, 'iter_time': 0.12466511594838109, 'flops': 17612527735995.848, 'remaining_time': 34.15824176985642}\n",
            "DEBUG:__main__:Step (727) Logs: {'loss': 1.3784, 'grad_norm': 50.563926696777344, 'learning_rate': 2.732732732732733e-06, 'epoch': 3.23, 'iter_time': 0.12464468735308687, 'flops': 17615414334766.06, 'remaining_time': 34.02799964739272}\n",
            "DEBUG:__main__:Step (728) Logs: {'loss': 1.7973, 'grad_norm': 81.03047943115234, 'learning_rate': 2.722722722722723e-06, 'epoch': 3.24, 'iter_time': 0.12462905184602803, 'flops': 17617624300509.164, 'remaining_time': 33.89910210211963}\n",
            "DEBUG:__main__:Step (729) Logs: {'loss': 2.1717, 'grad_norm': 55.44947814941406, 'learning_rate': 2.712712712712713e-06, 'epoch': 3.24, 'iter_time': 0.12461231141299992, 'flops': 17619991054294.348, 'remaining_time': 33.76993639292298}\n",
            "DEBUG:__main__:Step (730) Logs: {'loss': 2.7519, 'grad_norm': 59.43803405761719, 'learning_rate': 2.702702702702703e-06, 'epoch': 3.24, 'iter_time': 0.12459255703846286, 'flops': 17622784735641.77, 'remaining_time': 33.639990400384974}\n",
            "DEBUG:__main__:Step (731) Logs: {'loss': 2.1473, 'grad_norm': 70.97076416015625, 'learning_rate': 2.6926926926926928e-06, 'epoch': 3.25, 'iter_time': 0.12457413902021434, 'flops': 17625390226423.434, 'remaining_time': 33.51044339643766}\n",
            "DEBUG:__main__:Step (732) Logs: {'loss': 1.4482, 'grad_norm': 58.75294494628906, 'learning_rate': 2.682682682682683e-06, 'epoch': 3.25, 'iter_time': 0.12455388394002223, 'flops': 17628256485436.484, 'remaining_time': 33.38044089592596}\n",
            "DEBUG:__main__:Step (733) Logs: {'loss': 1.3781, 'grad_norm': 64.60033416748047, 'learning_rate': 2.672672672672673e-06, 'epoch': 3.26, 'iter_time': 0.12453391675740644, 'flops': 17631082917187.832, 'remaining_time': 33.25055577422752}\n",
            "DEBUG:__main__:Step (734) Logs: {'loss': 1.9928, 'grad_norm': 57.29939651489258, 'learning_rate': 2.662662662662663e-06, 'epoch': 3.26, 'iter_time': 0.12451435111229286, 'flops': 17633853389091.223, 'remaining_time': 33.1208173958699}\n",
            "DEBUG:__main__:Step (735) Logs: {'loss': 2.0952, 'grad_norm': 54.06943893432617, 'learning_rate': 2.652652652652653e-06, 'epoch': 3.27, 'iter_time': 0.12449624330536221, 'flops': 17636418208752.727, 'remaining_time': 32.99150447592098}\n",
            "DEBUG:__main__:Step (736) Logs: {'loss': 2.1253, 'grad_norm': 45.23236846923828, 'learning_rate': 2.642642642642643e-06, 'epoch': 3.27, 'iter_time': 0.12448024976821173, 'flops': 17638684180345.4, 'remaining_time': 32.862785938807896}\n",
            "DEBUG:__main__:Step (737) Logs: {'loss': 2.396, 'grad_norm': 49.82075119018555, 'learning_rate': 2.632632632632633e-06, 'epoch': 3.28, 'iter_time': 0.12446064663969952, 'flops': 17641462354829.535, 'remaining_time': 32.733150066240974}\n",
            "DEBUG:__main__:Step (738) Logs: {'loss': 1.8334, 'grad_norm': 73.588623046875, 'learning_rate': 2.6226226226226224e-06, 'epoch': 3.28, 'iter_time': 0.12444456493838348, 'flops': 17643742122760.812, 'remaining_time': 32.60447601385647}\n",
            "DEBUG:__main__:Step (739) Logs: {'loss': 1.5422, 'grad_norm': 41.05348587036133, 'learning_rate': 2.612612612612613e-06, 'epoch': 3.28, 'iter_time': 0.12442546679075495, 'flops': 17646450272470.605, 'remaining_time': 32.475046832387044}\n",
            "DEBUG:__main__:Step (740) Logs: {'loss': 2.0679, 'grad_norm': 66.8899917602539, 'learning_rate': 2.602602602602603e-06, 'epoch': 3.29, 'iter_time': 0.1244099165977096, 'flops': 17648655930313.7, 'remaining_time': 32.34657831540449}\n",
            "DEBUG:__main__:Step (741) Logs: {'loss': 1.8689, 'grad_norm': 112.63434600830078, 'learning_rate': 2.5925925925925925e-06, 'epoch': 3.29, 'iter_time': 0.12439512884294665, 'flops': 17650753954554.844, 'remaining_time': 32.21833837032318}\n",
            "DEBUG:__main__:Step (742) Logs: {'loss': 2.3504, 'grad_norm': 45.60649871826172, 'learning_rate': 2.5825825825825827e-06, 'epoch': 3.3, 'iter_time': 0.12437797590145054, 'flops': 17653188166462.14, 'remaining_time': 32.08951778257424}\n",
            "DEBUG:__main__:Step (743) Logs: {'loss': 2.0729, 'grad_norm': 61.97554016113281, 'learning_rate': 2.5725725725725724e-06, 'epoch': 3.3, 'iter_time': 0.12436184375433909, 'flops': 17655478127915.67, 'remaining_time': 31.960993844865147}\n",
            "DEBUG:__main__:Step (744) Logs: {'loss': 1.7001, 'grad_norm': 53.09598159790039, 'learning_rate': 2.5625625625625626e-06, 'epoch': 3.31, 'iter_time': 0.1243554579938886, 'flops': 17656384752005.86, 'remaining_time': 31.83499724643548}\n",
            "DEBUG:__main__:Step (745) Logs: {'loss': 2.0577, 'grad_norm': 62.097267150878906, 'learning_rate': 2.552552552552553e-06, 'epoch': 3.31, 'iter_time': 0.12433818815856852, 'flops': 17658837118905.613, 'remaining_time': 31.706237980434974}\n",
            "DEBUG:__main__:Step (746) Logs: {'loss': 1.822, 'grad_norm': 57.447914123535156, 'learning_rate': 2.5425425425425426e-06, 'epoch': 3.32, 'iter_time': 0.12432111509694349, 'flops': 17661262213099.164, 'remaining_time': 31.577563234623646}\n",
            "DEBUG:__main__:Step (747) Logs: {'loss': 1.9427, 'grad_norm': 53.91775131225586, 'learning_rate': 2.5325325325325327e-06, 'epoch': 3.32, 'iter_time': 0.12430428883345453, 'flops': 17663652903350.758, 'remaining_time': 31.448985074863995}\n",
            "DEBUG:__main__:Step (748) Logs: {'loss': 1.6782, 'grad_norm': 52.99278259277344, 'learning_rate': 2.5225225225225225e-06, 'epoch': 3.32, 'iter_time': 0.12429003766582035, 'flops': 17665678228013.016, 'remaining_time': 31.32108949178673}\n",
            "DEBUG:__main__:Step (749) Logs: {'loss': 1.9985, 'grad_norm': 53.196258544921875, 'learning_rate': 2.5125125125125127e-06, 'epoch': 3.33, 'iter_time': 0.12427619529917916, 'flops': 17667645900055.184, 'remaining_time': 31.19332502009397}\n",
            "DEBUG:__main__:Step (750) Logs: {'loss': 1.3051, 'grad_norm': 52.82052230834961, 'learning_rate': 2.502502502502503e-06, 'epoch': 3.33, 'iter_time': 0.12426124395770288, 'flops': 17669771703713.027, 'remaining_time': 31.065310989425722}\n",
            "DEBUG:__main__:Step (751) Logs: {'loss': 1.9147, 'grad_norm': 61.7917366027832, 'learning_rate': 2.4924924924924926e-06, 'epoch': 3.34, 'iter_time': 0.12424382559458415, 'flops': 17672248917355.54, 'remaining_time': 30.93671257305145}\n",
            "DEBUG:__main__:Step (752) Logs: {'loss': 1.4847, 'grad_norm': 54.68183135986328, 'learning_rate': 2.482482482482483e-06, 'epoch': 3.34, 'iter_time': 0.12422688505779729, 'flops': 17674658841606.25, 'remaining_time': 30.808267494333727}\n",
            "DEBUG:__main__:Step (753) Logs: {'loss': 2.1954, 'grad_norm': 65.41128540039062, 'learning_rate': 2.4724724724724726e-06, 'epoch': 3.35, 'iter_time': 0.12421424940545508, 'flops': 17676456790275.25, 'remaining_time': 30.680919603147405}\n",
            "DEBUG:__main__:Step (754) Logs: {'loss': 1.6442, 'grad_norm': 45.73096466064453, 'learning_rate': 2.4624624624624628e-06, 'epoch': 3.35, 'iter_time': 0.12419957468709147, 'flops': 17678545340302.23, 'remaining_time': 30.5530953730245}\n",
            "DEBUG:__main__:Step (755) Logs: {'loss': 1.5186, 'grad_norm': 52.672882080078125, 'learning_rate': 2.4524524524524525e-06, 'epoch': 3.36, 'iter_time': 0.12418146316821758, 'flops': 17681123706665.656, 'remaining_time': 30.424458476213307}\n",
            "DEBUG:__main__:Step (756) Logs: {'loss': 1.9812, 'grad_norm': 41.43498611450195, 'learning_rate': 2.4424424424424427e-06, 'epoch': 3.36, 'iter_time': 0.12416366362413823, 'flops': 17683658392995.0, 'remaining_time': 30.29593392428973}\n",
            "DEBUG:__main__:Step (757) Logs: {'loss': 1.8921, 'grad_norm': 52.18129348754883, 'learning_rate': 2.432432432432433e-06, 'epoch': 3.36, 'iter_time': 0.12414414226693452, 'flops': 17686439104238.03, 'remaining_time': 30.167026570865087}\n",
            "DEBUG:__main__:Step (758) Logs: {'loss': 1.9753, 'grad_norm': 50.19397735595703, 'learning_rate': 2.4224224224224226e-06, 'epoch': 3.37, 'iter_time': 0.12412636724141976, 'flops': 17688971820802.043, 'remaining_time': 30.038580872423584}\n",
            "DEBUG:__main__:Step (759) Logs: {'loss': 2.0273, 'grad_norm': 78.59925079345703, 'learning_rate': 2.412412412412413e-06, 'epoch': 3.37, 'iter_time': 0.12410767002910926, 'flops': 17691636720252.742, 'remaining_time': 29.90994847701533}\n",
            "DEBUG:__main__:Step (760) Logs: {'loss': 1.8205, 'grad_norm': 55.466915130615234, 'learning_rate': 2.4024024024024026e-06, 'epoch': 3.38, 'iter_time': 0.12408877172960123, 'flops': 17694331096584.027, 'remaining_time': 29.781305215104293}\n",
            "DEBUG:__main__:Step (761) Logs: {'loss': 2.0461, 'grad_norm': 68.95986938476562, 'learning_rate': 2.3923923923923923e-06, 'epoch': 3.38, 'iter_time': 0.12407271799288298, 'flops': 17696620561483.527, 'remaining_time': 29.653379600299033}\n",
            "DEBUG:__main__:Step (762) Logs: {'loss': 1.7031, 'grad_norm': 64.88365173339844, 'learning_rate': 2.3823823823823825e-06, 'epoch': 3.39, 'iter_time': 0.12405548302478765, 'flops': 17699079144396.07, 'remaining_time': 29.52520495989946}\n",
            "DEBUG:__main__:Step (763) Logs: {'loss': 2.2204, 'grad_norm': 76.87728881835938, 'learning_rate': 2.3723723723723727e-06, 'epoch': 3.39, 'iter_time': 0.12404046377797764, 'flops': 17701222209891.66, 'remaining_time': 29.397589915380703}\n",
            "DEBUG:__main__:Step (764) Logs: {'loss': 1.5067, 'grad_norm': 74.8214111328125, 'learning_rate': 2.3623623623623625e-06, 'epoch': 3.4, 'iter_time': 0.12402302347035739, 'flops': 17703711382885.164, 'remaining_time': 29.269433539004343}\n",
            "DEBUG:__main__:Step (765) Logs: {'loss': 1.9219, 'grad_norm': 46.33967208862305, 'learning_rate': 2.3523523523523527e-06, 'epoch': 3.4, 'iter_time': 0.12400723970373263, 'flops': 17705964729137.586, 'remaining_time': 29.14170133037717}\n",
            "DEBUG:__main__:Step (766) Logs: {'loss': 2.0609, 'grad_norm': 43.75853729248047, 'learning_rate': 2.3423423423423424e-06, 'epoch': 3.4, 'iter_time': 0.12399008133832146, 'flops': 17708414968781.76, 'remaining_time': 29.01367903316722}\n",
            "DEBUG:__main__:Step (767) Logs: {'loss': 2.3037, 'grad_norm': 56.233070373535156, 'learning_rate': 2.3323323323323326e-06, 'epoch': 3.41, 'iter_time': 0.123973566309279, 'flops': 17710773979627.477, 'remaining_time': 28.885840950062008}\n",
            "DEBUG:__main__:Step (768) Logs: {'loss': 1.4452, 'grad_norm': 70.88569641113281, 'learning_rate': 2.3223223223223228e-06, 'epoch': 3.41, 'iter_time': 0.12395738125469104, 'flops': 17713086466715.812, 'remaining_time': 28.75811245108832}\n",
            "DEBUG:__main__:Step (769) Logs: {'loss': 1.4947, 'grad_norm': 49.1274528503418, 'learning_rate': 2.3123123123123125e-06, 'epoch': 3.42, 'iter_time': 0.1239394573494792, 'flops': 17715648101966.023, 'remaining_time': 28.630014647729695}\n",
            "DEBUG:__main__:Step (770) Logs: {'loss': 1.5767, 'grad_norm': 48.153202056884766, 'learning_rate': 2.3023023023023023e-06, 'epoch': 3.42, 'iter_time': 0.12392210526336155, 'flops': 17718128720341.914, 'remaining_time': 28.502084210573155}\n",
            "DEBUG:__main__:Step (771) Logs: {'loss': 1.7993, 'grad_norm': 55.36773681640625, 'learning_rate': 2.2922922922922925e-06, 'epoch': 3.43, 'iter_time': 0.12390669847463633, 'flops': 17720331825332.695, 'remaining_time': 28.37463395069172}\n",
            "DEBUG:__main__:Step (772) Logs: {'loss': 2.2295, 'grad_norm': 68.16493225097656, 'learning_rate': 2.2822822822822822e-06, 'epoch': 3.43, 'iter_time': 0.12389070607344928, 'flops': 17722619249988.668, 'remaining_time': 28.247080984746436}\n",
            "DEBUG:__main__:Step (773) Logs: {'loss': 2.3001, 'grad_norm': 59.180294036865234, 'learning_rate': 2.2722722722722724e-06, 'epoch': 3.44, 'iter_time': 0.12387426158924794, 'flops': 17724971952870.797, 'remaining_time': 28.119457380759282}\n",
            "DEBUG:__main__:Step (774) Logs: {'loss': 1.8777, 'grad_norm': 77.85584259033203, 'learning_rate': 2.2622622622622626e-06, 'epoch': 3.44, 'iter_time': 0.12386114785464584, 'flops': 17726848575056.57, 'remaining_time': 27.99261941514996}\n",
            "DEBUG:__main__:Step (775) Logs: {'loss': 1.8803, 'grad_norm': 48.90715026855469, 'learning_rate': 2.2522522522522524e-06, 'epoch': 3.44, 'iter_time': 0.123845503619783, 'flops': 17729087840709.184, 'remaining_time': 27.865238314451176}\n",
            "DEBUG:__main__:Step (776) Logs: {'loss': 2.0556, 'grad_norm': 66.58934020996094, 'learning_rate': 2.2422422422422426e-06, 'epoch': 3.45, 'iter_time': 0.12382974563106414, 'flops': 17731343960713.03, 'remaining_time': 27.737863021358365}\n",
            "DEBUG:__main__:Step (777) Logs: {'loss': 2.0051, 'grad_norm': 47.79778289794922, 'learning_rate': 2.2322322322322323e-06, 'epoch': 3.45, 'iter_time': 0.12381467346063595, 'flops': 17733502427319.832, 'remaining_time': 27.610672181721817}\n",
            "DEBUG:__main__:Step (778) Logs: {'loss': 1.8372, 'grad_norm': 48.39817810058594, 'learning_rate': 2.222222222222222e-06, 'epoch': 3.46, 'iter_time': 0.12379687326448457, 'flops': 17736052247952.08, 'remaining_time': 27.482905864715576}\n",
            "DEBUG:__main__:Step (779) Logs: {'loss': 1.6323, 'grad_norm': 90.67544555664062, 'learning_rate': 2.2122122122122127e-06, 'epoch': 3.46, 'iter_time': 0.12378426290722923, 'flops': 17737859084700.895, 'remaining_time': 27.35632210249766}\n",
            "DEBUG:__main__:Step (780) Logs: {'loss': 1.4577, 'grad_norm': 39.34209442138672, 'learning_rate': 2.2022022022022024e-06, 'epoch': 3.47, 'iter_time': 0.12377166870469765, 'flops': 17739663974237.63, 'remaining_time': 27.229767115033482}\n",
            "DEBUG:__main__:Step (781) Logs: {'loss': 2.2023, 'grad_norm': 83.88854217529297, 'learning_rate': 2.192192192192192e-06, 'epoch': 3.47, 'iter_time': 0.12375758733504857, 'flops': 17741682426368.53, 'remaining_time': 27.102911626375636}\n",
            "DEBUG:__main__:Step (782) Logs: {'loss': 2.3366, 'grad_norm': 63.84434509277344, 'learning_rate': 2.1821821821821824e-06, 'epoch': 3.48, 'iter_time': 0.12374097681228696, 'flops': 17744064003008.414, 'remaining_time': 26.97553294507856}\n",
            "DEBUG:__main__:Step (783) Logs: {'loss': 2.4773, 'grad_norm': 77.6837387084961, 'learning_rate': 2.172172172172172e-06, 'epoch': 3.48, 'iter_time': 0.123725267322472, 'flops': 17746316980098.414, 'remaining_time': 26.848383008976423}\n",
            "DEBUG:__main__:Step (784) Logs: {'loss': 1.8215, 'grad_norm': 48.760650634765625, 'learning_rate': 2.1621621621621623e-06, 'epoch': 3.48, 'iter_time': 0.1237093997336591, 'flops': 17748593211826.88, 'remaining_time': 26.721230342470367}\n",
            "DEBUG:__main__:Step (785) Logs: {'loss': 1.817, 'grad_norm': 45.621864318847656, 'learning_rate': 2.1521521521521525e-06, 'epoch': 3.49, 'iter_time': 0.1236928284776454, 'flops': 17750971009194.895, 'remaining_time': 26.59395812269376}\n",
            "DEBUG:__main__:Step (786) Logs: {'loss': 2.2587, 'grad_norm': 67.51854705810547, 'learning_rate': 2.1421421421421423e-06, 'epoch': 3.49, 'iter_time': 0.12367713375456015, 'flops': 17753223621023.984, 'remaining_time': 26.46690662347587}\n",
            "DEBUG:__main__:Step (787) Logs: {'loss': 1.8401, 'grad_norm': 63.75642395019531, 'learning_rate': 2.1321321321321325e-06, 'epoch': 3.5, 'iter_time': 0.12366245903131616, 'flops': 17755330352892.07, 'remaining_time': 26.340103773670343}\n",
            "DEBUG:__main__:Step (788) Logs: {'loss': 2.0011, 'grad_norm': 93.47539520263672, 'learning_rate': 2.1221221221221222e-06, 'epoch': 3.5, 'iter_time': 0.12364757712338749, 'flops': 17757467339298.938, 'remaining_time': 26.213286350158146}\n",
            "DEBUG:__main__:Step (789) Logs: {'loss': 1.6406, 'grad_norm': 67.3934326171875, 'learning_rate': 2.1121121121121124e-06, 'epoch': 3.51, 'iter_time': 0.1236323218055183, 'flops': 17759658479972.0, 'remaining_time': 26.08641990096436}\n",
            "DEBUG:__main__:Step (790) Logs: {'loss': 1.6243, 'grad_norm': 49.7712287902832, 'learning_rate': 2.102102102102102e-06, 'epoch': 3.51, 'iter_time': 0.1236196204887748, 'flops': 17761483198788.63, 'remaining_time': 25.960120302642707}\n",
            "DEBUG:__main__:Step (791) Logs: {'loss': 1.7037, 'grad_norm': 51.10913848876953, 'learning_rate': 2.0920920920920923e-06, 'epoch': 3.52, 'iter_time': 0.1236034480831291, 'flops': 17763807130002.64, 'remaining_time': 25.83312064937398}\n",
            "DEBUG:__main__:Step (792) Logs: {'loss': 1.4651, 'grad_norm': 59.099735260009766, 'learning_rate': 2.082082082082082e-06, 'epoch': 3.52, 'iter_time': 0.12359104686983015, 'flops': 17765589563008.914, 'remaining_time': 25.70693774892467}\n",
            "DEBUG:__main__:Step (793) Logs: {'loss': 2.2689, 'grad_norm': 59.030757904052734, 'learning_rate': 2.0720720720720723e-06, 'epoch': 3.52, 'iter_time': 0.12357679280367764, 'flops': 17767638749455.043, 'remaining_time': 25.58039611036127}\n",
            "DEBUG:__main__:Step (794) Logs: {'loss': 1.9354, 'grad_norm': 62.54350280761719, 'learning_rate': 2.062062062062062e-06, 'epoch': 3.53, 'iter_time': 0.12356299139361965, 'flops': 17769623311866.312, 'remaining_time': 25.453976227085647}\n",
            "DEBUG:__main__:Step (795) Logs: {'loss': 1.9039, 'grad_norm': 48.70266342163086, 'learning_rate': 2.0520520520520522e-06, 'epoch': 3.53, 'iter_time': 0.12354764650090215, 'flops': 17771830338637.547, 'remaining_time': 25.327267532684942}\n",
            "DEBUG:__main__:Step (796) Logs: {'loss': 1.6673, 'grad_norm': 55.03306198120117, 'learning_rate': 2.0420420420420424e-06, 'epoch': 3.54, 'iter_time': 0.1235345852450005, 'flops': 17773709346232.332, 'remaining_time': 25.2010553899801}\n",
            "DEBUG:__main__:Step (797) Logs: {'loss': 2.1151, 'grad_norm': 47.31876754760742, 'learning_rate': 2.032032032032032e-06, 'epoch': 3.54, 'iter_time': 0.12352075768475557, 'flops': 17775699028301.707, 'remaining_time': 25.07471381000538}\n",
            "DEBUG:__main__:Step (798) Logs: {'loss': 1.6928, 'grad_norm': 52.20101547241211, 'learning_rate': 2.022022022022022e-06, 'epoch': 3.55, 'iter_time': 0.1235082433693382, 'flops': 17777500128360.582, 'remaining_time': 24.948665160606318}\n",
            "DEBUG:__main__:Step (799) Logs: {'loss': 1.9369, 'grad_norm': 50.19962692260742, 'learning_rate': 2.012012012012012e-06, 'epoch': 3.55, 'iter_time': 0.12349341178597663, 'flops': 17779635209668.168, 'remaining_time': 24.822175768981303}\n",
            "DEBUG:__main__:Step (800) Logs: {'loss': 2.0545, 'grad_norm': 57.77348327636719, 'learning_rate': 2.0020020020020023e-06, 'epoch': 3.56, 'iter_time': 0.12347936003616963, 'flops': 17781658503160.723, 'remaining_time': 24.695872007233927}\n",
            "DEBUG:__main__:Step (801) Logs: {'loss': 1.3096, 'grad_norm': 58.40410614013672, 'learning_rate': 1.991991991991992e-06, 'epoch': 3.56, 'iter_time': 0.12347127676010132, 'flops': 17782822612404.63, 'remaining_time': 24.570784075260164}\n",
            "DEBUG:__main__:Step (802) Logs: {'loss': 2.0188, 'grad_norm': 47.877784729003906, 'learning_rate': 1.9819819819819822e-06, 'epoch': 3.56, 'iter_time': 0.1234579071421153, 'flops': 17784748366295.527, 'remaining_time': 24.444665614138827}\n",
            "DEBUG:__main__:Step (803) Logs: {'loss': 2.0195, 'grad_norm': 94.1431655883789, 'learning_rate': 1.971971971971972e-06, 'epoch': 3.57, 'iter_time': 0.12344364810762858, 'flops': 17786802691035.44, 'remaining_time': 24.31839867720283}\n",
            "DEBUG:__main__:Step (804) Logs: {'loss': 2.2922, 'grad_norm': 68.7785873413086, 'learning_rate': 1.961961961961962e-06, 'epoch': 3.57, 'iter_time': 0.12342897803519166, 'flops': 17788916730121.336, 'remaining_time': 24.192079694897565}\n",
            "DEBUG:__main__:Step (805) Logs: {'loss': 1.9899, 'grad_norm': 46.40027618408203, 'learning_rate': 1.951951951951952e-06, 'epoch': 3.58, 'iter_time': 0.12341453602064902, 'flops': 17790998395720.85, 'remaining_time': 24.06583452402656}\n",
            "DEBUG:__main__:Step (806) Logs: {'loss': 1.6317, 'grad_norm': 59.08842849731445, 'learning_rate': 1.941941941941942e-06, 'epoch': 3.58, 'iter_time': 0.12340439239644116, 'flops': 17792460784526.504, 'remaining_time': 23.940452124909584}\n",
            "DEBUG:__main__:Step (807) Logs: {'loss': 1.5646, 'grad_norm': 53.74675369262695, 'learning_rate': 1.9319319319319323e-06, 'epoch': 3.59, 'iter_time': 0.12339204091292161, 'flops': 17794241801231.684, 'remaining_time': 23.81466389619387}\n",
            "DEBUG:__main__:Step (808) Logs: {'loss': 2.552, 'grad_norm': 51.01352310180664, 'learning_rate': 1.921921921921922e-06, 'epoch': 3.59, 'iter_time': 0.12338080902525041, 'flops': 17795861687879.25, 'remaining_time': 23.68911533284808}\n",
            "DEBUG:__main__:Step (809) Logs: {'loss': 2.4314, 'grad_norm': 53.361572265625, 'learning_rate': 1.911911911911912e-06, 'epoch': 3.6, 'iter_time': 0.12336780912805312, 'flops': 17797736928868.895, 'remaining_time': 23.563251543458147}\n",
            "DEBUG:__main__:Step (810) Logs: {'loss': 1.5258, 'grad_norm': 39.412353515625, 'learning_rate': 1.901901901901902e-06, 'epoch': 3.6, 'iter_time': 0.12335745866867462, 'flops': 17799230269888.56, 'remaining_time': 23.43791714704818}\n",
            "DEBUG:__main__:Step (811) Logs: {'loss': 2.2662, 'grad_norm': 49.600215911865234, 'learning_rate': 1.8918918918918922e-06, 'epoch': 3.6, 'iter_time': 0.12334550633842563, 'flops': 17800955037046.105, 'remaining_time': 23.312300697962442}\n",
            "DEBUG:__main__:Step (812) Logs: {'loss': 1.6509, 'grad_norm': 55.01334762573242, 'learning_rate': 1.8818818818818822e-06, 'epoch': 3.61, 'iter_time': 0.12333164173930553, 'flops': 17802956170754.074, 'remaining_time': 23.18634864698944}\n",
            "DEBUG:__main__:Step (813) Logs: {'loss': 1.9309, 'grad_norm': 58.980743408203125, 'learning_rate': 1.871871871871872e-06, 'epoch': 3.61, 'iter_time': 0.12331734942685207, 'flops': 17805019509070.785, 'remaining_time': 23.060344342821338}\n",
            "DEBUG:__main__:Step (814) Logs: {'loss': 1.8585, 'grad_norm': 81.3200912475586, 'learning_rate': 1.861861861861862e-06, 'epoch': 3.62, 'iter_time': 0.12330378260266443, 'flops': 17806978553345.324, 'remaining_time': 22.934503564095586}\n",
            "DEBUG:__main__:Step (815) Logs: {'loss': 2.1049, 'grad_norm': 50.77787399291992, 'learning_rate': 1.8518518518518519e-06, 'epoch': 3.62, 'iter_time': 0.12328973390546419, 'flops': 17809007634290.047, 'remaining_time': 22.808600772510875}\n",
            "DEBUG:__main__:Step (816) Logs: {'loss': 1.6939, 'grad_norm': 45.03221130371094, 'learning_rate': 1.841841841841842e-06, 'epoch': 3.63, 'iter_time': 0.1232749473829211, 'flops': 17811143780347.66, 'remaining_time': 22.682590318457482}\n",
            "DEBUG:__main__:Step (817) Logs: {'loss': 1.5178, 'grad_norm': 55.10533905029297, 'learning_rate': 1.831831831831832e-06, 'epoch': 3.63, 'iter_time': 0.123262373547928, 'flops': 17812960672043.69, 'remaining_time': 22.557014359270823}\n",
            "DEBUG:__main__:Step (818) Logs: {'loss': 2.0456, 'grad_norm': 63.42754364013672, 'learning_rate': 1.821821821821822e-06, 'epoch': 3.64, 'iter_time': 0.1232485105825025, 'flops': 17814964269951.33, 'remaining_time': 22.431228926015454}\n",
            "DEBUG:__main__:Step (819) Logs: {'loss': 2.1073, 'grad_norm': 83.83130645751953, 'learning_rate': 1.811811811811812e-06, 'epoch': 3.64, 'iter_time': 0.1232400785739964, 'flops': 17816183158579.105, 'remaining_time': 22.306454221893347}\n",
            "DEBUG:__main__:Step (820) Logs: {'loss': 2.206, 'grad_norm': 60.834129333496094, 'learning_rate': 1.801801801801802e-06, 'epoch': 3.64, 'iter_time': 0.12322792290767907, 'flops': 17817940613970.82, 'remaining_time': 22.18102612338223}\n",
            "DEBUG:__main__:Step (821) Logs: {'loss': 2.3698, 'grad_norm': 70.49121856689453, 'learning_rate': 1.7917917917917917e-06, 'epoch': 3.65, 'iter_time': 0.12321462049716857, 'flops': 17819864261988.746, 'remaining_time': 22.055417068993172}\n",
            "DEBUG:__main__:Step (822) Logs: {'loss': 2.2853, 'grad_norm': 55.37868881225586, 'learning_rate': 1.781781781781782e-06, 'epoch': 3.65, 'iter_time': 0.12320023041840157, 'flops': 17821945664348.758, 'remaining_time': 21.92964101447548}\n",
            "DEBUG:__main__:Step (823) Logs: {'loss': 1.8048, 'grad_norm': 54.999900817871094, 'learning_rate': 1.7717717717717719e-06, 'epoch': 3.66, 'iter_time': 0.12318567492956083, 'flops': 17824051486567.016, 'remaining_time': 21.803864462532268}\n",
            "DEBUG:__main__:Step (824) Logs: {'loss': 1.6504, 'grad_norm': 105.21282196044922, 'learning_rate': 1.7617617617617618e-06, 'epoch': 3.66, 'iter_time': 0.1231717631709677, 'flops': 17826064641977.387, 'remaining_time': 21.678230318090314}\n",
            "DEBUG:__main__:Step (825) Logs: {'loss': 1.6943, 'grad_norm': 65.06024169921875, 'learning_rate': 1.7517517517517518e-06, 'epoch': 3.67, 'iter_time': 0.12315852665206761, 'flops': 17827980506416.188, 'remaining_time': 21.552742164111834}\n",
            "DEBUG:__main__:Step (826) Logs: {'loss': 1.2707, 'grad_norm': 54.1338005065918, 'learning_rate': 1.7417417417417418e-06, 'epoch': 3.67, 'iter_time': 0.1231461949781938, 'flops': 17829765773443.504, 'remaining_time': 21.427437926205723}\n",
            "DEBUG:__main__:Step (827) Logs: {'loss': 1.6036, 'grad_norm': 44.86690902709961, 'learning_rate': 1.731731731731732e-06, 'epoch': 3.68, 'iter_time': 0.1231321950801637, 'flops': 17831792984138.207, 'remaining_time': 21.30186974886832}\n",
            "DEBUG:__main__:Step (828) Logs: {'loss': 2.1361, 'grad_norm': 59.969268798828125, 'learning_rate': 1.721721721721722e-06, 'epoch': 3.68, 'iter_time': 0.12311799235038343, 'flops': 17833850036340.055, 'remaining_time': 21.17629468426595}\n",
            "DEBUG:__main__:Step (829) Logs: {'loss': 1.2991, 'grad_norm': 35.144798278808594, 'learning_rate': 1.711711711711712e-06, 'epoch': 3.68, 'iter_time': 0.12310544246636727, 'flops': 17835668093649.574, 'remaining_time': 21.051030661748804}\n",
            "DEBUG:__main__:Step (830) Logs: {'loss': 1.4819, 'grad_norm': 66.04287719726562, 'learning_rate': 1.7017017017017019e-06, 'epoch': 3.69, 'iter_time': 0.12309069886569954, 'flops': 17837804420524.293, 'remaining_time': 20.92541880716892}\n",
            "DEBUG:__main__:Step (831) Logs: {'loss': 2.0652, 'grad_norm': 44.73307418823242, 'learning_rate': 1.6916916916916916e-06, 'epoch': 3.69, 'iter_time': 0.12307624730719141, 'flops': 17839898927627.652, 'remaining_time': 20.799885794915348}\n",
            "DEBUG:__main__:Step (832) Logs: {'loss': 1.4006, 'grad_norm': 72.11944580078125, 'learning_rate': 1.681681681681682e-06, 'epoch': 3.7, 'iter_time': 0.12306282810068876, 'flops': 17841844253372.16, 'remaining_time': 20.674555120915713}\n",
            "DEBUG:__main__:Step (833) Logs: {'loss': 2.7358, 'grad_norm': 74.93173217773438, 'learning_rate': 1.6716716716716718e-06, 'epoch': 3.7, 'iter_time': 0.12304993317677425, 'flops': 17843713975835.246, 'remaining_time': 20.5493388405213}\n",
            "DEBUG:__main__:Step (834) Logs: {'loss': 2.3136, 'grad_norm': 63.91167449951172, 'learning_rate': 1.6616616616616618e-06, 'epoch': 3.71, 'iter_time': 0.12303598931714409, 'flops': 17845736231634.88, 'remaining_time': 20.423974226645917}\n",
            "DEBUG:__main__:Step (835) Logs: {'loss': 1.3388, 'grad_norm': 78.41351318359375, 'learning_rate': 1.6516516516516517e-06, 'epoch': 3.71, 'iter_time': 0.1230215546038511, 'flops': 17847830158075.94, 'remaining_time': 20.298556509635432}\n",
            "DEBUG:__main__:Step (836) Logs: {'loss': 1.4398, 'grad_norm': 52.2325439453125, 'learning_rate': 1.6416416416416417e-06, 'epoch': 3.72, 'iter_time': 0.1230094375724564, 'flops': 17849588256662.69, 'remaining_time': 20.17354776188285}\n",
            "DEBUG:__main__:Step (837) Logs: {'loss': 2.1621, 'grad_norm': 63.40565490722656, 'learning_rate': 1.6316316316316317e-06, 'epoch': 3.72, 'iter_time': 0.12299549665177267, 'flops': 17851611417679.94, 'remaining_time': 20.048265954238946}\n",
            "DEBUG:__main__:Step (838) Logs: {'loss': 2.4099, 'grad_norm': 95.97555541992188, 'learning_rate': 1.6216216216216219e-06, 'epoch': 3.72, 'iter_time': 0.12298238889860566, 'flops': 17853514084542.992, 'remaining_time': 19.923147001574115}\n",
            "DEBUG:__main__:Step (839) Logs: {'loss': 2.2358, 'grad_norm': 52.582969665527344, 'learning_rate': 1.6116116116116118e-06, 'epoch': 3.73, 'iter_time': 0.1229668815835848, 'flops': 17855765585626.64, 'remaining_time': 19.797667934957154}\n",
            "DEBUG:__main__:Step (840) Logs: {'loss': 1.806, 'grad_norm': 47.10972213745117, 'learning_rate': 1.6016016016016018e-06, 'epoch': 3.73, 'iter_time': 0.12295137741852716, 'flops': 17858017197139.117, 'remaining_time': 19.672220386964344}\n",
            "DEBUG:__main__:Step (840) Logs: {'eval_loss': 2.9205052852630615, 'eval_runtime': 0.8373, 'eval_samples_per_second': 119.425, 'eval_steps_per_second': 119.425, 'epoch': 3.73, 'iter_time': 0.12395756378219296, 'flops': 17713060384197.523, 'remaining_time': 19.833210205150873}\n",
            "DEBUG:__main__:Step (841) Logs: {'loss': 2.0838, 'grad_norm': 61.31060028076172, 'learning_rate': 1.5915915915915916e-06, 'epoch': 3.74, 'iter_time': 0.1247949032556443, 'flops': 17594210621359.594, 'remaining_time': 19.84238961764744}\n",
            "DEBUG:__main__:Step (842) Logs: {'loss': 1.6681, 'grad_norm': 49.522823333740234, 'learning_rate': 1.5815815815815815e-06, 'epoch': 3.74, 'iter_time': 0.12481266309758571, 'flops': 17591707106155.574, 'remaining_time': 19.720400769418543}\n",
            "DEBUG:__main__:Step (843) Logs: {'loss': 1.9449, 'grad_norm': 54.77018356323242, 'learning_rate': 1.5715715715715717e-06, 'epoch': 3.75, 'iter_time': 0.12479722358268683, 'flops': 17593883496111.734, 'remaining_time': 19.593164102481833}\n",
            "DEBUG:__main__:Step (844) Logs: {'loss': 1.6885, 'grad_norm': 51.78313064575195, 'learning_rate': 1.5615615615615617e-06, 'epoch': 3.75, 'iter_time': 0.12478162696494467, 'flops': 17596082578477.973, 'remaining_time': 19.465933806531368}\n",
            "DEBUG:__main__:Step (845) Logs: {'loss': 1.6651, 'grad_norm': 60.668983459472656, 'learning_rate': 1.5515515515515517e-06, 'epoch': 3.76, 'iter_time': 0.12476568481933449, 'flops': 17598330947579.15, 'remaining_time': 19.338681146996848}\n",
            "DEBUG:__main__:Step (846) Logs: {'loss': 1.8144, 'grad_norm': 46.85833740234375, 'learning_rate': 1.5415415415415416e-06, 'epoch': 3.76, 'iter_time': 0.12474875139766896, 'flops': 17600719748711.07, 'remaining_time': 19.21130771524102}\n",
            "DEBUG:__main__:Step (847) Logs: {'loss': 1.7958, 'grad_norm': 50.15947723388672, 'learning_rate': 1.5315315315315316e-06, 'epoch': 3.76, 'iter_time': 0.12473257382710774, 'flops': 17603002527594.94, 'remaining_time': 19.084083795547485}\n",
            "DEBUG:__main__:Step (848) Logs: {'loss': 1.5088, 'grad_norm': 68.27722930908203, 'learning_rate': 1.5215215215215218e-06, 'epoch': 3.77, 'iter_time': 0.12471918035144648, 'flops': 17604892897506.402, 'remaining_time': 18.957315413419867}\n",
            "DEBUG:__main__:Step (849) Logs: {'loss': 2.1883, 'grad_norm': 68.67063903808594, 'learning_rate': 1.5115115115115118e-06, 'epoch': 3.77, 'iter_time': 0.12470480349828612, 'flops': 17606922514273.285, 'remaining_time': 18.830425328241205}\n",
            "DEBUG:__main__:Step (850) Logs: {'loss': 2.4252, 'grad_norm': 58.96562576293945, 'learning_rate': 1.5015015015015017e-06, 'epoch': 3.78, 'iter_time': 0.12468918782381343, 'flops': 17609127548849.64, 'remaining_time': 18.703378173572013}\n",
            "DEBUG:__main__:Step (851) Logs: {'loss': 1.2785, 'grad_norm': 41.656925201416016, 'learning_rate': 1.4914914914914915e-06, 'epoch': 3.78, 'iter_time': 0.12467962545507094, 'flops': 17610478090048.66, 'remaining_time': 18.577264192805572}\n",
            "DEBUG:__main__:Step (852) Logs: {'loss': 1.9964, 'grad_norm': 46.8005485534668, 'learning_rate': 1.4814814814814815e-06, 'epoch': 3.79, 'iter_time': 0.12466440497778278, 'flops': 17612628181583.215, 'remaining_time': 18.45033193671185}\n",
            "DEBUG:__main__:Step (853) Logs: {'loss': 1.4201, 'grad_norm': 46.434974670410156, 'learning_rate': 1.4714714714714714e-06, 'epoch': 3.79, 'iter_time': 0.12464934811345849, 'flops': 17614755677289.676, 'remaining_time': 18.323454172678396}\n",
            "DEBUG:__main__:Step (854) Logs: {'loss': 1.7767, 'grad_norm': 62.33824157714844, 'learning_rate': 1.4614614614614616e-06, 'epoch': 3.8, 'iter_time': 0.12463297402313697, 'flops': 17617069877064.75, 'remaining_time': 18.196414207377998}\n",
            "DEBUG:__main__:Step (855) Logs: {'loss': 1.844, 'grad_norm': 68.47534942626953, 'learning_rate': 1.4514514514514516e-06, 'epoch': 3.8, 'iter_time': 0.12461779212504974, 'flops': 17619216124040.473, 'remaining_time': 18.06957985813221}\n",
            "DEBUG:__main__:Step (856) Logs: {'loss': 1.4359, 'grad_norm': 45.73476791381836, 'learning_rate': 1.4414414414414416e-06, 'epoch': 3.8, 'iter_time': 0.12460246588054456, 'flops': 17621383307590.156, 'remaining_time': 17.942755086798417}\n",
            "DEBUG:__main__:Step (857) Logs: {'loss': 1.7547, 'grad_norm': 69.9134750366211, 'learning_rate': 1.4314314314314315e-06, 'epoch': 3.81, 'iter_time': 0.12458780742137232, 'flops': 17623456562855.812, 'remaining_time': 17.81605646125624}\n",
            "DEBUG:__main__:Step (858) Logs: {'loss': 1.8956, 'grad_norm': 48.12314987182617, 'learning_rate': 1.4214214214214215e-06, 'epoch': 3.81, 'iter_time': 0.12457291776686037, 'flops': 17625563017326.26, 'remaining_time': 17.68935432289417}\n",
            "DEBUG:__main__:Step (859) Logs: {'loss': 2.0755, 'grad_norm': 60.47160720825195, 'learning_rate': 1.4114114114114117e-06, 'epoch': 3.82, 'iter_time': 0.12455621271422415, 'flops': 17627926897469.465, 'remaining_time': 17.562425992705606}\n",
            "DEBUG:__main__:Step (860) Logs: {'loss': 1.5897, 'grad_norm': 54.078895568847656, 'learning_rate': 1.4014014014014016e-06, 'epoch': 3.82, 'iter_time': 0.12455061428483068, 'flops': 17628719255697.93, 'remaining_time': 17.437085999876295}\n",
            "DEBUG:__main__:Step (861) Logs: {'loss': 1.9531, 'grad_norm': 66.0917739868164, 'learning_rate': 1.3913913913913914e-06, 'epoch': 3.83, 'iter_time': 0.12453526286191718, 'flops': 17630892342408.457, 'remaining_time': 17.310401537806488}\n",
            "DEBUG:__main__:Step (862) Logs: {'loss': 1.9449, 'grad_norm': 71.00025177001953, 'learning_rate': 1.3813813813813814e-06, 'epoch': 3.83, 'iter_time': 0.1245198316275035, 'flops': 17633077266922.906, 'remaining_time': 17.183736764595483}\n",
            "DEBUG:__main__:Step (863) Logs: {'loss': 1.7941, 'grad_norm': 64.07210540771484, 'learning_rate': 1.3713713713713714e-06, 'epoch': 3.84, 'iter_time': 0.12450415297063487, 'flops': 17635297778941.26, 'remaining_time': 17.057068956976977}\n",
            "DEBUG:__main__:Step (864) Logs: {'loss': 2.2693, 'grad_norm': 112.97599029541016, 'learning_rate': 1.3613613613613615e-06, 'epoch': 3.84, 'iter_time': 0.12448946211318704, 'flops': 17637378900036.35, 'remaining_time': 16.930566847393436}\n",
            "DEBUG:__main__:Step (865) Logs: {'loss': 2.1732, 'grad_norm': 59.04829406738281, 'learning_rate': 1.3513513513513515e-06, 'epoch': 3.84, 'iter_time': 0.12447424867638836, 'flops': 17639534567992.12, 'remaining_time': 16.804023571312428}\n",
            "DEBUG:__main__:Step (866) Logs: {'loss': 1.7159, 'grad_norm': 45.23990249633789, 'learning_rate': 1.3413413413413415e-06, 'epoch': 3.85, 'iter_time': 0.12445777661538537, 'flops': 17641869170918.27, 'remaining_time': 16.67734206646164}\n",
            "DEBUG:__main__:Step (867) Logs: {'loss': 1.7248, 'grad_norm': 47.655799865722656, 'learning_rate': 1.3313313313313315e-06, 'epoch': 3.85, 'iter_time': 0.12444458079393136, 'flops': 17643739874762.58, 'remaining_time': 16.551129245592872}\n",
            "DEBUG:__main__:Step (868) Logs: {'loss': 1.2364, 'grad_norm': 57.59703826904297, 'learning_rate': 1.3213213213213214e-06, 'epoch': 3.86, 'iter_time': 0.12442929686972014, 'flops': 17645907094138.016, 'remaining_time': 16.42466718680306}\n",
            "DEBUG:__main__:Step (869) Logs: {'loss': 1.4561, 'grad_norm': 58.67554473876953, 'learning_rate': 1.3113113113113112e-06, 'epoch': 3.86, 'iter_time': 0.12442367856953002, 'flops': 17646703887837.75, 'remaining_time': 16.299501892608433}\n",
            "DEBUG:__main__:Step (870) Logs: {'loss': 1.4111, 'grad_norm': 40.16667938232422, 'learning_rate': 1.3013013013013016e-06, 'epoch': 3.87, 'iter_time': 0.12440910108893322, 'flops': 17648771618263.184, 'remaining_time': 16.173183141561317}\n",
            "DEBUG:__main__:Step (871) Logs: {'loss': 1.8549, 'grad_norm': 44.88344955444336, 'learning_rate': 1.2912912912912913e-06, 'epoch': 3.87, 'iter_time': 0.12439390736064691, 'flops': 17650927275612.04, 'remaining_time': 16.04681404952345}\n",
            "DEBUG:__main__:Step (872) Logs: {'loss': 2.1263, 'grad_norm': 57.796730041503906, 'learning_rate': 1.2812812812812813e-06, 'epoch': 3.88, 'iter_time': 0.12437877972555762, 'flops': 17653074079008.91, 'remaining_time': 15.920483804871376}\n",
            "DEBUG:__main__:Step (873) Logs: {'loss': 1.9797, 'grad_norm': 53.101158142089844, 'learning_rate': 1.2712712712712713e-06, 'epoch': 3.88, 'iter_time': 0.12436653878710685, 'flops': 17654811605801.69, 'remaining_time': 15.79455042596257}\n",
            "DEBUG:__main__:Step (874) Logs: {'loss': 1.9139, 'grad_norm': 70.25887298583984, 'learning_rate': 1.2612612612612613e-06, 'epoch': 3.88, 'iter_time': 0.12435203128390843, 'flops': 17656871300630.91, 'remaining_time': 15.668355941772461}\n",
            "DEBUG:__main__:Step (875) Logs: {'loss': 1.8589, 'grad_norm': 66.48892211914062, 'learning_rate': 1.2512512512512514e-06, 'epoch': 3.89, 'iter_time': 0.12433700785211349, 'flops': 17659004750729.797, 'remaining_time': 15.542125981514186}\n",
            "DEBUG:__main__:Step (876) Logs: {'loss': 2.5962, 'grad_norm': 110.1050796508789, 'learning_rate': 1.2412412412412414e-06, 'epoch': 3.89, 'iter_time': 0.12432439967564174, 'flops': 17660795612771.305, 'remaining_time': 15.416225559779576}\n",
            "DEBUG:__main__:Step (877) Logs: {'loss': 1.513, 'grad_norm': 44.24674987792969, 'learning_rate': 1.2312312312312314e-06, 'epoch': 3.9, 'iter_time': 0.12430866259962456, 'flops': 17663031412572.14, 'remaining_time': 15.289965499753821}\n",
            "DEBUG:__main__:Step (878) Logs: {'loss': 2.0547, 'grad_norm': 67.03803253173828, 'learning_rate': 1.2212212212212213e-06, 'epoch': 3.9, 'iter_time': 0.12429346679417817, 'flops': 17665190850198.76, 'remaining_time': 15.163802948889737}\n",
            "DEBUG:__main__:Step (879) Logs: {'loss': 2.1628, 'grad_norm': 57.06972885131836, 'learning_rate': 1.2112112112112113e-06, 'epoch': 3.91, 'iter_time': 0.12428001064917493, 'flops': 17667103509912.49, 'remaining_time': 15.037881288550167}\n",
            "DEBUG:__main__:Step (880) Logs: {'loss': 2.2901, 'grad_norm': 52.07465744018555, 'learning_rate': 1.2012012012012013e-06, 'epoch': 3.91, 'iter_time': 0.1242653436628218, 'flops': 17669188750724.137, 'remaining_time': 14.911841239538616}\n",
            "DEBUG:__main__:Step (881) Logs: {'loss': 1.8391, 'grad_norm': 44.59268569946289, 'learning_rate': 1.1911911911911913e-06, 'epoch': 3.92, 'iter_time': 0.12425090751864694, 'flops': 17671241652882.78, 'remaining_time': 14.785857994718986}\n",
            "DEBUG:__main__:Step (882) Logs: {'loss': 2.2224, 'grad_norm': 64.8228530883789, 'learning_rate': 1.1811811811811812e-06, 'epoch': 3.92, 'iter_time': 0.12423553639995388, 'flops': 17673428038201.918, 'remaining_time': 14.659793295194557}\n",
            "DEBUG:__main__:Step (883) Logs: {'loss': 1.437, 'grad_norm': 61.284202575683594, 'learning_rate': 1.1711711711711712e-06, 'epoch': 3.92, 'iter_time': 0.12421986629633136, 'flops': 17675657508068.383, 'remaining_time': 14.533724356670769}\n",
            "DEBUG:__main__:Step (884) Logs: {'loss': 1.8252, 'grad_norm': 86.05059051513672, 'learning_rate': 1.1611611611611614e-06, 'epoch': 3.93, 'iter_time': 0.12420388175299052, 'flops': 17677932294568.836, 'remaining_time': 14.4076502833469}\n",
            "DEBUG:__main__:Step (885) Logs: {'loss': 2.3262, 'grad_norm': 49.82362747192383, 'learning_rate': 1.1511511511511512e-06, 'epoch': 3.93, 'iter_time': 0.1241936049849739, 'flops': 17679395107482.81, 'remaining_time': 14.282264573271998}\n",
            "DEBUG:__main__:Step (886) Logs: {'loss': 1.4432, 'grad_norm': 68.47268676757812, 'learning_rate': 1.1411411411411411e-06, 'epoch': 3.94, 'iter_time': 0.12418182286839027, 'flops': 17681072492219.742, 'remaining_time': 14.156727806996491}\n",
            "DEBUG:__main__:Step (887) Logs: {'loss': 1.7746, 'grad_norm': 43.66041564941406, 'learning_rate': 1.1311311311311313e-06, 'epoch': 3.94, 'iter_time': 0.12417171125218239, 'flops': 17682512306629.824, 'remaining_time': 14.03140337149661}\n",
            "DEBUG:__main__:Step (888) Logs: {'loss': 1.4525, 'grad_norm': 48.780517578125, 'learning_rate': 1.1211211211211213e-06, 'epoch': 3.95, 'iter_time': 0.12415964600736151, 'flops': 17684230609209.51, 'remaining_time': 13.90588035282449}\n",
            "DEBUG:__main__:Step (889) Logs: {'loss': 1.4951, 'grad_norm': 56.30232620239258, 'learning_rate': 1.111111111111111e-06, 'epoch': 3.95, 'iter_time': 0.12414497137069702, 'flops': 17686320985130.63, 'remaining_time': 13.78009182214737}\n",
            "DEBUG:__main__:Step (890) Logs: {'loss': 1.5856, 'grad_norm': 58.09455490112305, 'learning_rate': 1.1011011011011012e-06, 'epoch': 3.96, 'iter_time': 0.12412990520721882, 'flops': 17688467647555.33, 'remaining_time': 13.65428957279407}\n",
            "DEBUG:__main__:Step (891) Logs: {'loss': 2.0436, 'grad_norm': 68.13265991210938, 'learning_rate': 1.0910910910910912e-06, 'epoch': 3.96, 'iter_time': 0.12411665461036596, 'flops': 17690356054509.887, 'remaining_time': 13.52871535252989}\n",
            "DEBUG:__main__:Step (892) Logs: {'loss': 2.4815, 'grad_norm': 63.791202545166016, 'learning_rate': 1.0810810810810812e-06, 'epoch': 3.96, 'iter_time': 0.12410264973153437, 'flops': 17692352396196.12, 'remaining_time': 13.403086171005713}\n",
            "DEBUG:__main__:Step (893) Logs: {'loss': 1.7052, 'grad_norm': 52.49840545654297, 'learning_rate': 1.0710710710710711e-06, 'epoch': 3.97, 'iter_time': 0.12408918329418507, 'flops': 17694272410082.75, 'remaining_time': 13.277542612477802}\n",
            "DEBUG:__main__:Step (894) Logs: {'loss': 1.779, 'grad_norm': 58.45262908935547, 'learning_rate': 1.0610610610610611e-06, 'epoch': 3.97, 'iter_time': 0.12407722638675908, 'flops': 17695977547950.016, 'remaining_time': 13.152185996996463}\n",
            "DEBUG:__main__:Step (895) Logs: {'loss': 3.0611, 'grad_norm': 73.95870208740234, 'learning_rate': 1.051051051051051e-06, 'epoch': 3.98, 'iter_time': 0.12406332354150895, 'flops': 17697960603299.3, 'remaining_time': 13.02664897185844}\n",
            "DEBUG:__main__:Step (896) Logs: {'loss': 2.0469, 'grad_norm': 134.15965270996094, 'learning_rate': 1.041041041041041e-06, 'epoch': 3.98, 'iter_time': 0.12405033804184898, 'flops': 17699813213014.227, 'remaining_time': 12.901235156352294}\n",
            "DEBUG:__main__:Step (897) Logs: {'loss': 1.9518, 'grad_norm': 65.59276580810547, 'learning_rate': 1.031031031031031e-06, 'epoch': 3.99, 'iter_time': 0.12403728467013155, 'flops': 17701675896817.836, 'remaining_time': 12.77584032102355}\n",
            "DEBUG:__main__:Step (898) Logs: {'loss': 1.9364, 'grad_norm': 55.87561798095703, 'learning_rate': 1.0210210210210212e-06, 'epoch': 3.99, 'iter_time': 0.12402286178690933, 'flops': 17703734462477.58, 'remaining_time': 12.650331902264751}\n",
            "DEBUG:__main__:Step (899) Logs: {'loss': 2.487, 'grad_norm': 60.62290954589844, 'learning_rate': 1.011011011011011e-06, 'epoch': 4.0, 'iter_time': 0.12400724680758266, 'flops': 17705963714837.848, 'remaining_time': 12.524731927565847}\n",
            "DEBUG:__main__:Step (900) Logs: {'loss': 1.8781, 'grad_norm': 69.44392395019531, 'learning_rate': 1.0010010010010011e-06, 'epoch': 4.0, 'iter_time': 0.12399097464904106, 'flops': 17708287385972.098, 'remaining_time': 12.399097464904106}\n",
            "DEBUG:__main__:Step (901) Logs: {'loss': 1.4785, 'grad_norm': 49.44120407104492, 'learning_rate': 9.909909909909911e-07, 'epoch': 4.0, 'iter_time': 0.12397574636671278, 'flops': 17710462543676.46, 'remaining_time': 12.273598890304566}\n",
            "DEBUG:__main__:Step (902) Logs: {'loss': 1.5765, 'grad_norm': 60.73231506347656, 'learning_rate': 9.80980980980981e-07, 'epoch': 4.01, 'iter_time': 0.12395904754824962, 'flops': 17712848362257.4, 'remaining_time': 12.147986659728462}\n",
            "DEBUG:__main__:Step (903) Logs: {'loss': 1.663, 'grad_norm': 49.75743865966797, 'learning_rate': 9.70970970970971e-07, 'epoch': 4.01, 'iter_time': 0.12394457302178088, 'flops': 17714916908593.918, 'remaining_time': 12.022623583112745}\n",
            "DEBUG:__main__:Step (904) Logs: {'loss': 1.8837, 'grad_norm': 50.552947998046875, 'learning_rate': 9.60960960960961e-07, 'epoch': 4.02, 'iter_time': 0.12392855614654777, 'flops': 17717206434290.92, 'remaining_time': 11.897141390068587}\n",
            "DEBUG:__main__:Step (905) Logs: {'loss': 1.8194, 'grad_norm': 49.60177993774414, 'learning_rate': 9.50950950950951e-07, 'epoch': 4.02, 'iter_time': 0.12391337040251335, 'flops': 17719377700886.625, 'remaining_time': 11.771770188238769}\n",
            "DEBUG:__main__:Step (906) Logs: {'loss': 1.8956, 'grad_norm': 57.289642333984375, 'learning_rate': 9.409409409409411e-07, 'epoch': 4.03, 'iter_time': 0.12389948249521836, 'flops': 17721363867978.523, 'remaining_time': 11.646551354550526}\n",
            "DEBUG:__main__:Step (907) Logs: {'loss': 1.6554, 'grad_norm': 54.624717712402344, 'learning_rate': 9.30930930930931e-07, 'epoch': 4.03, 'iter_time': 0.1238834968465843, 'flops': 17723650593033.277, 'remaining_time': 11.52116520673234}\n",
            "DEBUG:__main__:Step (908) Logs: {'loss': 1.3448, 'grad_norm': 46.886436462402344, 'learning_rate': 9.20920920920921e-07, 'epoch': 4.04, 'iter_time': 0.12386733326391454, 'flops': 17725963371423.043, 'remaining_time': 11.395794660280137}\n",
            "DEBUG:__main__:Step (909) Logs: {'loss': 1.6919, 'grad_norm': 43.3093147277832, 'learning_rate': 9.10910910910911e-07, 'epoch': 4.04, 'iter_time': 0.12385294589702253, 'flops': 17728022506445.562, 'remaining_time': 11.27061807662905}\n",
            "DEBUG:__main__:Step (910) Logs: {'loss': 1.8073, 'grad_norm': 44.24624252319336, 'learning_rate': 9.00900900900901e-07, 'epoch': 4.04, 'iter_time': 0.12383814167530492, 'flops': 17730141801617.87, 'remaining_time': 11.145432750777443}\n",
            "DEBUG:__main__:Step (911) Logs: {'loss': 2.0766, 'grad_norm': 62.41193771362305, 'learning_rate': 8.90890890890891e-07, 'epoch': 4.05, 'iter_time': 0.12382227090688852, 'flops': 17732414340899.074, 'remaining_time': 11.020182110713078}\n",
            "DEBUG:__main__:Step (912) Logs: {'loss': 1.5712, 'grad_norm': 59.18523406982422, 'learning_rate': 8.808808808808809e-07, 'epoch': 4.05, 'iter_time': 0.12381016723934303, 'flops': 17734147859662.086, 'remaining_time': 10.895294717062187}\n",
            "DEBUG:__main__:Step (913) Logs: {'loss': 1.5013, 'grad_norm': 45.66035842895508, 'learning_rate': 8.708708708708709e-07, 'epoch': 4.06, 'iter_time': 0.1237980809650923, 'flops': 17735879225552.12, 'remaining_time': 10.770433043963031}\n",
            "DEBUG:__main__:Step (914) Logs: {'loss': 1.1896, 'grad_norm': 36.257625579833984, 'learning_rate': 8.60860860860861e-07, 'epoch': 4.06, 'iter_time': 0.12378549105758083, 'flops': 17737683096726.17, 'remaining_time': 10.645552230951951}\n",
            "DEBUG:__main__:Step (915) Logs: {'loss': 1.7181, 'grad_norm': 52.67002868652344, 'learning_rate': 8.508508508508509e-07, 'epoch': 4.07, 'iter_time': 0.12378003482484713, 'flops': 17738464975057.918, 'remaining_time': 10.521302960112006}\n",
            "DEBUG:__main__:Step (916) Logs: {'loss': 1.6891, 'grad_norm': 69.01101684570312, 'learning_rate': 8.40840840840841e-07, 'epoch': 4.07, 'iter_time': 0.12376543524486772, 'flops': 17740557434375.035, 'remaining_time': 10.396296560568889}\n",
            "DEBUG:__main__:Step (917) Logs: {'loss': 1.8357, 'grad_norm': 57.28239440917969, 'learning_rate': 8.308308308308309e-07, 'epoch': 4.08, 'iter_time': 0.12375056509367764, 'flops': 17742689180367.836, 'remaining_time': 10.271296902775244}\n",
            "DEBUG:__main__:Step (918) Logs: {'loss': 1.3143, 'grad_norm': 46.05718994140625, 'learning_rate': 8.208208208208208e-07, 'epoch': 4.08, 'iter_time': 0.12373627415140166, 'flops': 17744738375307.934, 'remaining_time': 10.146374480414936}\n",
            "DEBUG:__main__:Step (919) Logs: {'loss': 1.6266, 'grad_norm': 43.926204681396484, 'learning_rate': 8.108108108108109e-07, 'epoch': 4.08, 'iter_time': 0.12372288802610244, 'flops': 17746658256868.113, 'remaining_time': 10.021553930114298}\n",
            "DEBUG:__main__:Step (920) Logs: {'loss': 2.0278, 'grad_norm': 56.898433685302734, 'learning_rate': 8.008008008008009e-07, 'epoch': 4.09, 'iter_time': 0.12371043359883073, 'flops': 17748444884383.242, 'remaining_time': 9.896834687906459}\n",
            "DEBUG:__main__:Step (921) Logs: {'loss': 2.015, 'grad_norm': 66.70155334472656, 'learning_rate': 7.907907907907908e-07, 'epoch': 4.09, 'iter_time': 0.1236967330393584, 'flops': 17750410689127.676, 'remaining_time': 9.772041910109314}\n",
            "DEBUG:__main__:Step (922) Logs: {'loss': 1.8795, 'grad_norm': 50.67308044433594, 'learning_rate': 7.807807807807808e-07, 'epoch': 4.1, 'iter_time': 0.1236830969198519, 'flops': 17752367680240.242, 'remaining_time': 9.647281559748448}\n",
            "DEBUG:__main__:Step (923) Logs: {'loss': 1.375, 'grad_norm': 48.11095428466797, 'learning_rate': 7.707707707707708e-07, 'epoch': 4.1, 'iter_time': 0.12366886640577668, 'flops': 17754410436234.406, 'remaining_time': 9.522502713244805}\n",
            "DEBUG:__main__:Step (924) Logs: {'loss': 1.9455, 'grad_norm': 50.309871673583984, 'learning_rate': 7.607607607607609e-07, 'epoch': 4.11, 'iter_time': 0.12365457425267312, 'flops': 17756462513593.87, 'remaining_time': 9.397747643203157}\n",
            "DEBUG:__main__:Step (925) Logs: {'loss': 1.8483, 'grad_norm': 60.695316314697266, 'learning_rate': 7.507507507507509e-07, 'epoch': 4.11, 'iter_time': 0.12364147390638079, 'flops': 17758343887217.992, 'remaining_time': 9.273110542978559}\n",
            "DEBUG:__main__:Step (926) Logs: {'loss': 1.7503, 'grad_norm': 60.35924530029297, 'learning_rate': 7.407407407407407e-07, 'epoch': 4.12, 'iter_time': 0.12362842894889213, 'flops': 17760217702513.125, 'remaining_time': 9.148503742218018}\n",
            "DEBUG:__main__:Step (927) Logs: {'loss': 1.5303, 'grad_norm': 62.78962326049805, 'learning_rate': 7.307307307307308e-07, 'epoch': 4.12, 'iter_time': 0.12361775747385705, 'flops': 17761750878035.016, 'remaining_time': 9.024096295591564}\n",
            "DEBUG:__main__:Step (928) Logs: {'loss': 2.1621, 'grad_norm': 48.929771423339844, 'learning_rate': 7.207207207207208e-07, 'epoch': 4.12, 'iter_time': 0.12360431872782456, 'flops': 17763682005212.44, 'remaining_time': 8.899510948403368}\n",
            "DEBUG:__main__:Step (929) Logs: {'loss': 1.7891, 'grad_norm': 55.87470245361328, 'learning_rate': 7.107107107107107e-07, 'epoch': 4.13, 'iter_time': 0.1235902175821107, 'flops': 17765708769735.316, 'remaining_time': 8.774905448329859}\n",
            "DEBUG:__main__:Step (930) Logs: {'loss': 2.4233, 'grad_norm': 54.53061294555664, 'learning_rate': 7.007007007007008e-07, 'epoch': 4.13, 'iter_time': 0.12357878659333557, 'flops': 17767352090754.46, 'remaining_time': 8.65051506153349}\n",
            "DEBUG:__main__:Step (931) Logs: {'loss': 1.5651, 'grad_norm': 47.528690338134766, 'learning_rate': 6.906906906906907e-07, 'epoch': 4.14, 'iter_time': 0.12356619040171306, 'flops': 17769163273658.395, 'remaining_time': 8.5260671377182}\n",
            "DEBUG:__main__:Step (932) Logs: {'loss': 1.8582, 'grad_norm': 55.28537368774414, 'learning_rate': 6.806806806806808e-07, 'epoch': 4.14, 'iter_time': 0.1235522514511256, 'flops': 17771167959821.074, 'remaining_time': 8.40155309867654}\n",
            "DEBUG:__main__:Step (933) Logs: {'loss': 1.6387, 'grad_norm': 70.22154998779297, 'learning_rate': 6.706706706706707e-07, 'epoch': 4.15, 'iter_time': 0.1235383889705838, 'flops': 17773162096802.305, 'remaining_time': 8.277072061029115}\n",
            "DEBUG:__main__:Step (934) Logs: {'loss': 2.3756, 'grad_norm': 56.03800582885742, 'learning_rate': 6.606606606606607e-07, 'epoch': 4.15, 'iter_time': 0.12352688008438224, 'flops': 17774818006025.254, 'remaining_time': 8.152774085569227}\n",
            "DEBUG:__main__:Step (935) Logs: {'loss': 1.2426, 'grad_norm': 40.08663558959961, 'learning_rate': 6.506506506506508e-07, 'epoch': 4.16, 'iter_time': 0.12351584996094796, 'flops': 17776405320015.246, 'remaining_time': 8.028530247461617}\n",
            "DEBUG:__main__:Step (936) Logs: {'loss': 1.5973, 'grad_norm': 39.44955825805664, 'learning_rate': 6.406406406406407e-07, 'epoch': 4.16, 'iter_time': 0.12350377399016192, 'flops': 17778143464076.676, 'remaining_time': 7.904241535370363}\n",
            "DEBUG:__main__:Step (937) Logs: {'loss': 1.6548, 'grad_norm': 57.349063873291016, 'learning_rate': 6.306306306306306e-07, 'epoch': 4.16, 'iter_time': 0.1234901684981126, 'flops': 17780102165668.016, 'remaining_time': 7.779880615381094}\n",
            "DEBUG:__main__:Step (938) Logs: {'loss': 1.4666, 'grad_norm': 54.534183502197266, 'learning_rate': 6.206206206206207e-07, 'epoch': 4.17, 'iter_time': 0.12347698593343208, 'flops': 17782000392653.824, 'remaining_time': 7.655573127872789}\n",
            "DEBUG:__main__:Step (939) Logs: {'loss': 2.272, 'grad_norm': 49.7701301574707, 'learning_rate': 6.106106106106107e-07, 'epoch': 4.17, 'iter_time': 0.12346344817676015, 'flops': 17783950187496.03, 'remaining_time': 7.531270338782369}\n",
            "DEBUG:__main__:Step (940) Logs: {'loss': 1.7872, 'grad_norm': 61.629127502441406, 'learning_rate': 6.006006006006006e-07, 'epoch': 4.18, 'iter_time': 0.12345142003954156, 'flops': 17785682915990.164, 'remaining_time': 7.407085202372493}\n",
            "DEBUG:__main__:Step (941) Logs: {'loss': 1.8265, 'grad_norm': 46.55463790893555, 'learning_rate': 5.905905905905906e-07, 'epoch': 4.18, 'iter_time': 0.12343765370389248, 'flops': 17787666457263.21, 'remaining_time': 7.2828215685296565}\n",
            "DEBUG:__main__:Step (942) Logs: {'loss': 2.578, 'grad_norm': 51.48189163208008, 'learning_rate': 5.805805805805807e-07, 'epoch': 4.19, 'iter_time': 0.12342630562696143, 'flops': 17789301893132.05, 'remaining_time': 7.1587257263637625}\n",
            "DEBUG:__main__:Step (943) Logs: {'loss': 1.3034, 'grad_norm': 49.71599578857422, 'learning_rate': 5.705705705705706e-07, 'epoch': 4.19, 'iter_time': 0.12341580952808356, 'flops': 17790814813335.324, 'remaining_time': 7.034701143100763}\n",
            "DEBUG:__main__:Step (944) Logs: {'loss': 1.4336, 'grad_norm': 46.853275299072266, 'learning_rate': 5.605605605605606e-07, 'epoch': 4.2, 'iter_time': 0.12340544491279416, 'flops': 17792309033880.906, 'remaining_time': 6.910704915116473}\n",
            "DEBUG:__main__:Step (945) Logs: {'loss': 1.5313, 'grad_norm': 47.129234313964844, 'learning_rate': 5.505505505505506e-07, 'epoch': 4.2, 'iter_time': 0.1233928994101993, 'flops': 17794117999066.26, 'remaining_time': 6.786609467560962}\n",
            "DEBUG:__main__:Step (946) Logs: {'loss': 2.0929, 'grad_norm': 62.980682373046875, 'learning_rate': 5.405405405405406e-07, 'epoch': 4.2, 'iter_time': 0.12337964148748488, 'flops': 17796030089572.918, 'remaining_time': 6.6625006403241835}\n",
            "DEBUG:__main__:Step (947) Logs: {'loss': 1.6206, 'grad_norm': 43.408878326416016, 'learning_rate': 5.305305305305306e-07, 'epoch': 4.21, 'iter_time': 0.12336859970213747, 'flops': 17797622876917.18, 'remaining_time': 6.538535784213286}\n",
            "DEBUG:__main__:Step (948) Logs: {'loss': 1.1958, 'grad_norm': 41.292362213134766, 'learning_rate': 5.205205205205205e-07, 'epoch': 4.21, 'iter_time': 0.12335803163844655, 'flops': 17799147596545.18, 'remaining_time': 6.414617645199221}\n",
            "DEBUG:__main__:Step (949) Logs: {'loss': 1.9591, 'grad_norm': 48.300193786621094, 'learning_rate': 5.105105105105106e-07, 'epoch': 4.22, 'iter_time': 0.1233469401230792, 'flops': 17800748118770.504, 'remaining_time': 6.290693946277039}\n",
            "DEBUG:__main__:Step (950) Logs: {'loss': 2.0141, 'grad_norm': 40.23823928833008, 'learning_rate': 5.005005005005006e-07, 'epoch': 4.22, 'iter_time': 0.12333390433871205, 'flops': 17802629569903.46, 'remaining_time': 6.166695216935603}\n",
            "DEBUG:__main__:Step (951) Logs: {'loss': 1.3453, 'grad_norm': 49.097660064697266, 'learning_rate': 4.904904904904905e-07, 'epoch': 4.23, 'iter_time': 0.12332058906555175, 'flops': 17804551770222.9, 'remaining_time': 6.0427088642120355}\n",
            "DEBUG:__main__:Step (952) Logs: {'loss': 1.7667, 'grad_norm': 57.08130645751953, 'learning_rate': 4.804804804804805e-07, 'epoch': 4.23, 'iter_time': 0.12330886768617841, 'flops': 17806244218704.4, 'remaining_time': 5.918825648936563}\n",
            "DEBUG:__main__:Step (953) Logs: {'loss': 2.0849, 'grad_norm': 56.500770568847656, 'learning_rate': 4.7047047047047054e-07, 'epoch': 4.24, 'iter_time': 0.12329614613236499, 'flops': 17808081446396.82, 'remaining_time': 5.7949188682211545}\n",
            "DEBUG:__main__:Step (954) Logs: {'loss': 1.9379, 'grad_norm': 71.78617095947266, 'learning_rate': 4.604604604604605e-07, 'epoch': 4.24, 'iter_time': 0.12328334244951246, 'flops': 17809930917886.816, 'remaining_time': 5.671033752677573}\n",
            "DEBUG:__main__:Step (955) Logs: {'loss': 2.2711, 'grad_norm': 64.3519058227539, 'learning_rate': 4.504504504504505e-07, 'epoch': 4.24, 'iter_time': 0.1232698868405644, 'flops': 17811874973097.418, 'remaining_time': 5.547144907825398}\n",
            "DEBUG:__main__:Step (956) Logs: {'loss': 1.5635, 'grad_norm': 48.64582443237305, 'learning_rate': 4.4044044044044046e-07, 'epoch': 4.25, 'iter_time': 0.12325815730069944, 'flops': 17813569993549.957, 'remaining_time': 5.423358921230776}\n",
            "DEBUG:__main__:Step (957) Logs: {'loss': 1.9812, 'grad_norm': 48.27831268310547, 'learning_rate': 4.304304304304305e-07, 'epoch': 4.25, 'iter_time': 0.12324589341255411, 'flops': 17815342576991.246, 'remaining_time': 5.299573416739827}\n",
            "DEBUG:__main__:Step (958) Logs: {'loss': 2.2169, 'grad_norm': 58.83330535888672, 'learning_rate': 4.204204204204205e-07, 'epoch': 4.26, 'iter_time': 0.12323564969882946, 'flops': 17816823441251.8, 'remaining_time': 5.175897287350837}\n",
            "DEBUG:__main__:Step (959) Logs: {'loss': 1.737, 'grad_norm': 71.0313949584961, 'learning_rate': 4.104104104104104e-07, 'epoch': 4.26, 'iter_time': 0.12322220672894121, 'flops': 17818767173857.984, 'remaining_time': 5.05211047588659}\n",
            "DEBUG:__main__:Step (960) Logs: {'loss': 1.7576, 'grad_norm': 43.11094665527344, 'learning_rate': 4.0040040040040045e-07, 'epoch': 4.27, 'iter_time': 0.12321015816411086, 'flops': 17820509648461.457, 'remaining_time': 4.928406326564435}\n",
            "DEBUG:__main__:Step (960) Logs: {'eval_loss': 2.9306845664978027, 'eval_runtime': 0.8261, 'eval_samples_per_second': 121.057, 'eval_steps_per_second': 121.057, 'epoch': 4.27, 'iter_time': 0.12407880953131428, 'flops': 17695751761688.77, 'remaining_time': 4.963152381252572}\n",
            "DEBUG:__main__:Step (961) Logs: {'loss': 2.0256, 'grad_norm': 63.95097351074219, 'learning_rate': 3.903903903903904e-07, 'epoch': 4.27, 'iter_time': 0.12478005116184553, 'flops': 17596304793176.57, 'remaining_time': 4.866421995311976}\n",
            "DEBUG:__main__:Step (962) Logs: {'loss': 1.8698, 'grad_norm': 100.02588653564453, 'learning_rate': 3.8038038038038044e-07, 'epoch': 4.28, 'iter_time': 0.12476442954294639, 'flops': 17598508007414.145, 'remaining_time': 4.741048322631963}\n",
            "DEBUG:__main__:Step (963) Logs: {'loss': 1.6867, 'grad_norm': 48.620304107666016, 'learning_rate': 3.7037037037037036e-07, 'epoch': 4.28, 'iter_time': 0.12475046075555242, 'flops': 17600478579829.812, 'remaining_time': 4.61576704795544}\n",
            "DEBUG:__main__:Step (964) Logs: {'loss': 1.9674, 'grad_norm': 52.73002243041992, 'learning_rate': 3.603603603603604e-07, 'epoch': 4.28, 'iter_time': 0.12473530932750286, 'flops': 17602616485979.062, 'remaining_time': 4.490471135790103}\n",
            "DEBUG:__main__:Step (965) Logs: {'loss': 2.1975, 'grad_norm': 50.56150436401367, 'learning_rate': 3.503503503503504e-07, 'epoch': 4.29, 'iter_time': 0.12472109576973182, 'flops': 17604622528379.516, 'remaining_time': 4.365238351940614}\n",
            "DEBUG:__main__:Step (966) Logs: {'loss': 1.3794, 'grad_norm': 46.93920135498047, 'learning_rate': 3.403403403403404e-07, 'epoch': 4.29, 'iter_time': 0.12470807139737618, 'flops': 17606461135587.703, 'remaining_time': 4.24007442751079}\n",
            "DEBUG:__main__:Step (967) Logs: {'loss': 1.5685, 'grad_norm': 41.836753845214844, 'learning_rate': 3.3033033033033036e-07, 'epoch': 4.3, 'iter_time': 0.12469397469830562, 'flops': 17608451552405.566, 'remaining_time': 4.114901165044086}\n",
            "DEBUG:__main__:Step (968) Logs: {'loss': 2.0715, 'grad_norm': 46.07263946533203, 'learning_rate': 3.2032032032032033e-07, 'epoch': 4.3, 'iter_time': 0.12468188846986568, 'flops': 17610158454430.773, 'remaining_time': 3.9898204310357017}\n",
            "DEBUG:__main__:Step (969) Logs: {'loss': 1.3817, 'grad_norm': 48.42976379394531, 'learning_rate': 3.1031031031031035e-07, 'epoch': 4.31, 'iter_time': 0.12466688097015885, 'flops': 17612278379512.605, 'remaining_time': 3.864673310074924}\n",
            "DEBUG:__main__:Step (970) Logs: {'loss': 1.9209, 'grad_norm': 59.5690803527832, 'learning_rate': 3.003003003003003e-07, 'epoch': 4.31, 'iter_time': 0.12465286082650609, 'flops': 17614259294120.547, 'remaining_time': 3.7395858247951828}\n",
            "DEBUG:__main__:Step (971) Logs: {'loss': 1.6103, 'grad_norm': 63.839176177978516, 'learning_rate': 2.9029029029029035e-07, 'epoch': 4.32, 'iter_time': 0.12463833450042096, 'flops': 17616312197629.57, 'remaining_time': 3.6145117005122076}\n",
            "DEBUG:__main__:Step (972) Logs: {'loss': 1.2703, 'grad_norm': 44.272457122802734, 'learning_rate': 2.802802802802803e-07, 'epoch': 4.32, 'iter_time': 0.12462515123840709, 'flops': 17618175709586.117, 'remaining_time': 3.4895042346753984}\n",
            "DEBUG:__main__:Step (973) Logs: {'loss': 1.8285, 'grad_norm': 48.93748092651367, 'learning_rate': 2.702702702702703e-07, 'epoch': 4.32, 'iter_time': 0.12461154720910783, 'flops': 17620099112223.52, 'remaining_time': 3.3645117746459112}\n",
            "DEBUG:__main__:Step (974) Logs: {'loss': 1.6707, 'grad_norm': 52.343360900878906, 'learning_rate': 2.6026026026026026e-07, 'epoch': 4.33, 'iter_time': 0.12459781334064479, 'flops': 17622041298181.883, 'remaining_time': 3.2395431468567644}\n",
            "DEBUG:__main__:Step (975) Logs: {'loss': 1.5173, 'grad_norm': 50.32273864746094, 'learning_rate': 2.502502502502503e-07, 'epoch': 4.33, 'iter_time': 0.12458488706201008, 'flops': 17623869669353.574, 'remaining_time': 3.114622176550252}\n",
            "DEBUG:__main__:Step (976) Logs: {'loss': 1.637, 'grad_norm': 169.53492736816406, 'learning_rate': 2.4024024024024026e-07, 'epoch': 4.34, 'iter_time': 0.12457243161323743, 'flops': 17625631802459.59, 'remaining_time': 2.989738358717698}\n",
            "DEBUG:__main__:Step (977) Logs: {'loss': 1.7251, 'grad_norm': 49.72821807861328, 'learning_rate': 2.3023023023023026e-07, 'epoch': 4.34, 'iter_time': 0.12455837428569794, 'flops': 17627620984485.758, 'remaining_time': 2.8648426085710526}\n",
            "DEBUG:__main__:Step (978) Logs: {'loss': 1.6214, 'grad_norm': 69.5888900756836, 'learning_rate': 2.2022022022022023e-07, 'epoch': 4.35, 'iter_time': 0.12454383253685161, 'flops': 17629679187063.06, 'remaining_time': 2.7399643158107354}\n",
            "DEBUG:__main__:Step (979) Logs: {'loss': 2.0158, 'grad_norm': 58.50027084350586, 'learning_rate': 2.1021021021021025e-07, 'epoch': 4.35, 'iter_time': 0.12453123567538271, 'flops': 17631462503716.56, 'remaining_time': 2.6151559491830367}\n",
            "DEBUG:__main__:Step (980) Logs: {'loss': 1.4329, 'grad_norm': 69.32294464111328, 'learning_rate': 2.0020020020020022e-07, 'epoch': 4.36, 'iter_time': 0.12451846874770885, 'flops': 17633270264515.684, 'remaining_time': 2.490369374954177}\n",
            "DEBUG:__main__:Step (981) Logs: {'loss': 2.2357, 'grad_norm': 58.481563568115234, 'learning_rate': 1.9019019019019022e-07, 'epoch': 4.36, 'iter_time': 0.12450653655188425, 'flops': 17634960164818.523, 'remaining_time': 2.3656241944858007}\n",
            "DEBUG:__main__:Step (982) Logs: {'loss': 1.7983, 'grad_norm': 62.79978942871094, 'learning_rate': 1.801801801801802e-07, 'epoch': 4.36, 'iter_time': 0.12449310071363848, 'flops': 17636863406611.74, 'remaining_time': 2.2408758128454926}\n",
            "DEBUG:__main__:Step (983) Logs: {'loss': 1.5328, 'grad_norm': 42.182186126708984, 'learning_rate': 1.701701701701702e-07, 'epoch': 4.37, 'iter_time': 0.12447890317609984, 'flops': 17638874992702.953, 'remaining_time': 2.1161413539936973}\n",
            "DEBUG:__main__:Step (984) Logs: {'loss': 2.1561, 'grad_norm': 57.538448333740234, 'learning_rate': 1.6016016016016016e-07, 'epoch': 4.37, 'iter_time': 0.12446525380667205, 'flops': 17640809343967.285, 'remaining_time': 1.9914440609067527}\n",
            "DEBUG:__main__:Step (985) Logs: {'loss': 2.3816, 'grad_norm': 61.43407440185547, 'learning_rate': 1.5015015015015016e-07, 'epoch': 4.38, 'iter_time': 0.12445159777393186, 'flops': 17642745064153.074, 'remaining_time': 1.866773966608978}\n",
            "DEBUG:__main__:Step (986) Logs: {'loss': 2.0796, 'grad_norm': 69.55854797363281, 'learning_rate': 1.4014014014014016e-07, 'epoch': 4.38, 'iter_time': 0.1244366142350405, 'flops': 17644869444974.94, 'remaining_time': 1.742112599290567}\n",
            "DEBUG:__main__:Step (987) Logs: {'loss': 1.9601, 'grad_norm': 123.09385681152344, 'learning_rate': 1.3013013013013013e-07, 'epoch': 4.39, 'iter_time': 0.12442238843465189, 'flops': 17646886866387.32, 'remaining_time': 1.6174910496504746}\n",
            "DEBUG:__main__:Step (988) Logs: {'loss': 1.4967, 'grad_norm': 53.6987419128418, 'learning_rate': 1.2012012012012013e-07, 'epoch': 4.39, 'iter_time': 0.12440844896233431, 'flops': 17648864129933.46, 'remaining_time': 1.4929013875480117}\n",
            "DEBUG:__main__:Step (989) Logs: {'loss': 1.8434, 'grad_norm': 53.07282638549805, 'learning_rate': 1.1011011011011011e-07, 'epoch': 4.4, 'iter_time': 0.12439532390972863, 'flops': 17650726276056.45, 'remaining_time': 1.368348563007015}\n",
            "DEBUG:__main__:Step (990) Logs: {'loss': 2.2194, 'grad_norm': 61.83810806274414, 'learning_rate': 1.0010010010010011e-07, 'epoch': 4.4, 'iter_time': 0.12438233677369398, 'flops': 17652569241779.746, 'remaining_time': 1.24382336773694}\n",
            "DEBUG:__main__:Step (991) Logs: {'loss': 1.8514, 'grad_norm': 44.73868942260742, 'learning_rate': 9.00900900900901e-08, 'epoch': 4.4, 'iter_time': 0.1243683119012852, 'flops': 17654559901840.32, 'remaining_time': 1.1193148071115668}\n",
            "DEBUG:__main__:Step (992) Logs: {'loss': 1.3361, 'grad_norm': 47.619625091552734, 'learning_rate': 8.008008008008008e-08, 'epoch': 4.41, 'iter_time': 0.12435633960573753, 'flops': 17656259578829.68, 'remaining_time': 0.9948507168459002}\n",
            "DEBUG:__main__:Step (993) Logs: {'loss': 2.1454, 'grad_norm': 55.0961799621582, 'learning_rate': 7.007007007007008e-08, 'epoch': 4.41, 'iter_time': 0.1243508453330686, 'flops': 17657039696601.938, 'remaining_time': 0.8704559173314802}\n",
            "DEBUG:__main__:Step (994) Logs: {'loss': 2.0961, 'grad_norm': 63.82551193237305, 'learning_rate': 6.006006006006006e-08, 'epoch': 4.42, 'iter_time': 0.1243400230388507, 'flops': 17658576528218.527, 'remaining_time': 0.7460401382331041}\n",
            "DEBUG:__main__:Step (995) Logs: {'loss': 1.172, 'grad_norm': 44.65337371826172, 'learning_rate': 5.0050050050050056e-08, 'epoch': 4.42, 'iter_time': 0.12432650804999369, 'flops': 17660496114546.117, 'remaining_time': 0.6216325402499685}\n",
            "DEBUG:__main__:Step (996) Logs: {'loss': 1.8404, 'grad_norm': 54.41541290283203, 'learning_rate': 4.004004004004004e-08, 'epoch': 4.43, 'iter_time': 0.12431242453992067, 'flops': 17662496894241.664, 'remaining_time': 0.4972496981596827}\n",
            "DEBUG:__main__:Step (997) Logs: {'loss': 2.3163, 'grad_norm': 50.47172164916992, 'learning_rate': 3.003003003003003e-08, 'epoch': 4.43, 'iter_time': 0.12429945966804841, 'flops': 17664339154938.45, 'remaining_time': 0.37289837900414524}\n",
            "DEBUG:__main__:Step (998) Logs: {'loss': 1.5643, 'grad_norm': 50.063743591308594, 'learning_rate': 2.002002002002002e-08, 'epoch': 4.44, 'iter_time': 0.12428543990928168, 'flops': 17666331743723.64, 'remaining_time': 0.24857087981856335}\n",
            "DEBUG:__main__:Step (999) Logs: {'loss': 2.0531, 'grad_norm': 108.88279724121094, 'learning_rate': 1.001001001001001e-08, 'epoch': 4.44, 'iter_time': 0.12427170482092725, 'flops': 17668284309094.402, 'remaining_time': 0.12427170482092725}\n",
            "DEBUG:__main__:Step (1000) Logs: {'loss': 2.4197, 'grad_norm': 48.44717788696289, 'learning_rate': 0.0, 'epoch': 4.44, 'iter_time': 0.12425789150509152, 'flops': 17670248430555.668, 'remaining_time': 0.0}\n",
            "DEBUG:__main__:Step (1000) Logs: {'train_runtime': 124.3689, 'train_samples_per_second': 32.162, 'train_steps_per_second': 8.041, 'total_flos': 49922227912704.0, 'train_loss': 2.271273751616478, 'epoch': 4.44, 'iter_time': 0.12434787602276653, 'flops': 17657461330099.445, 'remaining_time': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Save finetuned model locally"
      ],
      "metadata": {
        "id": "PhBKdZB51IYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = f'{output_dir}/final'\n",
        "\n",
        "trainer.save_model(save_dir)\n",
        "print(\"Saved model to:\", save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF7bqmko0OKc",
        "outputId": "855704d4-b432-41d7-e5cd-d95667445ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: financialQA_1000_steps_2024-05-24_13:51:30/final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)"
      ],
      "metadata": {
        "id": "USmBGkRw1Am5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_slightly_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6E9H1NV1CSe",
        "outputId": "502e1f13-074c-4cc9-a68d-375078924996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 512)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Run the slightly finetuned model!"
      ],
      "metadata": {
        "id": "ftVkCqAs1Pul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_question = test_dataset[0]['question']\n",
        "print()\n",
        "print()\n",
        "print(\"Question input (test):\")\n",
        "print(test_question)\n",
        "print()\n",
        "print()\n",
        "\n",
        "# Predicted answer\n",
        "print(\"Finetuned slightly model's answer: \")\n",
        "print(inference(test_question, finetuned_slightly_model, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3NMyIN-1N_1",
        "outputId": "e2626098-cd64-41fd-e16e-efbcd893f1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question input (test):\n",
            "How are non-GAAP financial measures justified for aiding investors according to the document?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Finetuned slightly model's answer: \n",
            "Non-GAAP financial measures are generally based on the document's text and text. They are not based on the document's text and text and text and text and text are not included in the document's text. Non-GAAP financial measures are generally based on the document's text and text and text and text and text and text are not included in the document's text. Non-GAAP financial measures are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual answer\n",
        "test_answer = test_dataset[0]['answer']\n",
        "print(\"Target answer output (test):\", test_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCR3ygoc1TmQ",
        "outputId": "4e1308bc-044d-4090-f3e9-521ce1013501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target answer output (test): Non-GAAP financial measures are justified as they provide additional insight into operational performance and help clarify trends affecting the business, aiding investors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sji8zMDn1VH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}